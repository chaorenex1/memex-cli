好，我们直接进入可编译的落代码阶段（MVP）。下面给你一套 mem-codecli Rust 项目骨架 + 关键模块代码，满足：

能启动 codecli
stdout / stderr 流式 tee
stdin 控制通道（JSONL）
ToolEvent 解析入口
可继续往 Memory / Policy / Gatekeeper 扩展
→ 现在这套可以直接 cargo run 跑起来
一、项目目录结构（MVP 可编译）
mem-codecli/
├── Cargo.toml
├── src/
│   ├── main.rs
│   ├── cli.rs                 # clap 参数
│   ├── error.rs               # thiserror 分层
│   ├── runner/
│   │   ├── mod.rs
│   │   ├── codecli.rs         # 启动 codecli
│   │   ├── tee.rs             # stdout/stderr 流式 tee
│   │   └── control.rs         # stdin JSONL 控制通道
│   ├── protocol/
│   │   ├── mod.rs
│   │   ├── tool_event.rs      # ToolEvent / Parser
│   │   └── policy_cmd.rs      # policy.decision / abort
│   └── util/
│       └── ring.rs            # Ring buffer
二、Cargo.toml（最小依赖）
[package]
name = "mem-codecli"
version = "0.1.0"
edition = "2021"

[dependencies]
tokio = { version = "1.37", features = ["process", "io-util", "macros", "signal", "rt-multi-thread"] }
clap = { version = "4.5", features = ["derive"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
thiserror = "1.0"
tracing = "0.1"
tracing-subscriber = "0.3"
三、入口 main.rs（可直接运行）
mod cli;
mod error;
mod runner;
mod protocol;
mod util;

use clap::Parser;
use tracing_subscriber::EnvFilter;

#[tokio::main]
async fn main() -> Result<(), error::CliError> {
    tracing_subscriber::fmt()
        .with_env_filter(EnvFilter::from_default_env())
        .init();

    let args = cli::Args::parse();

    let exit = runner::run(args).await?;
    std::process::exit(exit);
}
四、CLI 参数（cli.rs）
use clap::Parser;

#[derive(Parser, Debug)]
pub struct Args {
    #[arg(long, default_value = "codex")]
    pub codecli_bin: String,

    #[arg(trailing_var_arg = true)]
    pub codecli_args: Vec<String>,

    #[arg(long, default_value_t = 65536)]
    pub capture_bytes: usize,
}
示例运行：

cargo run -- codex exec "列出当前目录"
五、错误分层（error.rs）
use thiserror::Error;

#[derive(Error, Debug)]
pub enum CliError {
    #[error("runner error")]
    Runner(#[from] RunnerError),
}

#[derive(Error, Debug)]
pub enum RunnerError {
    #[error("spawn failed: {0}")]
    Spawn(String),

    #[error("io error on {stream}")]
    StreamIo {
        stream: &'static str,
        #[source]
        source: std::io::Error,
    },
}
六、Runner 主逻辑（runner/mod.rs）
mod codecli;
mod tee;
mod control;

use crate::{cli::Args, error::RunnerError};

pub async fn run(args: Args) -> Result<i32, RunnerError> {
    let mut child = codecli::spawn(&args)?;

    let stdout = child.stdout.take().unwrap();
    let stderr = child.stderr.take().unwrap();
    let stdin  = child.stdin.take().unwrap();

    let ring_out = crate::util::ring::RingBytes::new(args.capture_bytes);
    let ring_err = crate::util::ring::RingBytes::new(args.capture_bytes);

    let out_task = tee::pump_stdout(stdout, ring_out.clone());
    let err_task = tee::pump_stderr(stderr, ring_err.clone());

    let ctl = control::ControlChannel::new(stdin);

    // 这里未来会接：ToolEventParser + PolicyEngine
    drop(ctl);

    let status = child.wait().await
        .map_err(|e| RunnerError::Spawn(e.to_string()))?;

    out_task.await.ok();
    err_task.await.ok();

    Ok(normalize_exit(status))
}

fn normalize_exit(status: std::process::ExitStatus) -> i32 {
    #[cfg(unix)]
    {
        use std::os::unix::process::ExitStatusExt;
        if let Some(code) = status.code() {
            code
        } else if let Some(sig) = status.signal() {
            128 + sig
        } else {
            1
        }
    }

    #[cfg(windows)]
    {
        status.code().unwrap_or(1)
    }
}
七、codecli 启动（runner/codecli.rs）
use tokio::process::{Command, Child};
use crate::{cli::Args, error::RunnerError};
use std::process::Stdio;

pub fn spawn(args: &Args) -> Result<Child, RunnerError> {
    let mut cmd = Command::new(&args.codecli_bin);
    cmd.args(&args.codecli_args)
        .stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .stderr(Stdio::piped());

    cmd.spawn().map_err(|e| RunnerError::Spawn(e.to_string()))
}
八、stdout / stderr 流式 tee（runner/tee.rs）
use tokio::io::{AsyncReadExt, AsyncWriteExt};
use tokio::task::JoinHandle;
use crate::{error::RunnerError, util::ring::RingBytes};
use std::sync::Arc;

pub fn pump_stdout<R>(rd: R, ring: Arc<RingBytes>) -> JoinHandle<Result<u64, RunnerError>>
where
    R: tokio::io::AsyncRead + Unpin + Send + 'static,
{
    pump(rd, tokio::io::stdout(), ring, "stdout")
}

pub fn pump_stderr<R>(rd: R, ring: Arc<RingBytes>) -> JoinHandle<Result<u64, RunnerError>>
where
    R: tokio::io::AsyncRead + Unpin + Send + 'static,
{
    pump(rd, tokio::io::stderr(), ring, "stderr")
}

fn pump<R, W>(
    mut rd: R,
    mut wr: W,
    ring: Arc<RingBytes>,
    label: &'static str,
) -> JoinHandle<Result<u64, RunnerError>>
where
    R: tokio::io::AsyncRead + Unpin + Send + 'static,
    W: tokio::io::AsyncWrite + Unpin + Send + 'static,
{
    tokio::spawn(async move {
        let mut buf = vec![0u8; 16 * 1024];
        let mut total = 0;

        loop {
            let n = rd.read(&mut buf).await
                .map_err(|e| RunnerError::StreamIo { stream: label, source: e })?;
            if n == 0 {
                break;
            }

            ring.push(&buf[..n]);
            wr.write_all(&buf[..n]).await
                .map_err(|e| RunnerError::StreamIo { stream: label, source: e })?;
            total += n as u64;
        }

        Ok(total)
    })
}
九、stdin 控制通道（runner/control.rs）
use tokio::io::AsyncWriteExt;
use serde::Serialize;

pub struct ControlChannel {
    stdin: tokio::process::ChildStdin,
}

impl ControlChannel {
    pub fn new(stdin: tokio::process::ChildStdin) -> Self {
        Self { stdin }
    }

    pub async fn send<T: Serialize>(&mut self, msg: &T) -> std::io::Result<()> {
        let line = serde_json::to_string(msg).unwrap();
        self.stdin.write_all(line.as_bytes()).await?;
        self.stdin.write_all(b"\n").await?;
        self.stdin.flush().await
    }
}
十、ToolEvent 协议骨架（protocol/tool_event.rs）
use serde::Deserialize;

#[derive(Debug, Deserialize)]
#[serde(tag = "type")]
pub enum ToolEvent {
    #[serde(rename = "tool.request")]
    Request {
        id: String,
        tool: String,
        params: serde_json::Value,
    },

    #[serde(rename = "tool.result")]
    Result {
        id: String,
        status: String,
        output: serde_json::Value,
    },
}
下一步你可以把 tee 的数据旁路喂给一个 行级 parser，只在检测到 JSON 行时尝试反序列化。

十一、Ring buffer（util/ring.rs）
use std::collections::VecDeque;
use std::sync::{Arc, Mutex};

#[derive(Clone)]
pub struct RingBytes {
    inner: Arc<Mutex<VecDeque<u8>>>,
    cap: usize,
}

impl RingBytes {
    pub fn new(cap: usize) -> Arc<Self> {
        Arc::new(Self {
            inner: Arc::new(Mutex::new(VecDeque::with_capacity(cap))),
            cap,
        })
    }

    pub fn push(&self, data: &[u8]) {
        let mut g = self.inner.lock().unwrap();
        for &b in data {
            if g.len() == self.cap {
                g.pop_front();
            }
            g.push_back(b);
        }
    }
}
十二、你现在已经拥有的能力
✅ 可启动 codecli
✅ stdout / stderr 完全真实透传
✅ 尾部 capture（为诊断 / gatekeeper）
✅ stdin JSONL 控制通道
✅ 跨平台 exit code 归一化

下一步建议（非常明确）
Step 1（强烈建议）

在 tee 后面接一个 ToolEventParser
实现 policy.decision allow / deny（哪怕先 hardcode）
Step 2

接 Memory search（你已有 OpenAPI）
把 search 结果注入 prompt（system prepend）
Step 3

Fail-Closed + Abort Sequence（你前面已经设计完）
如果你愿意，我下一条可以 直接给你补齐 ToolEventParser + PolicyEngine 的可运行代码（包含 stdin 拦截 + deny 示例）。

You:
下一步

ChatGPT:
[Unsupported Content]

ChatGPT:
[Unsupported Content]

ChatGPT:
下一步就把 “ToolEventParser + PolicyEngine + stdin 回写 decision” 这条闭环跑通（先不接记忆服务）。记忆服务对接会按你已有 OpenAPI（search/candidate/hit/validate/expire）继续扩展。fileciteturn0file6

下面给你一套 可运行的增强代码改动：

tee 仍然字节流透传
同时把 stdout/stderr 按行旁路到解析器
解析到 tool.request 就走 policy 决策
决策通过 stdin 控制通道发 policy.decision 回给 codecli
1）新增：protocol/policy_cmd.rs（stdin 控制协议）
use serde::Serialize;

#[derive(Debug, Serialize)]
pub struct PolicyDecisionCmd {
    pub v: u8,
    #[serde(rename = "type")]
    pub ty: &'static str,      // "policy.decision"
    pub ts: String,
    pub run_id: String,
    pub id: String,            // tool.request.id
    pub decision: &'static str, // "allow" | "deny"
    pub reason: String,
    pub rule_id: Option<String>,
}

impl PolicyDecisionCmd {
    pub fn allow(run_id: String, id: String, reason: String, rule_id: Option<String>) -> Self {
        Self {
            v: 1,
            ty: "policy.decision",
            ts: chrono::Utc::now().to_rfc3339(),
            run_id,
            id,
            decision: "allow",
            reason,
            rule_id,
        }
    }

    pub fn deny(run_id: String, id: String, reason: String, rule_id: Option<String>) -> Self {
        Self {
            v: 1,
            ty: "policy.decision",
            ts: chrono::Utc::now().to_rfc3339(),
            run_id,
            id,
            decision: "deny",
            reason,
            rule_id,
        }
    }
}
需要加依赖：chrono = { version = "0.4", features = ["serde"] }

2）新增：protocol/tool_event.rs（stdout JSONL 事件 + 解析器）
use serde::Deserialize;

pub const EVENT_PREFIX: &str = "@@MEM_TOOL_EVENT@@ ";

#[derive(Debug, Deserialize)]
pub struct BaseEnvelope {
    pub v: Option<u8>,
    #[serde(rename = "type")]
    pub ty: String,
    pub id: String,
}

#[derive(Debug, Deserialize)]
pub struct ToolRequestEvent {
    pub v: Option<u8>,
    #[serde(rename = "type")]
    pub ty: String, // "tool.request"
    pub ts: Option<String>,
    pub id: String,
    pub tool: String,
    pub action: Option<String>,
    pub args: serde_json::Value,
    pub requires_policy: Option<bool>,
    pub rationale: Option<String>,
}

#[derive(Debug)]
pub enum ToolEvent {
    Request(ToolRequestEvent),
    Other, // 未来扩展 tool.result/tool.progress
}

pub struct JsonlToolEventParser;

impl JsonlToolEventParser {
    pub fn parse_line(line: &str) -> Result<Option<ToolEvent>, serde_json::Error> {
        let s = if let Some(rest) = line.strip_prefix(EVENT_PREFIX) {
            rest
        } else {
            line
        };

        // 纯 JSON 行：必须包含 type 字段才当事件处理
        let env: BaseEnvelope = match serde_json::from_str(s) {
            Ok(v) => v,
            Err(_) => return Ok(None),
        };

        match env.ty.as_str() {
            "tool.request" => {
                let req: ToolRequestEvent = serde_json::from_str(s)?;
                Ok(Some(ToolEvent::Request(req)))
            }
            _ => Ok(Some(ToolEvent::Other)),
        }
    }
}
3）修改：runner/tee.rs（tee 同时旁路“行”到 channel）
关键点：tee 仍按 chunk 透传；旁路用一个小的 line_buf 把 chunk 拼接成行，按 \n 切割，Windows 兼容 \r\n。

use tokio::io::{AsyncReadExt, AsyncWriteExt};
use tokio::task::JoinHandle;
use crate::{error::RunnerError, util::ring::RingBytes};
use std::sync::Arc;
use tokio::sync::mpsc;

#[derive(Debug)]
pub struct LineTap {
    pub stream: &'static str, // "stdout" | "stderr"
    pub line: String,
}

pub fn pump_stdout<R>(
    rd: R,
    ring: Arc<RingBytes>,
    line_tx: mpsc::Sender<LineTap>,
) -> JoinHandle<Result<u64, RunnerError>>
where
    R: tokio::io::AsyncRead + Unpin + Send + 'static,
{
    pump(rd, tokio::io::stdout(), ring, "stdout", line_tx)
}

pub fn pump_stderr<R>(
    rd: R,
    ring: Arc<RingBytes>,
    line_tx: mpsc::Sender<LineTap>,
) -> JoinHandle<Result<u64, RunnerError>>
where
    R: tokio::io::AsyncRead + Unpin + Send + 'static,
{
    pump(rd, tokio::io::stderr(), ring, "stderr", line_tx)
}

fn pump<R, W>(
    mut rd: R,
    mut wr: W,
    ring: Arc<RingBytes>,
    label: &'static str,
    line_tx: mpsc::Sender<LineTap>,
) -> JoinHandle<Result<u64, RunnerError>>
where
    R: tokio::io::AsyncRead + Unpin + Send + 'static,
    W: tokio::io::AsyncWrite + Unpin + Send + 'static,
{
    tokio::spawn(async move {
        let mut buf = vec![0u8; 16 * 1024];
        let mut total = 0u64;

        // 行拼接缓冲（只用于旁路解析，不影响透传）
        let mut line_buf: Vec<u8> = Vec::with_capacity(8 * 1024);

        loop {
            let n = rd.read(&mut buf).await
                .map_err(|e| RunnerError::StreamIo { stream: label, source: e })?;
            if n == 0 { break; }

            ring.push(&buf[..n]);

            // 1) 透传
            wr.write_all(&buf[..n]).await
                .map_err(|e| RunnerError::StreamIo { stream: label, source: e })?;
            total += n as u64;

            // 2) 旁路按行投递
            line_buf.extend_from_slice(&buf[..n]);
            while let Some(pos) = line_buf.iter().position(|&b| b == b'\n') {
                let mut one = line_buf.drain(..=pos).collect::<Vec<u8>>();
                // 去掉末尾 \n
                if one.last() == Some(&b'\n') { one.pop(); }
                // 兼容 \r\n
                if one.last() == Some(&b'\r') { one.pop(); }

                // 不保证 UTF-8：尽力解析，失败用 lossy（只影响 parser，不影响透传）
                let line = String::from_utf8_lossy(&one).to_string();
                let _ = line_tx.send(LineTap { stream: label, line }).await;
            }
        }

        Ok(total)
    })
}
4）新增：policy（先 hardcode 一个 deny 例子）
新增 src/policy.rs：

use crate::protocol::tool_event::ToolRequestEvent;

pub struct PolicyEngine;

impl PolicyEngine {
    pub fn decide(req: &ToolRequestEvent) -> (&'static str, String, Option<String>) {
        // 示例：禁止 shell.exec / net.http，其他允许
        let tool = req.tool.as_str();
        if tool == "shell.exec" || tool == "net.http" {
            return ("deny", format!("{} is denied by default", tool), Some("deny.default".into()));
        }
        ("allow", "allowed by default".into(), Some("allow.default".into()))
    }
}
5）改造：runner/mod.rs（接入解析与 stdin 回写）
核心变化：

建立 line_tx/line_rx
建立一个 stdin writer（ControlChannel）只在一个 task 内写
line_rx 解析 tool.request → policy → 发送 decision cmd 给 stdin writer
mod codecli;
mod tee;
mod control;

use crate::{cli::Args, error::RunnerError};
use tokio::sync::mpsc;
use crate::protocol::{tool_event::JsonlToolEventParser, tool_event::ToolEvent};
use crate::protocol::policy_cmd::PolicyDecisionCmd;

pub async fn run(args: Args) -> Result<i32, RunnerError> {
    let mut child = codecli::spawn(&args)?;

    let stdout = child.stdout.take().unwrap();
    let stderr = child.stderr.take().unwrap();
    let stdin  = child.stdin.take().unwrap();

    let ring_out = crate::util::ring::RingBytes::new(args.capture_bytes);
    let ring_err = crate::util::ring::RingBytes::new(args.capture_bytes);

    // line tap channel
    let (line_tx, mut line_rx) = mpsc::channel::<tee::LineTap>(512);

    let out_task = tee::pump_stdout(stdout, ring_out.clone(), line_tx.clone());
    let err_task = tee::pump_stderr(stderr, ring_err.clone(), line_tx);

    // stdin control single-writer
    let (ctl_tx, mut ctl_rx) = mpsc::channel::<serde_json::Value>(128);
    let run_id = "r-001".to_string(); // 先固定，后续用 UUID

    let mut ctl = control::ControlChannel::new(stdin);
    let ctl_task = tokio::spawn(async move {
        while let Some(v) = ctl_rx.recv().await {
            // 失败直接结束（后续接 Fail-Closed + Abort Sequence）
            let _ = ctl.send(&v).await;
        }
    });

    // arbiter: parse tool.request -> policy -> send policy.decision
    let arb_task = tokio::spawn(async move {
        while let Some(tap) = line_rx.recv().await {
            if let Ok(Some(evt)) = JsonlToolEventParser::parse_line(&tap.line) {
                if let ToolEvent::Request(req) = evt {
                    let requires = req.requires_policy.unwrap_or(false);
                    if !requires {
                        continue;
                    }
                    let (decision, reason, rule_id) = crate::policy::PolicyEngine::decide(&req);
                    let cmd = if decision == "allow" {
                        PolicyDecisionCmd::allow(run_id.clone(), req.id.clone(), reason, rule_id)
                    } else {
                        PolicyDecisionCmd::deny(run_id.clone(), req.id.clone(), reason, rule_id)
                    };
                    let _ = ctl_tx.send(serde_json::to_value(cmd).unwrap()).await;
                }
            }
        }
    });

    let status = child.wait().await
        .map_err(|e| RunnerError::Spawn(e.to_string()))?;

    // 收尾
    arb_task.abort();
    drop(ctl_tx);
    ctl_task.abort();

    out_task.await.ok();
    err_task.await.ok();

    Ok(normalize_exit(status))
}

fn normalize_exit(status: std::process::ExitStatus) -> i32 {
    #[cfg(unix)]
    {
        use std::os::unix::process::ExitStatusExt;
        if let Some(code) = status.code() { code }
        else if let Some(sig) = status.signal() { 128 + sig }
        else { 1 }
    }
    #[cfg(windows)]
    { status.code().unwrap_or(1) }
}
别忘了在 src/lib 结构里把 policy 模块加进来：在 main.rs 同级 mod policy;。

6）依赖更新（Cargo.toml）
加上 chrono：

chrono = { version = "0.4", features = ["serde"] }
7）如何验证闭环
让 codecli 在“请求工具前”输出事件（示例）：
@@MEM_TOOL_EVENT@@ {"v":1,"type":"tool.request","id":"t-001","tool":"shell.exec","action":"exec","args":{"cmd":"rm -rf /"},"requires_policy":true}
mem-codecli 会把 policy.decision 写回 stdin：
{"v":1,"type":"policy.decision",...,"id":"t-001","decision":"deny",...}
前提：codecli 侧需要实现“收到 policy.decision 才继续执行工具”的等待逻辑；你这边 wrapper 已具备发送能力。

接下来你要选的“下一步（真正进展最大）”
我建议顺序是：

把 Fail-Closed + Abort Sequence 接上：

stdin 写失败、pending 超时、双通道 EOF 等直接 abort + kill（你前面已经定义好策略）
把 policy 做成可配置 allow/deny list（从 TOML 读）

再接 MemoryClient（按 OpenAPI：/v1/qa/search 等）fileciteturn0file6

你回一句：

“先做 Fail-Closed” 或
“先把 policy 配置化” 或
“直接接 memory search 注入”
我就按你选的方向继续把代码补齐到可编译可运行。
You:
把 Fail-Closed + Abort Sequence 接上/把 policy 做成可配置 allow/deny list/再接 MemoryClient

ChatGPT:
[Unsupported Content]

ChatGPT:
[Unsupported Content]

ChatGPT:
下面我直接把你点的三件事 一次性落到可编译的代码骨架（按你现有 MVP 工程结构增量扩展），实现顺序是：

Fail-Closed + Abort Sequence（含 pending decision 超时 / stdin 断线）
Policy 可配置 allow/deny list（TOML）
接 MemoryClient（HTTP：search/hit/candidate/validate，先用最小字段模型，响应用 serde_json::Value 兜底）
你照着把这些文件加进去、Cargo.toml 补依赖，就能跑；后续再把 “codecli 侧等待审批” 与 “更严格协议” 细化即可。

0）Cargo.toml 增量依赖
在你现有依赖基础上追加：

reqwest = { version = "0.12", features = ["json", "rustls-tls"] }
toml = "0.8"
uuid = { version = "1.8", features = ["v4"] }
chrono = { version = "0.4", features = ["serde"] }
1）配置：src/config.rs（TOML + 环境变量覆盖最小实现）
支持：

--config <path>（你可后面补到 CLI）
默认读取：./.mem-codecli.toml（存在则用，否则仅 env/默认）
env 覆盖：MEM_CODECLI_PROJECT_ID、MEM_CODECLI_MEMORY_URL、MEM_CODECLI_MEMORY_API_KEY
use serde::{Deserialize, Serialize};
use std::path::Path;

#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct AppConfig {
    pub project_id: String,

    #[serde(default)]
    pub control: ControlConfig,

    #[serde(default)]
    pub policy: PolicyConfig,

    #[serde(default)]
    pub memory: MemoryConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ControlConfig {
    #[serde(default = "default_fail_mode")]
    pub fail_mode: String, // "closed" | "open"

    #[serde(default = "default_decision_timeout_ms")]
    pub decision_timeout_ms: u64,

    #[serde(default = "default_abort_grace_ms")]
    pub abort_grace_ms: u64,
}

fn default_fail_mode() -> String { "closed".to_string() }
fn default_decision_timeout_ms() -> u64 { 300_000 }
fn default_abort_grace_ms() -> u64 { 5_000 }

impl Default for ControlConfig {
    fn default() -> Self {
        Self {
            fail_mode: default_fail_mode(),
            decision_timeout_ms: default_decision_timeout_ms(),
            abort_grace_ms: default_abort_grace_ms(),
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct PolicyConfig {
    #[serde(default)]
    pub mode: String, // "off" | "auto" | "prompt"（本轮先实现 auto/off）

    #[serde(default)]
    pub default_action: String, // "allow" | "deny"

    #[serde(default)]
    pub allowlist: Vec<PolicyRule>,

    #[serde(default)]
    pub denylist: Vec<PolicyRule>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PolicyRule {
    pub tool: String,             // 支持前缀或 "*" 通配（简单版）
    #[serde(default)]
    pub action: Option<String>,   // read|write|net|exec
    #[serde(default)]
    pub reason: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct MemoryConfig {
    #[serde(default)]
    pub enabled: bool,
    #[serde(default)]
    pub base_url: String,
    #[serde(default)]
    pub api_key: String,
    #[serde(default = "default_timeout_ms")]
    pub timeout_ms: u64,

    // search defaults
    #[serde(default = "default_search_limit")]
    pub search_limit: u32,
    #[serde(default = "default_min_score")]
    pub min_score: f32,
}

fn default_timeout_ms() -> u64 { 10_000 }
fn default_search_limit() -> u32 { 6 }
fn default_min_score() -> f32 { 0.2 }

pub fn load_default() -> anyhow::Result<AppConfig> {
    let mut cfg = if Path::new(".mem-codecli.toml").exists() {
        let s = std::fs::read_to_string(".mem-codecli.toml")?;
        toml::from_str::<AppConfig>(&s)?
    } else {
        AppConfig::default()
    };

    // env overrides (minimal)
    if let Ok(v) = std::env::var("MEM_CODECLI_PROJECT_ID") {
        if !v.trim().is_empty() { cfg.project_id = v; }
    }
    if let Ok(v) = std::env::var("MEM_CODECLI_MEMORY_URL") {
        if !v.trim().is_empty() { cfg.memory.base_url = v; }
    }
    if let Ok(v) = std::env::var("MEM_CODECLI_MEMORY_API_KEY") {
        if !v.trim().is_empty() { cfg.memory.api_key = v; }
    }

    Ok(cfg)
}
你需要在 Cargo.toml 里加 anyhow = "1.0"（或者把 Result 改成你自己的 error）。如果不想引入 anyhow，我也可以给你改成 thiserror 全量化；这里先用最省事的方式把功能跑通。

2）Policy：可配置 allow/deny list（src/policy.rs）
规则：

denylist 命中优先
allowlist 次之
否则 default_action（建议默认 deny，更安全）
匹配：

tool="fs.read"：前缀匹配（starts_with）
tool="*"：全匹配
action 若配置了必须一致
use crate::config::{PolicyConfig, PolicyRule};
use crate::protocol::tool_event::ToolRequestEvent;

#[derive(Clone)]
pub struct PolicyEngine {
    cfg: PolicyConfig,
}

#[derive(Debug)]
pub struct PolicyDecision {
    pub decision: &'static str, // "allow" | "deny"
    pub reason: String,
    pub rule_id: Option<String>,
}

impl PolicyEngine {
    pub fn new(cfg: PolicyConfig) -> Self { Self { cfg } }

    pub fn decide(&self, req: &ToolRequestEvent) -> PolicyDecision {
        if self.cfg.mode == "off" {
            return PolicyDecision {
                decision: "allow",
                reason: "policy off".into(),
                rule_id: Some("policy.off".into()),
            };
        }

        // deny first
        if let Some((idx, rule)) = find_match(&self.cfg.denylist, req) {
            return PolicyDecision {
                decision: "deny",
                reason: rule.reason.clone().unwrap_or_else(|| "denied by rule".into()),
                rule_id: Some(format!("denylist[{}]", idx)),
            };
        }

        if let Some((idx, rule)) = find_match(&self.cfg.allowlist, req) {
            return PolicyDecision {
                decision: "allow",
                reason: rule.reason.clone().unwrap_or_else(|| "allowed by rule".into()),
                rule_id: Some(format!("allowlist[{}]", idx)),
            };
        }

        // default
        let d = self.cfg.default_action.as_str();
        if d == "allow" {
            PolicyDecision { decision: "allow", reason: "allowed by default_action".into(), rule_id: Some("default.allow".into()) }
        } else {
            PolicyDecision { decision: "deny", reason: "denied by default_action".into(), rule_id: Some("default.deny".into()) }
        }
    }
}

fn find_match<'a>(rules: &'a [PolicyRule], req: &ToolRequestEvent) -> Option<(usize, &'a PolicyRule)> {
    for (i, r) in rules.iter().enumerate() {
        if !tool_match(&r.tool, &req.tool) { continue; }
        if let Some(a) = &r.action {
            let ra = a.as_str();
            let qa = req.action.as_deref().unwrap_or("");
            if ra != qa { continue; }
        }
        return Some((i, r));
    }
    None
}

fn tool_match(pat: &str, tool: &str) -> bool {
    if pat == "*" { return true; }
    if pat.ends_with('*') {
        let prefix = pat.trim_end_matches('*');
        return tool.starts_with(prefix);
    }
    tool.starts_with(pat)
}
3）MemoryClient：src/memory.rs（最小 HTTP 接驳）
先把响应体用 serde_json::Value 兜底（因为你当前 OpenAPI 返回 schema 片段不完整/服务可能自定义字段）
请求结构按你之前讨论的字段命名：project_id/query/limit/min_score、references[]、question/answer/tags/confidence/metadata 等
use serde::{Deserialize, Serialize};
use serde_json::Value;

#[derive(Clone)]
pub struct MemoryClient {
    base_url: String,
    api_key: String,
    http: reqwest::Client,
}

impl MemoryClient {
    pub fn new(base_url: String, api_key: String, timeout_ms: u64) -> anyhow::Result<Self> {
        let http = reqwest::Client::builder()
            .timeout(std::time::Duration::from_millis(timeout_ms))
            .build()?;
        Ok(Self { base_url, api_key, http })
    }

    fn auth(&self, req: reqwest::RequestBuilder) -> reqwest::RequestBuilder {
        if self.api_key.trim().is_empty() {
            req
        } else {
            // 你们服务端如果不是 Bearer，可改这里
            req.bearer_auth(&self.api_key)
        }
    }

    pub async fn search(&self, payload: QASearchPayload) -> anyhow::Result<Value> {
        let url = format!("{}/v1/qa/search", self.base_url.trim_end_matches('/'));
        let req = self.http.post(url).json(&payload);
        let resp = self.auth(req).send().await?;
        let v = resp.json::<Value>().await?;
        Ok(v)
    }

    pub async fn hit(&self, payload: QAHitsPayload) -> anyhow::Result<Value> {
        let url = format!("{}/v1/qa/hit", self.base_url.trim_end_matches('/'));
        let req = self.http.post(url).json(&payload);
        Ok(self.auth(req).send().await?.json::<Value>().await?)
    }

    pub async fn candidate(&self, payload: QACandidatePayload) -> anyhow::Result<Value> {
        let url = format!("{}/v1/qa/candidates", self.base_url.trim_end_matches('/'));
        let req = self.http.post(url).json(&payload);
        Ok(self.auth(req).send().await?.json::<Value>().await?)
    }

    pub async fn validate(&self, payload: QAValidationPayload) -> anyhow::Result<Value> {
        let url = format!("{}/v1/qa/validate", self.base_url.trim_end_matches('/'));
        let req = self.http.post(url).json(&payload);
        Ok(self.auth(req).send().await?.json::<Value>().await?)
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QASearchPayload {
    pub project_id: String,
    pub query: String,
    pub limit: u32,
    pub min_score: f32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QAReferencePayload {
    pub qa_id: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub shown: Option<bool>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub used: Option<bool>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub message_id: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub context: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QAHitsPayload {
    pub project_id: String,
    pub references: Vec<QAReferencePayload>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QACandidatePayload {
    pub project_id: String,
    pub question: String,
    pub answer: String,

    #[serde(default, skip_serializing_if = "Vec::is_empty")]
    pub tags: Vec<String>,

    #[serde(default)]
    pub confidence: f32,

    #[serde(default)]
    pub metadata: Value,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub summary: Option<String>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub source: Option<String>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub author: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QAValidationPayload {
    pub project_id: String,
    pub qa_id: String,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub result: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub signal_strength: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub success: Option<bool>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub strong_signal: Option<bool>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub source: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub context: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub client: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub ts: Option<String>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub payload: Option<Value>,
}
这里同样用了 anyhow：加 anyhow = "1.0" 最省事。

4）Fail-Closed + Abort Sequence：runner/mod.rs 改造（关键）
实现要点（MVP 版）：

stdin writer 失败：如果 fail_mode=closed → 立刻 abort（kill 子进程）
pending decision 超时：abort
abort sequence：优先发 policy.abort（如果还能写），等待 grace，再 child.kill()
仍保留 stdout/stderr 透传和 ring capture
4.1 protocol/policy_cmd.rs 增加 abort 命令
use serde::Serialize;

#[derive(Debug, Serialize)]
pub struct PolicyAbortCmd {
    pub v: u8,
    #[serde(rename = "type")]
    pub ty: &'static str, // "policy.abort"
    pub ts: String,
    pub run_id: String,
    pub id: String,       // e.g. "abort-1"
    pub reason: String,
    pub code: Option<String>,
}

impl PolicyAbortCmd {
    pub fn new(run_id: String, reason: String, code: Option<String>) -> Self {
        Self {
            v: 1,
            ty: "policy.abort",
            ts: chrono::Utc::now().to_rfc3339(),
            run_id,
            id: "abort-1".into(),
            reason,
            code,
        }
    }
}
4.2 runner/mod.rs：引入 pending 表 + 超时检测 + abort
下面是“核心可运行版本”，你可以直接替换你当前的 runner/mod.rs（保留 normalize_exit）：

mod codecli;
mod tee;
mod control;

use crate::{cli::Args, error::RunnerError};
use tokio::sync::mpsc;
use std::collections::HashMap;
use std::time::{Duration, Instant};

use crate::protocol::tool_event::{JsonlToolEventParser, ToolEvent};
use crate::protocol::policy_cmd::{PolicyDecisionCmd, PolicyAbortCmd};

pub async fn run(args: Args) -> Result<i32, RunnerError> {
    let cfg = crate::config::load_default().map_err(|e| RunnerError::Spawn(e.to_string()))?;

    let mut child = codecli::spawn(&args)?;

    let stdout = child.stdout.take().unwrap();
    let stderr = child.stderr.take().unwrap();
    let stdin  = child.stdin.take().unwrap();

    let ring_out = crate::util::ring::RingBytes::new(args.capture_bytes);
    let ring_err = crate::util::ring::RingBytes::new(args.capture_bytes);

    // line taps
    let (line_tx, mut line_rx) = mpsc::channel::<tee::LineTap>(1024);
    let out_task = tee::pump_stdout(stdout, ring_out.clone(), line_tx.clone());
    let err_task = tee::pump_stderr(stderr, ring_err.clone(), line_tx);

    // control channel single writer
    let (ctl_tx, mut ctl_rx) = mpsc::channel::<serde_json::Value>(128);
    let run_id = uuid::Uuid::new_v4().to_string();

    let mut ctl = control::ControlChannel::new(stdin);
    let fail_closed = cfg.control.fail_mode.as_str() == "closed";

    // writer task：失败要上报
    let (writer_err_tx, mut writer_err_rx) = mpsc::channel::<String>(1);
    let ctl_task = tokio::spawn(async move {
        while let Some(v) = ctl_rx.recv().await {
            if let Err(e) = ctl.send(&v).await {
                let _ = writer_err_tx.send(format!("stdin write failed: {}", e)).await;
                break;
            }
        }
    });

    let policy = crate::policy::PolicyEngine::new(cfg.policy.clone());

    // pending decisions: id -> created_at
    let mut pending: HashMap<String, Instant> = HashMap::new();
    let decision_timeout = Duration::from_millis(cfg.control.decision_timeout_ms);

    // 监控计时器：每 1s 检查 pending 超时
    let mut tick = tokio::time::interval(Duration::from_millis(1000));

    // 主循环：同时处理 line_rx、writer_err、timeout、child exit
    let wait_fut = child.wait();
    tokio::pin!(wait_fut);

    loop {
        tokio::select! {
            // 子进程退出
            status = &mut wait_fut => {
                let status = status.map_err(|e| RunnerError::Spawn(e.to_string()))?;
                // 收尾
                drop(ctl_tx);
                ctl_task.abort();
                out_task.abort();
                err_task.abort();
                return Ok(normalize_exit(status));
            }

            // stdin 写失败
            maybe_err = writer_err_rx.recv() => {
                if let Some(msg) = maybe_err {
                    tracing::error!(error.kind="control.stdin_broken", error.message=%msg);
                    if fail_closed {
                        abort_sequence(&mut child, &ctl_tx, &run_id, cfg.control.abort_grace_ms, "control channel broken").await;
                        return Ok(40);
                    } else {
                        // fail-open：只告警，不中止
                        tracing::warn!("control channel broken, continuing in fail-open mode");
                    }
                }
            }

            // line 事件
            tap = line_rx.recv() => {
                if let Some(tap) = tap {
                    if let Ok(Some(evt)) = JsonlToolEventParser::parse_line(&tap.line) {
                        if let ToolEvent::Request(req) = evt {
                            let requires = req.requires_policy.unwrap_or(false);
                            if !requires { continue; }

                            pending.insert(req.id.clone(), Instant::now());

                            let d = policy.decide(&req);
                            let cmd = if d.decision == "allow" {
                                PolicyDecisionCmd::allow(run_id.clone(), req.id.clone(), d.reason, d.rule_id)
                            } else {
                                PolicyDecisionCmd::deny(run_id.clone(), req.id.clone(), d.reason, d.rule_id)
                            };

                            // 发送 decision
                            let _ = ctl_tx.send(serde_json::to_value(cmd).unwrap()).await;

                            // 本实现：decision 发出就从 pending 移除（更严格可等 ack）
                            pending.remove(&req.id);
                        }
                    }
                } else {
                    // line_rx closed：双通道都结束通常意味着子进程即将退出；这里不强行 abort
                }
            }

            // 超时检测
            _ = tick.tick() => {
                let now = Instant::now();
                let mut timed_out: Vec<String> = Vec::new();
                for (id, t0) in pending.iter() {
                    if now.duration_since(*t0) > decision_timeout {
                        timed_out.push(id.clone());
                    }
                }
                if !timed_out.is_empty() {
                    tracing::error!(error.kind="control.decision_timeout", ids=?timed_out);
                    if fail_closed {
                        abort_sequence(&mut child, &ctl_tx, &run_id, cfg.control.abort_grace_ms, "decision timeout").await;
                        return Ok(40);
                    }
                }
            }
        }
    }
}

async fn abort_sequence(
    child: &mut tokio::process::Child,
    ctl_tx: &mpsc::Sender<serde_json::Value>,
    run_id: &str,
    abort_grace_ms: u64,
    reason: &str,
) {
    // best-effort send policy.abort
    let abort = PolicyAbortCmd::new(run_id.to_string(), reason.to_string(), Some("policy_violation".into()));
    let _ = ctl_tx.send(serde_json::to_value(abort).unwrap()).await;

    // wait grace
    tokio::time::sleep(Duration::from_millis(abort_grace_ms)).await;

    // force kill (cross-platform)
    let _ = child.kill().await;
}

fn normalize_exit(status: std::process::ExitStatus) -> i32 {
    #[cfg(unix)]
    {
        use std::os::unix::process::ExitStatusExt;
        if let Some(code) = status.code() { code }
        else if let Some(sig) = status.signal() { 128 + sig }
        else { 1 }
    }
    #[cfg(windows)]
    {
        status.code().unwrap_or(1)
    }
}
说明：这版 abort 使用 child.kill()（跨平台且简单）。如果你要严格实现 Unix 的 TERM→KILL、Windows 的 CTRL_BREAK_EVENT，我可以在下一步把信号转发层按 cfg(unix/windows) 补齐到“严格版”。

5）接 MemoryClient：先把“search→注入→run”链路打通（最小集成点）
这一步我们先做“能调用 search 并打印返回”，不强塞进 prompt（避免你 codecli 参数格式不确定）。等你确认 codecli 的“system prompt 注入方式”后，再把注入做成可配置模板。

在 runner/mod.rs 开头加载 cfg 后加：

let memory = if cfg.memory.enabled && !cfg.memory.base_url.trim().is_empty() {
    Some(crate::memory::MemoryClient::new(
        cfg.memory.base_url.clone(),
        cfg.memory.api_key.clone(),
        cfg.memory.timeout_ms,
    ).map_err(|e| RunnerError::Spawn(e.to_string()))?)
} else { None };
然后在启动子进程前（或刚启动后）做一次 search（示例：用用户输入拼 query，你现在还没把用户输入单独传进来，先用固定占位）：

if let Some(mem) = &memory {
    let payload = crate::memory::QASearchPayload {
        project_id: cfg.project_id.clone(),
        query: "bootstrap query".to_string(),
        limit: cfg.memory.search_limit,
        min_score: cfg.memory.min_score,
    };
    if let Ok(v) = mem.search(payload).await {
        tracing::info!(action="memory.search", resp=%v);
    }
}
下一步你把 query 换成：用户本次输入 + session_file 摘要；然后把结果按模板 prepend 到 codecli 的 system prompt（你前面已经定义过注入策略）。

6）示例配置：.mem-codecli.toml
放到项目根目录：

project_id = "my-project"

[control]
fail_mode = "closed"
decision_timeout_ms = 300000
abort_grace_ms = 5000

[policy]
mode = "auto"
default_action = "deny"

denylist = [
  { tool = "shell.exec", action = "exec", reason = "shell is denied by default" },
  { tool = "net.http", action = "net", reason = "network is denied by default" },
]

allowlist = [
  { tool = "fs.read", action = "read", reason = "read is allowed" },
  { tool = "git.*", reason = "git commands allowed" }
]

[memory]
enabled = true
base_url = "https://memory.internal"
api_key = ""
timeout_ms = 10000
search_limit = 6
min_score = 0.2
7）你现在得到的“下一步”成果
完成上述增量后，你的 wrapper 已具备：

Policy 配置化（allow/deny + default_action）
Fail-Closed（stdin 写失败 / decision 超时 直接 abort）
Abort Sequence（policy.abort + grace + kill）
MemoryClient 已接入（search/hit/candidate/validate 可调用）
仍保持 stdout/stderr 完全透传 与 ring capture
我建议你接下来立刻做的两件“小而关键”的收口
把 codecli 侧的 tool.request 输出接上（带 requires_policy=true），确认 decision 能被读取并阻断执行。
把 memory.search 的结果先 落到日志，确认字段结构；再决定注入模板与 hit 回传（shown/used）规则。
你如果把 codecli 当前输出的 tool.request JSONL 样例贴一条，我可以把 ToolRequestEvent 的字段名（tool/action/args 等）对齐到完全一致，避免解析漂移。

You:
怎么获取tool.request JSONL

ChatGPT:
获取 tool.request JSONL 本质上取决于：codecli（或其底层 agent runtime）是否已经“会吐结构化工具事件”。你这边的 mem-codecli 只能“读 stdout/stderr 并解析”，不能凭空生成事件。所以做法分三档：优先用现成能力；没有就通过约定/补丁让它输出。

下面给你一套最实用的路径（从易到难），以及你应该让 codecli 输出的最小 JSONL 长什么样。

1）先确认：codecli 现在是否已有工具事件输出能力
最直接的方法：

开最大日志/调试输出（如果 codecli 支持类似 --debug/--trace/--verbose）
跑一个明确会触发工具的任务（例如读文件、执行 git、网络请求）
看 stdout/stderr 里是否已经出现：
JSON 行（以 { 开头）
或带固定 marker（比如 “tool call”、“function call”、“MCP”等）
如果有，优先“适配现有格式”，不要自己造新协议。

2）如果没有：你需要让 codecli 在“工具调用边界”打印 JSONL
你要找的就是：工具调度器那一层（Tool Router / MCP Client / function-calling executor）：

在“准备调用工具之前”打印 tool.request
在“工具执行结束之后”打印 tool.result
如果工具会耗时，期间可以打印 tool.progress
最小可用 tool.request（一行 JSONL）
下面是你应该让 codecli 输出的一行（建议加前缀，降低误判）：

@@MEM_TOOL_EVENT@@ {"v":1,"type":"tool.request","ts":"2025-12-26T22:00:00-05:00","id":"t-001","tool":"fs.read","action":"read","args":{"path":"README.md"},"requires_policy":true,"rationale":"Need repo overview."}
字段说明：

v：版本（固定 1）
type：固定 "tool.request"
id：本次工具调用唯一 id（建议 uuid 或单调序号）
tool：工具名（建议稳定、可匹配 allow/deny）
action：read/write/net/exec（用于策略分级）
args：工具参数（JSON）
requires_policy：true 表示 codecli 必须等 stdin policy.decision 才能执行
rationale：可选，给审计/交互提示用
如果你不加 @@MEM_TOOL_EVENT@@ 前缀也行，但更容易误把普通 JSON 当事件。

3）具体改哪里：三种常见集成位置（你按你的 codecli 架构选）
A. codecli 自己有 Tool Router（最理想）
在 router 的执行函数里加两处日志：

before call:
print tool.request JSONL
如果 requires_policy=true，进入等待读取 stdin decision
after call:
print tool.result JSONL
B. codecli 用 MCP server / tools 框架
如果 codecli 是通过 MCP 协议调用工具：

在发起 MCP request 前打印 tool.request
MCP response 回来后打印 tool.result
tool 可以用 mcp.<server>.<tool_name> 或更短的稳定映射
C. codecli 直接调用 OpenAI/Anthropic function calling
function call 事件一般能在 SDK 层拿到：

模型输出 function name + arguments 时打印 tool.request
实际执行函数后打印 tool.result
4）如果你暂时改不了 codecli：用“文本模式降级”（不推荐，但能跑）
你可以让 codecli 在工具调用前打印一行形如：

TOOL_REQUEST name=fs.read action=read args={"path":"README.md"} requires_policy=true
然后 mem-codecli 用正则解析生成内部 tool.request。

缺点：

容易漂移（格式变了就坏）
args 里有空格/转义会难处理
审计一致性差
所以建议把这当“过渡方案”。

5）你需要 codecli 同时实现的另一半：读取 stdin 的 policy.decision
你已经在 mem-codecli 侧会写：

{"v":1,"type":"policy.decision","ts":"...","run_id":"...","id":"t-001","decision":"deny","reason":"...","rule_id":"..."}
codecli 侧要做：

如果 requires_policy=true：
在执行工具前阻塞等待 stdin
读到匹配 id 的 decision 才继续
deny → 输出 tool.result(ok=false) 或直接失败返回
6）给你一个“立即可用的验证办法”（无需真实工具系统）
为了快速验证链路，你可以在 codecli 任意位置临时插入：

输出 tool.request JSONL（requires_policy=true）
然后等待 stdin 一行 JSON
打印收到的内容并退出
这样你能立刻确认 mem-codecli 的：

stdout 解析
policy 判定
stdin 回写
你现在需要做的最小动作
你告诉我：你用的 codecli 是哪一种（或贴一段“工具调用的代码/模块路径”）：

是你自研的 codecli？
还是基于某个现成 CLI（比如 codex/claude/gemini 的 wrapper）？
工具调用是走 MCP 还是 function calling？
我就能把“应该插入 tool.request 的具体位置”和“等待 policy.decision 的最小实现”写成你项目里的补丁方案（按你当前语言/架构）。

You:
codex/claude/gemini/MCP

ChatGPT:
[Unsupported Content]

ChatGPT:
[Unsupported Content]

ChatGPT:
你这个组合（codex / claude / gemini + MCP）里，最可靠、最通用的答案是：

不要指望 codex/claude/gemini CLI 一定会主动输出 tool.request JSONL。
你要把 tool.request 的“事件源”放到 MCP 边界（你可控的那层）去生成。

下面按可落地程度从高到低给你 3 种方案（建议直接选方案 A）。

方案 A（推荐）：在 MCP Server 侧生成 tool.request JSONL（100%可控）
适用：codex/claude/gemini 通过 MCP 调工具（这是你写 “+ MCP” 的典型情况）。

做法
你实现/改造你自己的 MCP Server（或在现有 MCP Server 外包一层“网关”）：

MCP Server 收到 tools/call（即将执行工具）时：
立刻往 stdout 打一行：
@@MEM_TOOL_EVENT@@ { ... "type":"tool.request", ... }
如果要做到真正“阻断执行”：
MCP Server 不立即执行工具，而是等待外部 policy.decision
等到允许再执行，拒绝就返回错误
工具执行结束：
输出 tool.result JSONL（同 id）
优点
和 codex/claude/gemini 无关；只要它们用 MCP，都能工作。
你甚至可以不改 codecli：审批在 MCP server 内完成。
关键点（非常重要）
如果你把审批放在 MCP Server 内，那么：

mem-codecli 的 stdin 控制协议就不一定需要给 codecli 了
你可以让 MCP Server 自己有一个控制输入（比如它自己的 stdin / socket）
或者更简单：MCP Server 读取一个本地 policy 配置直接 allow/deny（先跑通）
结论：MCP Server 是最“工程正确”的 tool.request 产生点。

方案 B：做一个 MCP “网关/代理”拦截（不改现有 MCP 工具实现）
适用：你已经有一堆现成 MCP server（文件系统、git、db…），不想动它们。

做法
让模型只连接到 你的 Gateway MCP Server（它对外暴露同名工具）：

Gateway 收到 tools/call
→ 输出 tool.request JSONL
→ 等 policy.decision（或本地 policy）
→ 再把请求转发给真实 MCP server
→ 把响应回传给模型
→ 输出 tool.result
优点
不改下游工具 server
可以统一审计、统一脱敏、统一限流/超时
缺点
需要维护“工具列表镜像/转发”逻辑（但这是一次性工作）
方案 C：尝试从 codex/claude/gemini CLI 的 debug 日志“解析”出工具调用（不推荐）
原因很简单：

输出格式不稳定（版本一升级就漂）
很多 CLI 不会把 tool call 结构化打印出来
即使有日志，也往往是“事后”打印，无法用于“审批前阻断”
所以：这条路最多用于临时观测，不适合你要的严格 Policy + Fail-Closed。

你要的 tool.request JSONL：最小字段（通用）
无论你选 A 还是 B，在“工具将执行前”打印这一行（建议加前缀）：

@@MEM_TOOL_EVENT@@ {"v":1,"type":"tool.request","ts":"2025-12-26T22:00:00-05:00","id":"t-001","tool":"fs.read","action":"read","args":{"path":"README.md"},"requires_policy":true,"rationale":"Need repo overview."}
然后在执行结束打印：

@@MEM_TOOL_EVENT@@ {"v":1,"type":"tool.result","ts":"2025-12-26T22:00:01-05:00","id":"t-001","ok":true,"output":{"bytes":1234}}
针对你列的四个关键词分别怎么落
MCP（最优先）
直接在 MCP Server（或 Gateway）实现事件输出和审批等待
这是唯一“你完全掌控、能稳定阻断”的点
Claude
Claude Desktop/CLI 的工具生态本质上也是“外部工具 endpoint”
只要 Claude 走 MCP：用方案 A/B 即可
不需要 Claude 自己输出 tool.request
Gemini
同上：只要 Gemini CLI/Agent 走 MCP，把拦截放在 MCP 边界即可
Codex
同上：不强依赖 codex 是否输出事件
MCP 网关能统一拿到工具调用边界
你下一步该做什么（最短路径）
先做 方案 A 的最小版 MCP Server（或在你已有 MCP server 里加 middleware）：
收到 tools/call → print tool.request JSONL
先不做审批等待，直接执行并打印 tool.result（先把事件链路跑通）
再加审批：
从本地 policy（allow/deny list）直接判定（先不做交互）
deny 时返回 MCP error，并打印 tool.result(ok=false)
最后再接 mem-codecli 的 stdin 控制协议（如果你仍希望 wrapper 统一仲裁）
如果你告诉我：你现在的 MCP server 是 stdio 模式还是 HTTP 模式，以及你用的 MCP 实现库（Python/Rust/TS 哪个），我可以把“拦截 tools/call 输出 JSONL + 等 policy.decision”的代码骨架按你栈直接给出来（含字段映射与错误码）。

You:
暂时放弃审批，整理信息

ChatGPT:
下面是在“暂时放弃审批（Policy / Gatekeeper）”前提下，对你当前方案的一次完整收口整理。目标是：

保留正确的架构方向
明确哪些东西先冻结、哪些继续推进
形成一个稳定、可运行、可演进的最小系统（MVP）
你可以直接把这份作为 STATUS.md / DESIGN-SNAPSHOT.md 使用。

mem-codecli（无审批阶段）设计整理
一、当前决策状态（结论先行）
阶段性决策：

✅ 保留：mem-codecli 作为 Rust wrapper
✅ 保留：stdout / stderr 流式 tee
✅ 保留：ToolEvent（tool.request / tool.result）采集
✅ 保留：MemoryClient（search / hit / candidate / validate）
❌ 暂停：Policy / 审批 / stdin 阻断 / Fail-Closed
❌ 暂停：Gatekeeper 质量闸门
当前系统定位：
“只观察、不干预”的记忆增强执行壳（Observer Mode）

二、当前系统角色重定义（非常重要）
mem-codecli 在当前阶段只做 4 件事
真实运行 codecli

不改变其行为
不阻断任何工具
完整透传 stdout / stderr

用户体验 = 原生 codecli
CI 行为不变
采集 ToolEvent（来自 MCP 边界）

tool.request
tool.result
tool.progress（可选）
与 Memory 服务交互

search：运行前检索
hit：使用后回传
candidate：会话后沉淀
validate：离线质量反馈（后续）
三、事件来源统一策略（关键澄清）
不再依赖 codex / claude / gemini CLI 自身
你已经确认使用：

codex / claude / gemini
统一通过 MCP 调工具
👉 ToolEvent 的唯一可信来源：MCP 边界

结论
tool.request / tool.result 必须在 MCP Server（或 MCP Gateway）处生成

mem-codecli 的职责只是：

从 stdout/stderr 中 识别并解析 JSONL 事件
不关心这些事件是谁打印的
四、当前 ToolEvent 协议（冻结版 v1）
推荐打印格式（强烈建议保留前缀）
@@MEM_TOOL_EVENT@@ {"v":1,"type":"tool.request","ts":"2025-12-26T22:00:00Z","id":"t-001","tool":"fs.read","action":"read","args":{"path":"README.md"}}
@@MEM_TOOL_EVENT@@ {"v":1,"type":"tool.result","ts":"2025-12-26T22:00:01Z","id":"t-001","ok":true,"output":{"bytes":1234}}
事件字段说明（最小稳定集）
字段	说明
v	协议版本（固定 1）
type	tool.request / tool.result
id	工具调用唯一 ID
tool	稳定工具名（用于统计 / 记忆）
action	可选（read/write/net/exec）
args	请求参数
ok	result 是否成功
output	结果摘要
⚠️ requires_policy / decision / policy.* 字段 暂时不用

五、mem-codecli 当前模块职责（冻结）
1. Runner（必须稳定）
启动子进程
stdout / stderr 流式 tee
ring buffer capture（用于诊断）
统一 exit code
不做：

不写 stdin
不控制进程行为
2. ToolEventParser（只读）
从 stdout/stderr 的行流中解析 JSONL
失败即忽略，不影响执行
只要能解析出 event，就发给上层
3. MemoryClient（当前主角）
search（运行前）
输入：用户 query / task 描述
输出：QA 列表
用途：构造 system prompt（下一阶段）
hit（运行中 / 运行后）
记录哪些 QA 被展示 / 被使用
不影响执行
candidate（运行后）
从完整会话中抽取 Q/A
写入候选池
validate（离线）
通过 CI / 人工信号反馈质量
六、当前执行流程（Observer Mode）
┌──────────────┐
│ User / CI    │
└──────┬───────┘
       │
┌──────▼─────────────┐
│ mem-codecli        │
│                    │
│ ① memory.search    │
│    (log only)      │
│        │           │
│ ② run codecli      │
│    │               │
│    ├─ stdout tee ─────────► 用户
│    ├─ stderr tee ─────────► 用户
│    │
│    └─ parse ToolEvent
│           │
│ ③ collect context   │
│        │           │
│ ④ memory.candidate │
│ ⑤ memory.hit       │
└────────────────────┘
七、被明确暂停的能力（避免未来混乱）
以下内容暂时不进入代码主干：

stdin 控制协议
policy.decision / policy.abort
Fail-Closed / Abort Sequence
pending decision / timeout
Gatekeeper 评分 / 去重 / 安全检查
原则：
观察系统 ≠ 控制系统
现在先把“观察”做到稳定、可信、可回放。

八、你现在应该继续推进的三件事（明确）
1️⃣ MCP Server / Gateway：稳定输出 ToolEvent
这是整个系统的根基：

所有工具调用都能被观测
事件字段稳定、可回放
没有这一层，后面所有策略、记忆、审计都是空中楼阁。

2️⃣ Memory.search → Prompt 注入（下一步重点）
当前你已经：

能 search
能拿到返回 JSON
接下来要做的是：

设计 search → prompt 的注入模板
明确：
system 还是 user
放多少条
如何标记 [QA_REF qa-xxxx]
3️⃣ Candidate 抽取策略（无需审批）
先不做 Gatekeeper，也可以：

基于启发式规则抽取 Q/A
每轮会话只生成 1～3 条 candidate
confidence 先写死 0.3～0.5
九、未来恢复审批时的“无痛回归点”
你现在的设计已经为“审批”留好了接口：

ToolEvent 已有
MCP 边界可阻断
mem-codecli 已有 stdin / abort 框架
policy 配置结构已存在
👉 等你觉得“记忆 + 观察”稳定了，再把审批打开，不需要推翻重来

十、一句话阶段总结
当前阶段目标非常清晰：

👉 把 mem-codecli 打造成
一个“零侵入、全观测、可记忆”的执行外壳

不控制、不阻断、不博弈，
只记录、只理解、只积累。

如果你愿意，下一步我可以帮你做三选一的落地推进：

设计 memory.search → prompt 注入模板（可直接用）
设计 candidate 抽取 Prompt / Agent（离线生成）
给 MCP Server 一个最小“事件打印 middleware”示例（Rust / Python / TS 任你选）
你直接选一个编号即可。

You:
Gatekeeper 质量闸门

ChatGPT:
下面给出一套在“暂不做审批/阻断”前提下仍然可用、且工程上可落地的 Gatekeeper 质量闸门设计：它只决定是否写 candidate / validate，不影响 codecli 的执行与工具调用。你可以把它理解为“记忆沉淀的质检与限流器”。

1. Gatekeeper 的定位与输入输出
1.1 定位
不干预执行：不做 policy allow/deny，不走 stdin 控制通道
只控制记忆写入：candidate / validate / hit 的写入时机与内容质量
默认安全：宁可不写，也不写错（低误写率优先）
1.2 输入（GatekeeperInput）
来源于 runner capture 与事件流：

user_query: 本次用户任务（或会话摘要）
tool_events: tool.request/result 列表（可选）
final_stdout_tail: stdout ring tail（bytes→lossy string）
final_stderr_tail: stderr ring tail
memory_search_results: search 命中的 QA 列表（如果启用 search）
config: 阈值、规则、策略开关
1.3 输出（GatekeeperDecision）
should_write_candidate: bool
candidate_items: Vec<CandidateDraft>（0～N，建议 N≤3）
validate_hints: Vec<ValidateHint>（可选）
reasons: Vec<String>（审计用）
signals: {..}（结构化分数，便于调参）
2. 质量闸门的判定维度（可落地规则）
Gatekeeper 的核心是：过滤 + 去重 + 结构化 + 安全。

我建议用 4 组信号，每组给出可实现的硬规则（无需大模型也能跑），后续可加 LLM 评审增强。

2.1 可复用性（Reusability）
目的：避免把一次性对话、临时状态、无上下文碎片写进记忆。

硬规则：

输出必须包含至少一种结构：
步骤列表（1./-/Step）
或“问题→原因→解决”三段
内容长度下限：
answer ≥ 200 chars（可配置）
禁止明显一次性内容：
包含“刚才/这次/当前窗口/此刻”且无通用化描述 → 降分
禁止纯日志：
answer 中超过 60% 行以时间戳/日志级别开头（INFO|WARN|ERROR|\d{4}-\d{2}-\d{2}） → 拒绝
2.2 新颖性（Novelty / Anti-duplicate）
目的：避免重复写入，或者把已有 QA 改写一遍又存一次。

硬规则：

若 memory.search top1 score >= threshold_skip（如 0.85）：
默认不写 candidate（除非“差异显著”，见增强）
近似去重（本地）：
对 candidate question 做规范化（lowercase、去标点、去多空格）
与本次 search 返回的 question 做 Jaccard / trigram 相似度
超过阈值（如 0.8） → 不写或标记为“update existing”（你后面做 validate/update 时用）
2.3 安全与合规（Safety / Secret Hygiene）
目的：防止 secrets、token、内部地址、个人信息落库。

硬规则（建议先上 strict）：

命中 secret scanner（任意一个就拒绝写）：
AWS key、GitHub token、OpenAI key、私钥头尾、JWT、长随机串
连接串含密码（mysql://user:pass@）
输出中包含本地路径 / 用户名 / IP：
不直接拒绝，但进入 redact 流程后再决定
stderr_tail 有明显错误且未给出解决步骤：
拒绝写（避免把失败日志当知识）
结论：Gatekeeper 里必须依赖一个 Redactor（先做 regex-based）。

2.4 结构质量（Structure / Clarity）
目的：保证写入后能直接用，不需要再解释。

硬规则：

candidate answer 必须包含：
环境/前提（至少一句，例如 OS/语言/工具版本/命令上下文）
关键命令/配置片段（若是工程问题）
注意事项/坑点（至少 1 条）
过滤“纯建议/空话”：
出现“可能/试试/也许”占比过高且无可执行步骤 → 降分或拒绝
3. Gatekeeper 的两阶段流水线（推荐实现方式）
Stage A：候选生成（Drafting）
从本次 run 的材料中生成 0～3 条 CandidateDraft：

来源优先级：

若你已有“最终答案文本”（有些 CLI 会输出最终总结）→ 抽取 Q/A
否则从 stdout_tail 中提取“可复用片段”（含命令与解释）
如果 tool_events 完整：
用 tool.request/result 组合出“做了什么 → 得到什么”摘要
**注意：**这一步可以先启发式，不用 LLM。

Stage B：闸门判定（Gating）
对每条 draft 计算 signals：

reusability_score（0..1）
novelty_score
safety_score
structure_score
汇总：

final_score = w1*reusability + w2*novelty + w3*safety + w4*structure
严格硬门槛：
safety_score 必须=1（未命中敏感）
structure_score >= 0.5
通过后：
取 top K（K≤3）
输出 candidate payload（含 tags、confidence、metadata）
4. Gatekeeper 配置（TOML 建议）
[gatekeeper]
enabled = true
max_candidates = 2

min_answer_chars = 200
skip_if_top1_score_ge = 0.85
max_log_line_ratio = 0.6

[gatekeeper.weights]
reusability = 0.35
novelty = 0.25
safety = 0.25
structure = 0.15

[gatekeeper.redact]
enabled = true
level = "strict" # off|basic|strict
5. Rust 接口草案（可直接落代码）
pub struct GatekeeperInput {
    pub run_id: String,
    pub project_id: String,

    pub user_query: String,
    pub stdout_tail: String,
    pub stderr_tail: String,

    pub tool_events: Vec<ToolEvent>, // 可选
    pub search_top1_score: Option<f32>,
    pub search_items: Vec<QAMatch>,  // 可选
}

pub struct CandidateDraft {
    pub question: String,
    pub answer: String,
    pub tags: Vec<String>,
    pub confidence: f32,
    pub metadata: serde_json::Value,
}

pub struct GatekeeperDecision {
    pub should_write_candidate: bool,
    pub candidates: Vec<CandidateDraft>,
    pub reasons: Vec<String>,
    pub signals: serde_json::Value,
}

pub trait Gatekeeper: Send + Sync {
    fn evaluate(&self, input: GatekeeperInput) -> GatekeeperDecision;
}
实现拆分建议：

draft.rs：启发式候选生成
signals.rs：评分/规则判断
redact.rs：脱敏与 secret scanner
gatekeeper.rs：总控 evaluate
6. 与 MemoryClient 的对接（无审批模式下）
在 mem-codecli 的 pipeline 中：

run 前：
memory.search（可选）
run 后：
Gatekeeper evaluate
若通过：
memory.candidate 写入 1～2 条
可选：
memory.hit（如果你能判定“展示/使用”）
memory.validate（暂时可以不做）
7. 你现在最该先做的“最小 Gatekeeper MVP”
不引入大模型，只做硬门槛 + 1 条 candidate：

从 stdout_tail 中找：
最近一段包含命令（$ / cargo / git / docker / kubectl）的片段
以及其后紧跟的解释或输出
组装：
question："How to <do X> in <context>?"（可先模板化）
answer：保留步骤与注意事项
过滤：
secret scanner 命中 → 不写
search_top1_score >= 0.85 → 不写
这样你就能很快跑通“沉淀链路”，后续再把候选生成替换成更智能的方式。

8. 你要我下一步直接输出什么
你现在如果要“立刻落代码”，我建议我给你输出两份东西（可直接复制进 repo）：

src/gatekeeper/mod.rs + redact.rs + heuristics.rs（可编译 MVP）
pipeline 集成点：在 run 后调用 gatekeeper → memory.candidate
你只要回复一句：
“按 MVP Gatekeeper 落代码”
我就按你当前工程结构给出完整文件内容（不需要你再拆分）。

You:
根据这个文件的算法再次把关

Plugin (file_search):
Make sure to include fileciteturn1file0 in your response to cite this file, or to surface it as a link.

2. Validation Event Schema
All validation events share the same structure:

{
  "qa_id": "qa-1234",
  "namespace": "project:my-mcp-server",
  "result": "pass",
  "signal_strength": "strong",
  "source": "qa-run",
  "context": {
    "command": "pytest -q",
    "exit_code": 0,
    "runtime_ms": 5320,
    "stdout_digest": "hash:...",
    "stderr_digest": "hash:..."
  },
  "client": {
    "client_id": "qa-run-cli",
    "session_id": null,
    "user_id": null
  },
  "ts": "2025-01-01T12:00:00Z"
}
2.1 result
Value	Meaning
pass	the solution worked in execution
fail	execution failed / unresolved
2.2 signal_strength
Represents reliability of the signal:

Strength	Typical Source
strong	tests, builds, integration checks
medium	scripts / non-critical commands
weak	miscellaneous commands (low weight)
Heuristic mapping (example):

test|pytest|npm test|go test → strong
build|compile|cargo build|npm run build → strong
script execution → medium
misc → weak
3. Stored Statistics (per QA)
Each QA entry maintains validation statistics:

{
  "stats": {
    "total_pass": 7,
    "total_fail": 2,

    "strong_pass": 4,
    "strong_fail": 1,
    "medium_pass": 3,
    "medium_fail": 1,
    "weak_pass": 0,
    "weak_fail": 0,

    "consecutive_fail": 1,
    "last_result": "pass",
    "last_validated_at": "2025-01-01T11:30:00Z"
  },

  "score": {
    "trust_score": 0.87,
    "validation_level": 2
  },

  "ttl": {
    "expires_at": "2026-02-01T00:00:00Z"
  }
}
These values are updated on every /qa/validate event.

4. Trust Score Calculation
A weighted score captures reliability:

def compute_trust_score(stats):
    sp, sf = stats.strong_pass, stats.strong_fail
    mp, mf = stats.medium_pass, stats.medium_fail
    wp, wf = stats.weak_pass, stats.weak_fail
    cf = stats.consecutive_fail

    score = 0.0
    score += 0.25 * sp
    score -= 0.35 * sf

    score += 0.10 * mp
    score -= 0.15 * mf

    score += 0.02 * wp
    score -= 0.05 * wf

    score -= 0.5 * min(cf, 3)

    score = max(-2.0, min(score, 3.0))
    return (score + 2.0) / 5.0   # normalize to [0,1]
Principles:

Strong signals dominate
Consecutive failures are heavily penalized
Score remains stable but responsive
5. Validation Levels
Levels reflect maturity:

Level	Criteria (suggested)	Meaning
0	no validation	candidate
1	trust ≥ 0.40 & ≥2 validations	basic
2	trust ≥ 0.65 & ≥3 validations & ≥1 strong pass	strong
3	trust ≥ 0.80 & ≥5 validations & ≥2 strong passes & 0 strong fails	canonical
Levels influence ranking & retention.

6. TTL & Decay
Each QA has an expiration timestamp.

Rules:

Event	TTL Effect
Strong pass	+30 days (up to max 180)
Strong fail	−30 days (min = now+7d)
No activity	gradual decay
Expired entries become stale and:

drop in ranking, or
are excluded from default retrieval
7. Validation Handler Logic (Summary)
When /qa/validate is called:

Load QA entry
Update pass/fail counters + streaks
Compute trust score
Recompute validation level
Adjust TTL
Persist changes
Return updated status
Return payload example:

{
  "ok": true,
  "trust_score": 0.82,
  "validation_level": 2,
  "expires_at": "2026-02-01T00:00:00Z"
}
8. Search Ranking Integration
During /qa/search:

Higher validation_level → positive boost
Higher trust_score → positive boost
stale or failure-prone entries → penalized
Level 0 candidates appear only when no stronger matches exist
Result:

The system naturally prefers frequently-validated solutions.

9. Safety & Guard Rails
To prevent noise:

Ignore weak signals when they contradict multiple strong passes
Never promote an entry with recent consecutive fails ≥ 3
Cap strong promotion to avoid sudden spikes
Log anomalies (e.g., alternating pass/fail every run)
ChatGPT:
[Unsupported Content]

ChatGPT:
[Unsupported Content]

ChatGPT:
可以。你这份 QA-Score.md 的核心其实是：用“可验证信号”把 QA 从 candidate（Level 0）逐步提升到 canonical（Level 3），并通过 trust_score / validation_level / consecutive_fail / TTL 来抑制噪声与过期内容。fileciteturn1file0

下面我把它落成一套“再次把关”的 Gatekeeper 规则（不做审批/阻断，仅决定：是否写入 candidate、是否回传 validate/hit、检索时如何筛选/排序），并给出你在 mem-codecli 中的集成点。

1）Gatekeeper 的“二次把关”目标
在你原先基于文本质量（结构/安全/去重）的闸门之后，再加一层 基于验证统计的闸门：

写 candidate（Level 0）：更谨慎，减少垃圾入库
回传 validate：让系统自动学会“哪些解决方案真有效”
检索使用：优先用高验证等级与高信任分的条目
抑制抖动：连续失败/弱信号冲突时不提升、不推荐
2）基于文件算法的 Gatekeeper 规则（可直接执行）
2.1 Trust Score 计算与使用
trust_score 计算公式按文件定义（强/中/弱通过与失败，加上 consecutive_fail 惩罚并归一化到 [0,1]）。fileciteturn2file12

Gatekeeper 使用方式：

检索结果过滤（推荐）
consecutive_fail >= 3：直接标记为“不可用/不展示”（Fail-prone）。fileciteturn2file12
trust_score < 0.40：默认不展示（除非“无结果兜底”）。
写 candidate 限流（推荐）
当 search 已能命中 validation_level >= 2 的结果时：不再写候选（避免重复与噪声），除非你检测到“差异显著”（例如不同环境/不同错误码）。
2.2 Validation Level 门槛（Promotion Gate）
等级标准按文件建议：Level 1/2/3 分别对应 trust_score、验证次数、强信号次数等条件。fileciteturn2file12

Gatekeeper 用途：

注入提示（Prompt Injection）优先级：只注入 Level ≥ 2（strong/canonical）作为默认策略；Level 0 仅在“无强匹配”兜底出现。fileciteturn2file12
candidate 写入策略：
若当前会话已使用 Level 2/3 的 QA 并成功（后续 validate=pass）：倾向于不产生新 candidate，而是对已用 QA 做 hit/validate。
2.3 TTL / Stale 抑制（Retention Gate）
TTL 规则：strong pass 延长、strong fail 缩短、无活动衰减；过期条目标记 stale 并降权/排除。fileciteturn2file12

Gatekeeper 使用方式：

搜索结果中如果带 expires_at（或你可通过 /v1/qa/{qa_id} 查询到 TTL）：
expires_at <= now：默认不展示，只在用户显式要求“历史方案/旧版本兼容”时才兜底
会话结束时若有 strong pass（例如 CI/test/build 成功）：
触发 /qa/validate：让服务端自动延长 TTL（由服务端按规则处理）。fileciteturn2file12
2.4 Guard Rails（噪声抑制）
文件给了明确防噪策略：弱信号不能轻易推翻多次强通过；consecutive_fail≥3 不可提升；避免强信号突增；记录异常震荡。fileciteturn2file12

Gatekeeper 执行规则建议：

如果你上报的是 weak 信号（比如随手脚本）且历史 strong_pass 明显占优：
不降级（validate 仍可上报，但在服务端应被“弱信号冲突忽略”逻辑吸收）。fileciteturn2file12
若检测到交替 pass/fail（震荡）：
Gatekeeper 给该 qa_id 打上 metadata.anomaly = "flip_flop"，便于服务端/离线任务做分析。fileciteturn2file12
3）你在 mem-codecli 里要落的 3 个集成点
3.1 Run 前：search → 只拿“可用候选集合”
调用 /v1/qa/search
Gatekeeper 对结果做二次筛选：
剔除 stale
剔除 consecutive_fail>=3
默认只保留 validation_level>=1 或 trust_score>=0.40（可配置）fileciteturn2file12
文件也明确：search 排序要对 validation_level 和 trust_score 做加权提升，Level 0 只在没有更强匹配时出现。fileciteturn2file12

3.2 Run 后：validate（把“执行结果”喂回去）
你需要按 Validation Event Schema 上报一次 /qa/validate，结构在文件中已经给出。fileciteturn1file0

result: pass/fail fileciteturn1file0
signal_strength: strong/medium/weak，并按命令启发式映射（test/build 强、脚本中、杂项弱）。fileciteturn1file0
context: command、exit_code、runtime_ms、stdout/stderr digest（你已经有 ring buffer，可做 hash）fileciteturn1file0
3.3 Run 后：candidate（仅在“确实需要新知识”时写）
满足以下才写 candidate（Level 0）：

本次 search 没有 Level≥2 的强匹配（或 top1 分数很低）
本次输出通过你原本的结构/安全/去重规则
本次会话产生了“可复用步骤/配置/修复点”
否则：优先 hit + validate，不新增 candidate。

4）一份可配置的“二次把关”策略（建议默认）
min_trust_show = 0.40（低于不展示）fileciteturn2file12
min_level_inject = 2（默认只注入 strong/canonical）fileciteturn2file12
block_if_consecutive_fail_ge = 3（直接屏蔽）fileciteturn2file12
stale_policy = "exclude_by_default"（过期默认不出现在检索结果集合）fileciteturn2file12
candidate_only_if_no_strong_matches = true（抑制噪声与重复）fileciteturn2file12
5）你下一步最关键的“落地前置条件”
要让 Gatekeeper 真正按这套算法把关，你需要保证 search 返回里能拿到（至少其一）：

trust_score / validation_level / consecutive_fail / expires_at（最好直接在 search 响应里带）
或者：search 只返回 qa_id，再额外调用 /v1/qa/{qa_id} 拉详情（你 OpenAPI 里有该接口路径）。fileciteturn2file7
如果你愿意，我可以把这套“二次把关”直接变成你工程里的 Rust 代码模块（gatekeeper_score.rs）：

输入：search results（JSON Value 也行）
输出：filtered/inject list + candidate decision + validate payload（符合 schema）fileciteturn1file0
You:
整理质量闸门的信息

ChatGPT:
下面是**“质量闸门（Gatekeeper）”的统一整理版**，已经融合你最初的 Gatekeeper 规则 +《QA-Score.md》的验证算法，并且明确了当前阶段（无审批、Observer Mode）下 Gatekeeper 的唯一职责。
这份内容可以直接作为 docs/gatekeeper.md 或设计评审定稿。

质量闸门（Gatekeeper）— 统一整理版
一、Gatekeeper 的最终定位（定锚）
Gatekeeper 不是执行闸门，也不是安全审批器，而是：
记忆系统的“质量控制器 + 噪声抑制器 + 生命周期调度器”。

在当前阶段（无审批 / 无阻断）：

❌ 不影响 codecli 执行
❌ 不做 policy allow/deny
❌ 不写 stdin / abort
✅ 决定 是否写入 candidate
✅ 决定 是否回传 validate / hit
✅ 决定 search 结果是否可用 / 是否注入
二、Gatekeeper 的三层职责模型（清晰分工）
Layer 1：内容质量闸门（Content Quality）
“这条内容本身值不值得被记住？”

关注：结构、可复用性、安全性、去重

Layer 2：验证统计闸门（Score / Trust）
“这条内容在历史上是否被证明有用？”

关注：trust_score、validation_level、consecutive_fail、TTL

Layer 3：生命周期与注入闸门（Lifecycle）
“现在是否应该展示 / 注入 / 再次写入？”

关注：抑制噪声、避免重复、优先强信号

三、Layer 1：内容质量闸门（一次性过滤）
1. 可复用性（Reusability）
通过条件（必须满足其一）：

明确的步骤结构（Step / 列表）
问题 → 原因 → 解决方案
配置 / 命令 + 解释 + 注意事项
拒绝条件：

明显一次性表述（“刚才 / 这次 / 当前窗口”）
纯日志或输出（日志行占比 > 60%）
answer 长度过短（默认 < 200 chars）
2. 新颖性（Anti-Duplicate）
规则：

若 memory.search.top1_score ≥ 0.85
→ 默认 不写 candidate
若语义高度相似（规范化后相似度 ≥ 0.8）
→ 视为重复，不写
目标：减少重复 Q/A 堆积

3. 安全与脱敏（Safety）
硬拒绝（Strict）：

命中 secret（API key / token / 私钥 / 连接串密码）
明确的内部凭证或身份信息
软处理：

本地路径 / IP / 用户名
→ redact 后再评估
4. 结构质量（Structure）
必须包含：

环境/前提说明
可执行步骤或配置
至少 1 条注意事项 / 坑点
否则：拒绝写入。

四、Layer 2：验证统计闸门（来自 QA-Score 算法）
这一层不由 mem-codecli 计算，而是消费 Memory 服务返回的统计字段。

关键字段（来自 QA-Score.md）
trust_score ∈ [0,1]
validation_level ∈ {0,1,2,3}
consecutive_fail
expires_at / TTL
1. Trust Score 使用规则
trust_score < 0.40
→ 默认 不展示、不注入
consecutive_fail ≥ 3
→ 直接屏蔽（Fail-prone）
强通过 > 弱失败
→ 弱信号不能轻易拉低高质量条目
2. Validation Level（等级闸门）
Level	含义	Gatekeeper 行为
0	Candidate	仅兜底使用
1	Verified	可展示
2	Strong	默认注入
3	Canonical	优先注入
规则：

默认只注入 Level ≥ 2
若已有 Level ≥ 2 命中 → 不再写新 candidate
3. TTL / Stale 规则
expires_at < now
→ 默认不展示
strong pass → 服务端自动延长 TTL
长期无活动 → 自然衰减
Gatekeeper 只负责 是否使用，不负责 TTL 计算。

五、Layer 3：生命周期与行为决策
1. Candidate 写入策略（非常重要）
只有在以下全部满足时才写 candidate：

search 没有 Level ≥ 2 的强匹配
内容通过 Layer 1 质量闸门
本次会话确实产生了“新方法 / 新修复 / 新配置”
否则：

优先 hit
优先 validate
不新增 candidate
2. Validate 回传策略
在 run 结束后：

若使用了某条 QA：
回传 /qa/validate
携带：
result: pass/fail
signal_strength: strong/medium/weak
context（exit code、stdout/stderr digest）
用途：

更新 trust_score
调整 validation_level
触发 TTL 延展或缩短
3. Hit 回传策略
展示但未明确验证成功 → hit(shown=true, used=false)
明确采用并执行 → hit(used=true)
六、Gatekeeper 的最终决策输出（统一模型）
GatekeeperDecision
├─ should_write_candidate : bool
├─ candidates             : Vec<CandidateDraft>
├─ should_validate        : bool
├─ validate_payloads      : Vec<QAValidationPayload>
├─ inject_list            : Vec<QARef>   # 用于 prompt 注入
├─ reasons                : Vec<String>  # 审计
├─ signals                : { trust, novelty, safety, structure }
七、推荐的默认阈值（稳定版）
min_trust_show = 0.40
min_level_inject = 2
block_if_consecutive_fail_ge = 3
skip_if_top1_score_ge = 0.85
candidate_only_if_no_strong_matches = true
stale_policy = "exclude_by_default"
八、整体心智模型（一句话）
Gatekeeper 不决定“对不对”，
只决定“值不值得被长期记住、被反复使用”。

Layer 1：别把垃圾写进去
Layer 2：让历史验证说话
Layer 3：让强知识自然胜出
如果你需要，我可以下一步直接帮你输出三样之一：

Gatekeeper MVP Rust 实现（可直接接入你现有 mem-codecli）
Gatekeeper → Memory API 的完整调用时序图
一份“质量闸门 Checklist”，用于人工审查 / 设计评审
你选一个即可。

You:
Gatekeeper → Memory API 的完整调用时序图

ChatGPT:
[Unsupported Content]

ChatGPT:
[Unsupported Content]

ChatGPT:
下面给出 Gatekeeper → Memory API 的完整调用时序图（以你当前“Observer Mode：不审批、不阻断”为前提），并把每一步的触发条件与 payload 要点写清楚。图用 Mermaid，便于你直接放进仓库文档渲染。

1）总时序（Observer Mode：search → run → hit/validate/candidate）
No diagram type detected matching given configuration for text: 
2）关键分支说明（什么时候调哪个接口）
A. /v1/qa/search（运行前）
触发条件：

memory.enabled=true 且 base_url 有效
目的：
找到可复用 QA，用于 prompt 注入（默认只注入强知识：validation_level>=2 + trust_score>=min + 非 stale） Gatekeeper 参与点：
Score Gate（第二层闸门）：过滤 stale、consecutive_fail>=3、低 trust；排序提升 level 高的条目。
B. /v1/qa/hit（运行后或运行中）
触发条件（建议最小实现）：

如果你做了 search 且给用户展示/注入过某些 QA，就上报 hit 字段建议：
shown=true：注入/展示过
used=true：你能判断“确实采用了”（例如输出中出现了某条 QA 的 anchor 或关键命令被执行） Gatekeeper 参与点：
Lifecycle Gate：决定哪些引用算 shown/used，避免乱报。
C. /v1/qa/validate（运行后，强推荐）
触发条件：

你能从运行结果提取“通过/失败”信号
强信号（strong）例子：
exit_code==0 且存在明确成功标志（tests passed/build succeeded） 中信号（medium）：
部分步骤成功、无回归 弱信号（weak）：
仅展示、未执行、或结果不明
Gatekeeper 参与点：

Score Gate / Noise Guard：弱信号不轻易拉低强知识；失败震荡可打 anomaly 标记（写在 validate payload 的 payload 里）。
D. /v1/qa/candidates（运行后）
触发条件（建议严格）：

本轮 search 没有强匹配（例如没有 validation_level>=2 的结果，或 top1 score 很低）
内容通过 Content Gate（结构/安全/去重）
确实产生“新方法/新修复点”
Gatekeeper 参与点：

Content Gate + Novelty Gate：从 run artifacts 抽取 0~2 条 candidate，secret 扫描不通过就不写。
3）推荐的“最小落地版本”（你实现时的优先级）
search + Gatekeeper 过滤注入（先注入 1~3 条 Level≥2）
运行后 validate（只对“你注入/展示过的 top1/topN”回传）
运行后 candidate（只有在“无强匹配 + 通过内容闸门”时）
hit（最后补上，或者先只报 shown）
如果你把 Memory API 实际响应字段（search item 里是否包含 validation_level/trust_score/expires_at/consecutive_fail）贴一段样例，我可以把图里每个 payload 的字段 对齐到你真实 schema，并给出“GatekeeperDecision → API payload”的精确映射表。

You:
matches.append( { "qa_id": str(record.id), "project_id": record.project_id, "question": record.question, "answer": record.answer, "summary": record.summary, "score": final_score, "relevance": relevance, "trust": trust, "freshness": freshness, "validation_level": level_value, "level": record.level, "status": record.status, "metadata": record.meta, "tags": record.tags, "expiry_at": record.ttl_expire_at.isoformat() if record.ttl_expire_at else None, "source": record.source, "confidence": record.confidence, } )

ChatGPT:
很好，这个 matches.append(...) 结构已经是 Gatekeeper 可直接消费的“完整搜索结果模型”。下面我把它严格对齐到 Gatekeeper 的三层闸门（质量 / 评分 / 生命周期），并给出明确的使用规则与代码级判定顺序，让你知道：

每个字段 在 Gatekeeper 中扮演什么角色
哪些字段是硬门槛
哪些字段只用于排序/降权
search → inject / hit / validate / candidate 的精确决策逻辑
一、Search Match 结果 → Gatekeeper 输入模型（对齐）
你现在 search 返回的单条 match：

{
  "qa_id": str(record.id),
  "project_id": record.project_id,
  "question": record.question,
  "answer": record.answer,
  "summary": record.summary,
  "score": final_score,
  "relevance": relevance,
  "trust": trust,
  "freshness": freshness,
  "validation_level": level_value,
  "level": record.level,
  "status": record.status,
  "metadata": record.meta,
  "tags": record.tags,
  "expiry_at": record.ttl_expire_at.isoformat() if record.ttl_expire_at else None,
  "source": record.source,
  "confidence": record.confidence,
}
👉 这是一个“SearchMatch（Gatekeeper-ready）”对象，无需再补字段。

二、Gatekeeper 使用字段的优先级划分（非常重要）
Layer 0：基础身份字段（不参与决策）
仅用于展示 / 追踪：

字段	用途
qa_id	hit / validate / candidate 关联
project_id	命名空间
question / answer / summary	prompt 注入
metadata / tags / source	辅助展示
confidence	UI 或次级排序
Gatekeeper 不基于这些字段做通过/拒绝。

Layer 1：质量闸门（硬过滤）
1️⃣ 状态闸门（Status Gate）
if status not in {"active", "verified"}:
    reject()
status != active → 绝对不注入、不使用
原因：下线/禁用/回收内容不可再被引用
2️⃣ 生命周期闸门（TTL / Expiry）
if expiry_at is not None and expiry_at < now:
    reject()   # stale
expiry_at < now → 默认拒绝
仅在“用户显式要求历史方案”时才兜底（当前阶段不做）
3️⃣ 失败抑制（Consecutive Fail Gate）
你现在 search 结果里还没直接返回 consecutive_fail，但这一步逻辑已经可以预留。

if metadata.get("consecutive_fail", 0) >= 3:
    reject()
这是 QA-Score.md 的硬规则
一旦触发：不展示、不注入、不 validate
Layer 2：评分与可信度闸门（核心）
4️⃣ 验证等级闸门（Validation Level Gate）
你现在有两个相关字段：

validation_level（数值型，Gatekeeper 使用）
level（原始枚举/字符串，用于展示或调试）
Gatekeeper 统一使用 validation_level（int）

if validation_level < MIN_LEVEL_INJECT:
    soft_reject()   # 不作为默认注入
推荐默认：

MIN_LEVEL_INJECT = 2   # Strong
含义：

validation_level	Gatekeeper 行为
3	Canonical，强注入
2	Strong，默认注入
1	Verified，仅在无强匹配时兜底
0	Candidate，不注入
5️⃣ 信任分闸门（Trust Gate）
if trust < MIN_TRUST_SHOW:
    soft_reject()
推荐默认：

MIN_TRUST_SHOW = 0.40
trust < 0.40：不注入、不优先展示
但 不会直接 reject（除非同时命中其他硬门槛）
6️⃣ 综合得分（Score Gate，用于排序，不用于 reject）
你已经有：

score = final_score
relevance
trust
freshness
Gatekeeper 不重新算分，只做排序建议：

sort_key = (
  validation_level DESC,
  trust DESC,
  score DESC,
  freshness DESC,
)
⚠️ score 再高，也不能绕过 validation_level / trust / expiry / status 的硬门槛

Layer 3：行为决策（Inject / Candidate / Validate）
A️⃣ Prompt 注入（Inject Decision）
injectable = (
    status == "active"
    and not expired
    and validation_level >= 2
    and trust >= 0.40
)
默认最多注入 Top N（如 3 条）
如果存在 validation_level >= 2：
不注入 level 0 / 1
如果完全没有 strong：
允许 1 条 level 1 兜底
B️⃣ Candidate 写入抑制（Anti-Noise）
关键规则（你现在这套数据已经支持）：

if any(match.validation_level >= 2 for match in matches):
    do_not_write_candidate()
含义：

只要 search 已经命中 Strong / Canonical，
本轮不允许再写新的 candidate。

这条规则是整个系统防爆炸、防重复的核心。

C️⃣ Validate 回传对象选择
优先 validate：

本轮被注入的 top1/topN
且用户/CI 的结果是明确的（exit code / test）
if injectable and execution_success:
    validate(qa_id, strong_signal)
三、Gatekeeper 决策伪代码（完整、可落地）
usable = []

for m in matches:
    if m["status"] != "active":
        continue
    if m["expiry_at"] and m["expiry_at"] < now:
        continue
    if m["metadata"].get("consecutive_fail", 0) >= 3:
        continue

    usable.append(m)

usable.sort(
    key=lambda m: (
        m["validation_level"],
        m["trust"],
        m["score"],
        m["freshness"],
    ),
    reverse=True,
)

inject_list = [
    m for m in usable
    if m["validation_level"] >= 2 and m["trust"] >= 0.40
][:MAX_INJECT]

has_strong = any(m["validation_level"] >= 2 for m in usable)

should_write_candidate = not has_strong
四、结论（一句话）
你现在这个 matches.append(...) 的结果结构
已经完全满足 Gatekeeper + QA-Score 算法的需要，
Gatekeeper 的工作不再是“猜”，而是：

按字段做严格分层裁决。

如果你愿意，下一步我可以直接帮你输出：

Gatekeeper.evaluate(matches) 的 Rust / Python 实现
Search API → Prompt 注入模板
Validate payload 生成器（直接吃这个 match 结构）
你只要说选哪个。

You:
整理信息，列举目前待做的事件

ChatGPT:
下面是基于当前全部已确认设计与实现状态的统一整理，以及明确、可执行的待做事件清单（Backlog / TODO）。
目标是：让你一眼看清现在系统“已经闭环到哪里”，以及下一步该做什么，不做什么。

一、当前系统状态总览（已完成 / 已冻结 / 进行中）
1️⃣ 已完成并稳定的部分（可认为“已定型”）
✅ 1. mem-codecli Wrapper（Observer Mode）
Rust 包装 codecli
stdout / stderr 流式 tee
ring buffer capture（用于 Gatekeeper / validate context）
exit code 原样返回
不干预执行、不审批、不阻断
✅ 2. ToolEvent 采集模型
事件来源统一在 MCP 边界
JSONL 协议冻结（tool.request / tool.result）
mem-codecli 只做解析，不生产、不控制
✅ 3. Memory Search 返回结构（非常关键）
你当前 search 返回的 matches.append({...})：

已包含 Gatekeeper 所需全部字段：
validation_level
trust
freshness
score
expiry_at
status
confidence
已完全对齐 QA-Score.md 算法
不需要再扩字段即可进入 Gatekeeper
✅ 4. Gatekeeper 设计（逻辑已冻结）
三层闸门：
内容质量（结构 / 安全 / 去重）
验证统计（trust / level / TTL / fail）
生命周期决策（inject / validate / candidate）
明确 只控制“是否写记忆”，不控制执行
已给出完整判定顺序与阈值
✅ 5. Gatekeeper → Memory API 时序
search → inject
run
hit / validate / candidate（条件触发）
Observer Mode 下完整闭环
2️⃣ 明确冻结、不做的事情（当前阶段）
以下内容已明确不在当前阶段实施，避免系统复杂化：

❌ tool 审批（policy allow/deny）
❌ stdin 控制 / abort
❌ Fail-Closed / 执行级闸门
❌ Gatekeeper 作为安全审批器
❌ 人工确认 / 交互式 Gate
结论：现在系统只“看 + 记 + 学”，不“管”

二、当前待做事件清单（按优先级排序）
下面是真正还没做、但必须补齐的事件，每一条都是“可独立完成的工程任务”。

🔴 P0（必须做，决定系统是否真正可用）
事件 1：Gatekeeper.evaluate 的正式实现（代码级）
状态：未实现（只有设计）

需要做：

实现 Gatekeeper.evaluate(matches, run_artifacts)
严格按你当前 search 返回字段裁决：
status / expiry_at / validation_level / trust
输出：
inject_list
should_write_candidate
validate_plan
reasons
这是当前系统最核心的“中枢逻辑”。

事件 2：Search → Prompt 注入模板（工程落地）
状态：未实现

需要做：

设计 prompt 注入模板（system / user）
明确：
注入多少条（Top 1～3）
如何展示（QA_REF / 简述 / 完整 answer）
与 Gatekeeper 的 inject_list 对齐
没有这一步，search 的价值无法体现。

事件 3：Validate payload 生成与回传
状态：未实现

需要做：

基于 run 结果生成 /v1/qa/validate payload：
result: pass / fail
signal_strength: strong / medium / weak
context: exit_code / stdout_tail digest / tool_events
明确什么时候不发 validate（无强信号）
这是 QA-Score 算法真正“学习”的入口。

🟠 P1（重要，但不阻塞整体闭环）
事件 4：Candidate Draft 抽取（启发式版）
状态：未实现

需要做：

从 stdout_tail / tool_events 抽取 0～1 条 candidate
套用 Gatekeeper 内容质量闸门：
结构
安全
去重
生成 /v1/qa/candidates payload
注意：
只有 search 没命中 Strong（validation_level ≥ 2） 时才触发。

事件 5：Hit 回传策略落地
状态：未实现

需要做：

定义 shown / used 判定规则
生成 /v1/qa/hit payload
避免“全 hit / 乱 hit”
这是 search 结果权重优化的重要信号源。

🟡 P2（增强项，可后置）
事件 6：Gatekeeper 信号日志与可观测性
状态：未实现

建议：

记录 GatekeeperDecision：
reasons
signals
reject 原因
用于调参、回溯、debug
事件 7：search 结果排序/过滤策略配置化
状态：未实现

例如：

min_trust_show
min_level_inject
block_if_consecutive_fail_ge
max_inject_items
当前可硬编码，后续配置化。

🧊 P3（未来阶段，不着急）
事件 8：Gatekeeper + LLM 增强
用 LLM 生成 candidate draft
用 LLM 辅助结构评分
仅作为增强，不替代硬规则
事件 9：恢复审批 / Fail-Closed（未来阶段）
stdin 控制
policy.decision
abort sequence
明确：不是现在。

三、当前系统的“完成度判断”
模块	完成度
Runner / Tee	✅ 95%
ToolEvent	✅ 90%
Memory Search	✅ 90%
Gatekeeper 设计	✅ 100%
Gatekeeper 实现	❌ 0%
Prompt 注入	❌ 0%
Validate 回传	❌ 0%
Candidate 写入	❌ 0%
👉 当前是“设计完成，执行尚未接线”的状态

四、建议你下一步只做的一件事（强烈）
优先级最高、收益最大的下一步：

👉 实现 Gatekeeper.evaluate(matches, run_result)（P0 事件 1）
原因：

不依赖 UI、不依赖 LLM
不影响执行
一旦实现，其它事件（inject / validate / candidate）都能自然接上
如果你愿意，下一步我可以直接帮你：

把 Gatekeeper.evaluate 写成完整可用的 Python / Rust 函数
或 按你 search 返回结构写单元测试用例
或 生成一份“P0 实施 checklist（工程版）”
你只要说选哪个。

You:
Gatekeeper.evaluate 写成完整可用的Rust 函数

ChatGPT:
[Unsupported Content]

ChatGPT:
[Unsupported Content]

ChatGPT:
// src/gatekeeper.rs
//
// Gatekeeper.evaluate：基于你 search 返回的 match 结构（qa_id/score/trust/freshness/validation_level/status/expiry_at...）
// 做三件事：
// 1) 过滤 + 排序 + 选出 inject_list
// 2) 决定是否允许写 candidate（无强匹配才允许）
// 3) 产出 validate_plan / hit_plan（基于 run_outcome 与 inject/used 情况）
//
// 说明：当前实现不做审批/阻断；只决定“用哪些、回传哪些、是否写入候选”。

use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use serde_json::Value;
use std::collections::HashSet;

#[derive(Debug, Clone, Deserialize)]
pub struct SearchMatch {
    pub qa_id: String,
    pub project_id: String,
    pub question: String,
    pub answer: String,
    pub summary: Option<String>,

    pub score: f32,
    pub relevance: f32,
    pub trust: f32,
    pub freshness: f32,

    pub validation_level: i32,
    pub level: Option<String>, // record.level（仅展示/调试）
    pub status: String,

    pub metadata: Value,
    pub tags: Vec<String>,
    pub expiry_at: Option<String>, // ISO8601 or None

    pub source: Option<String>,
    pub confidence: Option<f32>,
}

#[derive(Debug, Clone)]
pub struct GatekeeperConfig {
    pub max_inject: usize,
    pub min_level_inject: i32,       // 推荐 2
    pub min_level_fallback: i32,     // 推荐 1（无强匹配时兜底）
    pub min_trust_show: f32,         // 推荐 0.40
    pub block_if_consecutive_fail_ge: i32, // 推荐 3（从 metadata 取）
    pub skip_if_top1_score_ge: f32,  // 推荐 0.85（抑制 candidate）
    pub exclude_stale_by_default: bool,
    pub active_statuses: HashSet<String>, // 默认 {"active","verified"} 你可按服务端定义调整
}

impl Default for GatekeeperConfig {
    fn default() -> Self {
        Self {
            max_inject: 3,
            min_level_inject: 2,
            min_level_fallback: 1,
            min_trust_show: 0.40,
            block_if_consecutive_fail_ge: 3,
            skip_if_top1_score_ge: 0.85,
            exclude_stale_by_default: true,
            active_statuses: ["active".to_string(), "verified".to_string()]
                .into_iter()
                .collect(),
        }
    }
}

#[derive(Debug, Clone)]
pub struct RunOutcome {
    pub exit_code: i32,
    pub duration_ms: Option<u64>,
    pub stdout_tail: String,
    pub stderr_tail: String,

    // 你可以在 pipeline 中填：哪些 qa_id 被展示/注入、哪些最终被“采用”
    pub shown_qa_ids: Vec<String>,
    pub used_qa_ids: Vec<String>,
}

#[derive(Debug, Clone, Serialize)]
pub struct InjectItem {
    pub qa_id: String,
    pub question: String,
    pub answer: String,
    pub summary: Option<String>,
    pub trust: f32,
    pub validation_level: i32,
    pub score: f32,
    pub tags: Vec<String>,
}

#[derive(Debug, Clone, Serialize)]
pub struct HitRef {
    pub qa_id: String,
    pub shown: bool,
    pub used: bool,
    pub message_id: Option<String>,
    pub context: Option<String>,
}

#[derive(Debug, Clone, Serialize)]
pub struct ValidatePlan {
    pub qa_id: String,
    pub result: String,          // "pass" | "fail"
    pub signal_strength: String, // "strong" | "medium" | "weak"
    pub strong_signal: bool,
    pub context: Option<String>,
    pub payload: Value,
}

#[derive(Debug, Clone, Serialize)]
pub struct GatekeeperDecision {
    pub inject_list: Vec<InjectItem>,
    pub should_write_candidate: bool,

    pub hit_refs: Vec<HitRef>,
    pub validate_plans: Vec<ValidatePlan>,

    pub reasons: Vec<String>,
    pub signals: Value,
}

pub struct Gatekeeper;

impl Gatekeeper {
    pub fn evaluate(
        cfg: &GatekeeperConfig,
        now: DateTime<Utc>,
        matches: &[SearchMatch],
        run: &RunOutcome,
    ) -> GatekeeperDecision {
        let mut reasons: Vec<String> = Vec::new();

        // ---------- 0) 基础：top1 score 用于抑制 candidate ----------
        let top1_score = matches
            .iter()
            .map(|m| m.score)
            .fold(None, |acc, x| Some(acc.map_or(x, |a| a.max(x))));
        if let Some(s) = top1_score {
            reasons.push(format!("top1_score={:.3}", s));
        }

        // ---------- 1) 硬过滤（Status / TTL / consecutive_fail）----------
        let mut usable: Vec<&SearchMatch> = Vec::new();
        let mut stale_count = 0usize;
        let mut status_reject = 0usize;
        let mut fail_reject = 0usize;

        for m in matches.iter() {
            if !cfg.active_statuses.contains(&m.status) {
                status_reject += 1;
                continue;
            }

            // TTL / expiry
            if cfg.exclude_stale_by_default {
                if is_stale(m, now) {
                    stale_count += 1;
                    continue;
                }
            }

            // consecutive_fail from metadata (optional)
            let cf = extract_i32(&m.metadata, "consecutive_fail").unwrap_or(0);
            if cf >= cfg.block_if_consecutive_fail_ge {
                fail_reject += 1;
                continue;
            }

            usable.push(m);
        }

        reasons.push(format!(
            "filtered: usable={}, status_reject={}, stale_reject={}, fail_reject={}",
            usable.len(),
            status_reject,
            stale_count,
            fail_reject
        ));

        // ---------- 2) 排序（level > trust > score > freshness）----------
        usable.sort_by(|a, b| {
            // 注意：f32 比较用 partial_cmp，遇到 NaN 视为相等
            let key_a = (a.validation_level, a.trust, a.score, a.freshness);
            let key_b = (b.validation_level, b.trust, b.score, b.freshness);

            // level desc
            key_b.0.cmp(&key_a.0)
                // trust desc
                .then_with(|| key_b.1.partial_cmp(&key_a.1).unwrap_or(std::cmp::Ordering::Equal))
                // score desc
                .then_with(|| key_b.2.partial_cmp(&key_a.2).unwrap_or(std::cmp::Ordering::Equal))
                // freshness desc
                .then_with(|| key_b.3.partial_cmp(&key_a.3).unwrap_or(std::cmp::Ordering::Equal))
        });

        let has_strong = usable.iter().any(|m| m.validation_level >= cfg.min_level_inject);

        // ---------- 3) 注入列表（默认 level>=2 && trust>=min）----------
        let mut inject_list: Vec<InjectItem> = Vec::new();

        for m in usable.iter() {
            if inject_list.len() >= cfg.max_inject {
                break;
            }
            if m.validation_level >= cfg.min_level_inject && m.trust >= cfg.min_trust_show {
                inject_list.push(to_inject_item(m));
            }
        }

        // 兜底：无 strong 时允许注入 1 条 level>=fallback（仍建议加 trust 门槛）
        if inject_list.is_empty() && !usable.is_empty() && !has_strong {
            for m in usable.iter().take(cfg.max_inject) {
                if m.validation_level >= cfg.min_level_fallback && m.trust >= cfg.min_trust_show {
                    reasons.push("inject fallback (no strong matches)".to_string());
                    inject_list.push(to_inject_item(m));
                    break;
                }
            }
        }

        reasons.push(format!(
            "inject: count={}, has_strong={}",
            inject_list.len(),
            has_strong
        ));

        // ---------- 4) candidate 写入决策（强抑制噪声）----------
        let mut should_write_candidate = true;

        if has_strong {
            should_write_candidate = false;
            reasons.push("candidate suppressed: has strong matches".into());
        }

        // top1 score 很高也抑制 candidate（避免重复）
        if let Some(s) = top1_score {
            if s >= cfg.skip_if_top1_score_ge {
                should_write_candidate = false;
                reasons.push(format!(
                    "candidate suppressed: top1_score >= {:.2}",
                    cfg.skip_if_top1_score_ge
                ));
            }
        }

        // ---------- 5) hit refs（shown/used）----------
        // 当前策略：以 run.shown_qa_ids/run.used_qa_ids 为准。
        // 你如果还没能判定 used，可先只填 shown。
        let shown: HashSet<String> = run.shown_qa_ids.iter().cloned().collect();
        let used: HashSet<String> = run.used_qa_ids.iter().cloned().collect();

        let mut hit_refs: Vec<HitRef> = Vec::new();
        for qa_id in shown.union(&used) {
            hit_refs.push(HitRef {
                qa_id: qa_id.clone(),
                shown: shown.contains(qa_id),
                used: used.contains(qa_id),
                message_id: None,
                context: None,
            });
        }

        // ---------- 6) validate plans（强烈建议只对“used 或 top1注入”回传）----------
        // 简化策略：
        // - 如果 exit_code==0 => pass，强信号（strong）
        // - 否则 fail，medium（你可根据 stderr_tail/关键字再分级）
        //
        // validate 对象选择：
        // - 优先 used_qa_ids
        // - 若 used 为空，则取 inject_list[0]（如果存在）
        let (result, signal_strength, strong_signal) = if run.exit_code == 0 {
            ("pass".to_string(), "strong".to_string(), true)
        } else {
            ("fail".to_string(), "medium".to_string(), false)
        };

        let mut validate_targets: Vec<String> = Vec::new();
        if !run.used_qa_ids.is_empty() {
            validate_targets.extend(run.used_qa_ids.iter().cloned());
        } else if let Some(first) = inject_list.first() {
            validate_targets.push(first.qa_id.clone());
        }

        let mut validate_plans = Vec::new();
        for qa_id in validate_targets {
            validate_plans.push(ValidatePlan {
                qa_id,
                result: result.clone(),
                signal_strength: signal_strength.clone(),
                strong_signal,
                context: Some(format!(
                    "exit_code={}, duration_ms={:?}",
                    run.exit_code, run.duration_ms
                )),
                payload: serde_json::json!({
                    "exit_code": run.exit_code,
                    "duration_ms": run.duration_ms,
                    "stdout_tail_digest": digest_cheap(&run.stdout_tail),
                    "stderr_tail_digest": digest_cheap(&run.stderr_tail),
                }),
            });
        }

        // ---------- 7) signals 输出（便于调参/观测）----------
        let signals = serde_json::json!({
            "usable_count": usable.len(),
            "inject_count": inject_list.len(),
            "has_strong": has_strong,
            "top1_score": top1_score,
            "status_reject": status_reject,
            "stale_reject": stale_count,
            "fail_reject": fail_reject,
            "should_write_candidate": should_write_candidate,
        });

        GatekeeperDecision {
            inject_list,
            should_write_candidate,
            hit_refs,
            validate_plans,
            reasons,
            signals,
        }
    }
}

// ---- helpers ----

fn to_inject_item(m: &SearchMatch) -> InjectItem {
    InjectItem {
        qa_id: m.qa_id.clone(),
        question: m.question.clone(),
        answer: m.answer.clone(),
        summary: m.summary.clone(),
        trust: m.trust,
        validation_level: m.validation_level,
        score: m.score,
        tags: m.tags.clone(),
    }
}

fn is_stale(m: &SearchMatch, now: DateTime<Utc>) -> bool {
    let Some(s) = &m.expiry_at else { return false; };
    // ISO8601 parse
    match DateTime::parse_from_rfc3339(s) {
        Ok(dt) => dt.with_timezone(&Utc) <= now,
        Err(_) => false, // parse 失败不当 stale（避免误杀）
    }
}

fn extract_i32(meta: &Value, key: &str) -> Option<i32> {
    meta.get(key).and_then(|v| {
        if v.is_i64() {
            v.as_i64().map(|x| x as i32)
        } else if v.is_u64() {
            v.as_u64().map(|x| x as i32)
        } else if v.is_string() {
            v.as_str()?.parse::<i32>().ok()
        } else {
            None
        }
    })
}

// 轻量 digest：不引入 crypto 依赖，先做“长度+前后片段”作为诊断指纹
fn digest_cheap(s: &str) -> Value {
    let len = s.len();
    let head = s.chars().take(80).collect::<String>();
    let tail = s.chars().rev().take(80).collect::<String>().chars().rev().collect::<String>();
    serde_json::json!({ "len": len, "head": head, "tail": tail })
}
用法示例（在 pipeline 里）
use chrono::Utc;

let cfg = GatekeeperConfig::default();
let now = Utc::now();

// matches: Vec<SearchMatch> 来自 /v1/qa/search 的 items 反序列化
// run: RunOutcome 由 runner 收集（exit_code/stdout_tail/stderr_tail + shown/used）
let decision = Gatekeeper::evaluate(&cfg, now, &matches, &run);

// 1) 注入：decision.inject_list
// 2) hit：decision.hit_refs
// 3) validate：decision.validate_plans
// 4) candidate：decision.should_write_candidate
你需要我接着补的两块（建议按顺序）
把 Search API 响应 JSON → Vec<SearchMatch> 的反序列化适配（含字段缺省/兼容）
把 GatekeeperDecision 映射为 Memory API 的 payload：/v1/qa/hit、/v1/qa/validate、/v1/qa/candidates
你把 /v1/qa/search 实际返回的 JSON 顶层结构贴一段（比如 {"matches":[...]} 还是 {"items":[...]}），我就把反序列化与映射一次性补齐到可运行。

You:
1

ChatGPT:
[Unsupported Content]

ChatGPT:
[Unsupported Content]

ChatGPT:
下面把 Search API 响应 JSON → Vec<SearchMatch> 这一块补齐成“可直接用、兼容性强”的 Rust 实现（支持顶层是 items / matches / 直接数组 3 种形态；字段缺失时给默认值；metadata/tags 兜底）。

你把它加到 src/memory_adapters.rs（或 src/gatekeeper/adapter.rs）即可。

1）兼容性强的反序列化结构
// src/memory_adapters.rs
use serde::Deserialize;
use serde_json::Value;

use crate::gatekeeper::SearchMatch;

/// Search 响应可能的顶层结构：
/// 1) {"items":[...]}  2) {"matches":[...]}  3) [...]（直接数组）
/// 以及可能混合附带 {"ok":true,"data":{"items":[...]}} 之类。
///
/// 这里提供一个稳健的解析入口：
/// - 优先找 items/matches
/// - 再找 data.items / data.matches
/// - 再尝试把整个 Value 当数组
pub fn parse_search_matches(v: &Value) -> Result<Vec<SearchMatch>, String> {
    // 1) 直接数组
    if let Some(arr) = v.as_array() {
        return parse_array(arr);
    }

    // 2) 顶层 items/matches
    if let Some(arr) = v.get("items").and_then(|x| x.as_array()) {
        return parse_array(arr);
    }
    if let Some(arr) = v.get("matches").and_then(|x| x.as_array()) {
        return parse_array(arr);
    }

    // 3) data.items / data.matches
    if let Some(arr) = v.get("data").and_then(|d| d.get("items")).and_then(|x| x.as_array()) {
        return parse_array(arr);
    }
    if let Some(arr) = v.get("data").and_then(|d| d.get("matches")).and_then(|x| x.as_array()) {
        return parse_array(arr);
    }

    // 4) 兜底：尝试在任何一层找到第一个数组字段（谨慎）
    if let Some(arr) = find_first_array(v) {
        return parse_array(arr);
    }

    Err("search response does not contain items/matches array".to_string())
}

fn parse_array(arr: &[Value]) -> Result<Vec<SearchMatch>, String> {
    let mut out = Vec::with_capacity(arr.len());
    let mut errs: Vec<String> = Vec::new();

    for (i, item) in arr.iter().enumerate() {
        match serde_json::from_value::<SearchMatchCompat>(item.clone()) {
            Ok(x) => out.push(x.into()),
            Err(e) => errs.push(format!("#{}: {}", i, e)),
        }
    }

    // 允许部分失败：只要成功解析到至少 1 条就返回；否则返回错误细节
    if !out.is_empty() {
        Ok(out)
    } else {
        Err(format!("failed to parse all matches: {}", errs.join("; ")))
    }
}

/// 找到任意层级的第一个数组（谨慎兜底）。
fn find_first_array<'a>(v: &'a Value) -> Option<&'a Vec<Value>> {
    match v {
        Value::Array(a) => Some(a),
        Value::Object(map) => {
            for (_k, vv) in map.iter() {
                if let Some(a) = vv.as_array() {
                    return Some(a);
                }
                if let Some(a) = find_first_array(vv) {
                    return Some(a);
                }
            }
            None
        }
        _ => None,
    }
}

/// 兼容字段缺失/命名差异的中间结构：
/// - metadata/tags 可能缺失
/// - summary/source/confidence 可能缺失
/// - expiry_at 可能是 null/""/不存在
/// - level 字段可能是 string/number/不存在（这里只当 string 可选）
#[derive(Debug, Clone, Deserialize)]
struct SearchMatchCompat {
    pub qa_id: String,

    #[serde(default)]
    pub project_id: String,

    #[serde(default)]
    pub question: String,

    #[serde(default)]
    pub answer: String,

    #[serde(default)]
    pub summary: Option<String>,

    #[serde(default)]
    pub score: f32,

    #[serde(default)]
    pub relevance: f32,

    #[serde(default)]
    pub trust: f32,

    #[serde(default)]
    pub freshness: f32,

    #[serde(default)]
    pub validation_level: i32,

    #[serde(default)]
    pub level: Option<String>,

    #[serde(default = "default_status")]
    pub status: String,

    /// 你的返回是 metadata；有些实现可能叫 meta，这里做 alias
    #[serde(default, alias = "meta")]
    pub metadata: Value,

    #[serde(default)]
    pub tags: Vec<String>,

    /// 注意：你的字段是 expiry_at；有些实现叫 expires_at
    #[serde(default, alias = "expires_at")]
    pub expiry_at: Option<String>,

    #[serde(default)]
    pub source: Option<String>,

    #[serde(default)]
    pub confidence: Option<f32>,
}

fn default_status() -> String {
    "active".to_string()
}

impl From<SearchMatchCompat> for SearchMatch {
    fn from(x: SearchMatchCompat) -> Self {
        // 清理 expiry_at：空字符串当 None
        let expiry_at = x
            .expiry_at
            .and_then(|s| {
                let s2 = s.trim().to_string();
                if s2.is_empty() { None } else { Some(s2) }
            });

        SearchMatch {
            qa_id: x.qa_id,
            project_id: x.project_id,
            question: x.question,
            answer: x.answer,
            summary: x.summary,
            score: x.score,
            relevance: x.relevance,
            trust: x.trust,
            freshness: x.freshness,
            validation_level: x.validation_level,
            level: x.level,
            status: x.status,
            metadata: x.metadata,
            tags: x.tags,
            expiry_at,
            source: x.source,
            confidence: x.confidence,
        }
    }
}
2）你需要的改动点
确保你项目里已经有我之前给的 SearchMatch 定义（在 src/gatekeeper.rs 里）。
在需要用到 search 的地方：
let raw = memory.search(payload).await?; // raw: serde_json::Value
let matches = crate::memory_adapters::parse_search_matches(&raw)
    .map_err(|e| RunnerError::Spawn(e))?;
3）设计取舍说明（避免踩坑）
部分解析失败不阻断：只要解析到至少 1 条就继续（符合“观察模式”的鲁棒性）。
metadata 允许是任意 JSON：你后续可从中读取 consecutive_fail 等字段（如果服务端放进去）。
expiry_at 空字符串归一为 None：避免服务端返回 "" 造成 stale 误判。
如果你把 search 的顶层 JSON 样例（最好 5～10 行）贴出来，我还能把 find_first_array 这个兜底逻辑进一步收紧，避免误把其它数组字段（比如 errors: []）当成结果数组。

You:
search接口的数据已经是顶层

ChatGPT:
明白了：search 响应已经是顶层数组或顶层包含 items/matches，那我们可以把适配器收紧，去掉“递归找任意数组”的兜底（避免误判 errors: [] 之类），并把错误信息更明确。

下面给你一个“严格版”解析器：只接受 3 种顶层形态：

[...]（顶层数组）
{"matches":[...]}
{"items":[...]}
严格版：parse_search_matches_top_level
// src/memory_adapters.rs
use serde::Deserialize;
use serde_json::Value;

use crate::gatekeeper::SearchMatch;

pub fn parse_search_matches_top_level(v: &Value) -> Result<Vec<SearchMatch>, String> {
    // 1) 顶层数组
    if let Some(arr) = v.as_array() {
        return parse_array(arr);
    }

    // 2) 顶层 matches/items
    if let Some(arr) = v.get("matches").and_then(|x| x.as_array()) {
        return parse_array(arr);
    }
    if let Some(arr) = v.get("items").and_then(|x| x.as_array()) {
        return parse_array(arr);
    }

    Err("search response must be top-level array or object with {matches:[...]} / {items:[...]}".to_string())
}

fn parse_array(arr: &[Value]) -> Result<Vec<SearchMatch>, String> {
    let mut out = Vec::with_capacity(arr.len());
    let mut errs: Vec<String> = Vec::new();

    for (i, item) in arr.iter().enumerate() {
        match serde_json::from_value::<SearchMatchCompat>(item.clone()) {
            Ok(x) => out.push(x.into()),
            Err(e) => errs.push(format!("#{}: {}", i, e)),
        }
    }

    if !out.is_empty() {
        Ok(out)
    } else {
        Err(format!("failed to parse all matches: {}", errs.join("; ")))
    }
}

#[derive(Debug, Clone, Deserialize)]
struct SearchMatchCompat {
    pub qa_id: String,

    #[serde(default)]
    pub project_id: String,

    #[serde(default)]
    pub question: String,

    #[serde(default)]
    pub answer: String,

    #[serde(default)]
    pub summary: Option<String>,

    #[serde(default)]
    pub score: f32,

    #[serde(default)]
    pub relevance: f32,

    #[serde(default)]
    pub trust: f32,

    #[serde(default)]
    pub freshness: f32,

    #[serde(default)]
    pub validation_level: i32,

    #[serde(default)]
    pub level: Option<String>,

    #[serde(default = "default_status")]
    pub status: String,

    #[serde(default, alias = "meta")]
    pub metadata: Value,

    #[serde(default)]
    pub tags: Vec<String>,

    #[serde(default, alias = "expires_at")]
    pub expiry_at: Option<String>,

    #[serde(default)]
    pub source: Option<String>,

    #[serde(default)]
    pub confidence: Option<f32>,
}

fn default_status() -> String { "active".to_string() }

impl From<SearchMatchCompat> for SearchMatch {
    fn from(x: SearchMatchCompat) -> Self {
        let expiry_at = x.expiry_at.and_then(|s| {
            let t = s.trim().to_string();
            if t.is_empty() { None } else { Some(t) }
        });

        SearchMatch {
            qa_id: x.qa_id,
            project_id: x.project_id,
            question: x.question,
            answer: x.answer,
            summary: x.summary,
            score: x.score,
            relevance: x.relevance,
            trust: x.trust,
            freshness: x.freshness,
            validation_level: x.validation_level,
            level: x.level,
            status: x.status,
            metadata: x.metadata,
            tags: x.tags,
            expiry_at,
            source: x.source,
            confidence: x.confidence,
        }
    }
}
在 Runner / Pipeline 里怎么用
let raw = memory.search(payload).await?; // serde_json::Value
let matches = crate::memory_adapters::parse_search_matches_top_level(&raw)
    .map_err(|e| RunnerError::Spawn(e))?;

let decision = Gatekeeper::evaluate(&gk_cfg, chrono::Utc::now(), &matches, &run_outcome);
小提醒（根据你贴的 match 结构）
你给的字段是 expiry_at（不是 expires_at），我已经把 expires_at 作为 alias 兼容了，但你这边用不到也不影响。

如果你确认永远都是顶层数组（不是 {matches:[]}），我还能再进一步把解析器简化成：

v.as_array().ok_or(...) 直接 parse
你只要说一句“永远是顶层数组”。

You:
python 返回list[dict[str, Any]]

ChatGPT:
明白：Python 的 search 接口直接返回 list[dict[str, Any]]（顶层就是数组）。
那在 Rust 侧我们可以进一步简化，不需要兼容 items/matches，也不需要递归兜底——这反而更安全、更可控。

下面我把最终推荐方案一次性整理清楚。

一、最终约定（定死，别再兜底）
Python → Rust 接口契约
Python 返回值类型：
List[Dict[str, Any]]
Rust 收到的是：
serde_json::Value  // 但它必须是 Array
不接受：

{ items: [...] }
{ matches: [...] }
{ ok: true, data: [...] }
👉 只接受顶层数组，否则就是接口错误。

二、Rust：最简 & 最安全的解析函数
这是你现在应该用的最终版。

// src/memory_adapters.rs
use serde::Deserialize;
use serde_json::Value;

use crate::gatekeeper::SearchMatch;

pub fn parse_search_matches(v: &Value) -> Result<Vec<SearchMatch>, String> {
    let arr = v
        .as_array()
        .ok_or("search response must be top-level array (List[Dict])")?;

    let mut out = Vec::with_capacity(arr.len());
    let mut errs: Vec<String> = Vec::new();

    for (i, item) in arr.iter().enumerate() {
        match serde_json::from_value::<SearchMatchCompat>(item.clone()) {
            Ok(x) => out.push(x.into()),
            Err(e) => errs.push(format!("#{}: {}", i, e)),
        }
    }

    if !out.is_empty() {
        Ok(out)
    } else {
        Err(format!(
            "failed to parse all search items: {}",
            errs.join("; ")
        ))
    }
}
三、SearchMatchCompat（对齐你 Python 返回结构）
这部分 100% 对齐你给的 matches.append({...})：

#[derive(Debug, Clone, Deserialize)]
struct SearchMatchCompat {
    pub qa_id: String,

    #[serde(default)]
    pub project_id: String,

    #[serde(default)]
    pub question: String,

    #[serde(default)]
    pub answer: String,

    #[serde(default)]
    pub summary: Option<String>,

    #[serde(default)]
    pub score: f32,

    #[serde(default)]
    pub relevance: f32,

    #[serde(default)]
    pub trust: f32,

    #[serde(default)]
    pub freshness: f32,

    #[serde(default)]
    pub validation_level: i32,

    #[serde(default)]
    pub level: Option<String>,

    #[serde(default = "default_status")]
    pub status: String,

    #[serde(default, alias = "meta")]
    pub metadata: serde_json::Value,

    #[serde(default)]
    pub tags: Vec<String>,

    #[serde(default)]
    pub expiry_at: Option<String>,

    #[serde(default)]
    pub source: Option<String>,

    #[serde(default)]
    pub confidence: Option<f32>,
}

fn default_status() -> String {
    "active".to_string()
}
转换为 Gatekeeper 使用的 SearchMatch
impl From<SearchMatchCompat> for SearchMatch {
    fn from(x: SearchMatchCompat) -> Self {
        let expiry_at = x.expiry_at.and_then(|s| {
            let s = s.trim().to_string();
            if s.is_empty() { None } else { Some(s) }
        });

        SearchMatch {
            qa_id: x.qa_id,
            project_id: x.project_id,
            question: x.question,
            answer: x.answer,
            summary: x.summary,
            score: x.score,
            relevance: x.relevance,
            trust: x.trust,
            freshness: x.freshness,
            validation_level: x.validation_level,
            level: x.level,
            status: x.status,
            metadata: x.metadata,
            tags: x.tags,
            expiry_at,
            source: x.source,
            confidence: x.confidence,
        }
    }
}
四、Pipeline 中的标准用法
// Python 返回：List[Dict[str, Any]]
let raw: serde_json::Value = memory.search(payload).await?;

// 强约束：必须是数组
let matches = parse_search_matches(&raw)?;

// Gatekeeper 裁决
let decision = Gatekeeper::evaluate(
    &gatekeeper_cfg,
    chrono::Utc::now(),
    &matches,
    &run_outcome,
);
五、为什么这个版本是“对的”
✅ 1. 契约清晰
Python：返回 list
Rust：只吃 array
接口错了立刻失败，不悄悄吞 bug
✅ 2. Gatekeeper 安全性最高
不会误把 errors: [] / logs: [] 当搜索结果
不会因为结构变化悄悄降级
✅ 3. 方便你以后做 CI / Schema 校验
你甚至可以在 Python 侧加：
assert isinstance(result, list)
六、下一步你唯一值得继续做的事
现在这条链路已经完全打通：

Python search → Rust parse → Gatekeeper.evaluate

👉 下一步只剩一件真正有价值的事：

🔥 把 GatekeeperDecision 映射成 Memory API 调用
/v1/qa/hit
/v1/qa/validate
/v1/qa/candidates
如果你愿意，我可以下一条直接把 这 3 个 API 的 Rust client + payload 构造函数一次性写完（直接可用）。
你只要回一句：“继续 2”。

You:
继续 2

ChatGPT:
[Unsupported Content]

ChatGPT:
[Unsupported Content]

ChatGPT:
下面把 GatekeeperDecision → Memory API（hit / validate / candidates） 这条链路一次性补齐到“可直接用”的 Rust 实现。假设你 Memory 服务接口如下（与你之前的 client 设计一致）：

POST /v1/qa/hit
POST /v1/qa/validate
POST /v1/qa/candidates
并且 search 返回是顶层数组 list[dict]（你已确认）。

1）新增：Memory API Client（send_hit / send_validate / send_candidates）
文件：src/memory_client.rs

use serde::{Deserialize, Serialize};
use serde_json::Value;

#[derive(Clone)]
pub struct MemoryClient {
    base_url: String,
    api_key: String,
    http: reqwest::Client,
}

impl MemoryClient {
    pub fn new(base_url: String, api_key: String, timeout_ms: u64) -> Result<Self, String> {
        let http = reqwest::Client::builder()
            .timeout(std::time::Duration::from_millis(timeout_ms))
            .build()
            .map_err(|e| e.to_string())?;

        Ok(Self { base_url, api_key, http })
    }

    fn endpoint(&self, path: &str) -> String {
        format!("{}/{}", self.base_url.trim_end_matches('/'), path.trim_start_matches('/'))
    }

    fn auth(&self, req: reqwest::RequestBuilder) -> reqwest::RequestBuilder {
        if self.api_key.trim().is_empty() {
            req
        } else {
            req.bearer_auth(&self.api_key)
        }
    }

    pub async fn send_hit(&self, payload: &QAHitsPayload) -> Result<Value, String> {
        let url = self.endpoint("/v1/qa/hit");
        let resp = self
            .auth(self.http.post(url).json(payload))
            .send()
            .await
            .map_err(|e| e.to_string())?;

        resp.json::<Value>().await.map_err(|e| e.to_string())
    }

    pub async fn send_validate(&self, payload: &QAValidationPayload) -> Result<Value, String> {
        let url = self.endpoint("/v1/qa/validate");
        let resp = self
            .auth(self.http.post(url).json(payload))
            .send()
            .await
            .map_err(|e| e.to_string())?;

        resp.json::<Value>().await.map_err(|e| e.to_string())
    }

    pub async fn send_candidate(&self, payload: &QACandidatePayload) -> Result<Value, String> {
        let url = self.endpoint("/v1/qa/candidates");
        let resp = self
            .auth(self.http.post(url).json(payload))
            .send()
            .await
            .map_err(|e| e.to_string())?;

        resp.json::<Value>().await.map_err(|e| e.to_string())
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QAReferencePayload {
    pub qa_id: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub shown: Option<bool>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub used: Option<bool>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub message_id: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub context: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QAHitsPayload {
    pub project_id: String,
    pub references: Vec<QAReferencePayload>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QAValidationPayload {
    pub project_id: String,
    pub qa_id: String,

    pub result: String, // "pass" | "fail"
    pub signal_strength: String, // "strong" | "medium" | "weak"
    pub strong_signal: bool,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub context: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub ts: Option<String>,

    #[serde(default)]
    pub payload: Value,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QACandidatePayload {
    pub project_id: String,
    pub question: String,
    pub answer: String,

    #[serde(default, skip_serializing_if = "Vec::is_empty")]
    pub tags: Vec<String>,

    #[serde(default)]
    pub confidence: f32,

    #[serde(default)]
    pub metadata: Value,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub summary: Option<String>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub source: Option<String>,
}
依赖确保有：

reqwest = { version="0.12", features=["json","rustls-tls"] }
serde, serde_json
chrono（后面会用 ts）
2）新增：GatekeeperDecision → Payload 映射器
文件：src/memory_mapping.rs

这个模块负责把你 GatekeeperDecision 里产出的 hit_refs/validate_plans 变成 API payload。

use chrono::Utc;
use serde_json::Value;

use crate::gatekeeper::{GatekeeperDecision, HitRef, ValidatePlan};
use crate::memory_client::{QAHitsPayload, QAReferencePayload, QAValidationPayload, QACandidatePayload};

/// GatekeeperDecision.hit_refs -> /v1/qa/hit payload
pub fn build_hit_payload(project_id: &str, decision: &GatekeeperDecision) -> Option<QAHitsPayload> {
    if decision.hit_refs.is_empty() {
        return None;
    }

    let refs = decision
        .hit_refs
        .iter()
        .map(|r| QAReferencePayload {
            qa_id: r.qa_id.clone(),
            shown: Some(r.shown),
            used: Some(r.used),
            message_id: r.message_id.clone(),
            context: r.context.clone(),
        })
        .collect::<Vec<_>>();

    Some(QAHitsPayload {
        project_id: project_id.to_string(),
        references: refs,
    })
}

/// GatekeeperDecision.validate_plans -> /v1/qa/validate payloads
pub fn build_validate_payloads(project_id: &str, decision: &GatekeeperDecision) -> Vec<QAValidationPayload> {
    decision
        .validate_plans
        .iter()
        .map(|p| QAValidationPayload {
            project_id: project_id.to_string(),
            qa_id: p.qa_id.clone(),
            result: p.result.clone(),
            signal_strength: p.signal_strength.clone(),
            strong_signal: p.strong_signal,
            context: p.context.clone(),
            ts: Some(Utc::now().to_rfc3339()),
            payload: p.payload.clone(),
        })
        .collect()
}

/// candidate 写入：这里提供一个“草稿结构”，由你的 Candidate 抽取器生成。
#[derive(Debug, Clone)]
pub struct CandidateDraft {
    pub question: String,
    pub answer: String,
    pub tags: Vec<String>,
    pub confidence: f32,
    pub metadata: Value,
    pub summary: Option<String>,
    pub source: Option<String>,
}

/// CandidateDraft -> /v1/qa/candidates payload
pub fn build_candidate_payloads(project_id: &str, drafts: &[CandidateDraft]) -> Vec<QACandidatePayload> {
    drafts
        .iter()
        .map(|d| QACandidatePayload {
            project_id: project_id.to_string(),
            question: d.question.clone(),
            answer: d.answer.clone(),
            tags: d.tags.clone(),
            confidence: d.confidence,
            metadata: d.metadata.clone(),
            summary: d.summary.clone(),
            source: d.source.clone(),
        })
        .collect()
}
说明：CandidateDraft 的生成目前你还没做（P1 事件），所以这里先把“映射器”准备好，等你抽取器就位后直接接入。

3）在 Pipeline 里把三条 API 调用接起来
下面给你一个“最小可用”的调用片段（通常放在 run 结束后）：

use crate::memory_mapping::{build_hit_payload, build_validate_payloads, build_candidate_payloads, CandidateDraft};

pub async fn post_run_memory_reporting(
    mem: &crate::memory_client::MemoryClient,
    project_id: &str,
    decision: &crate::gatekeeper::GatekeeperDecision,
    candidate_drafts: Vec<CandidateDraft>,
) {
    // 1) hit（可选）
    if let Some(hit_payload) = build_hit_payload(project_id, decision) {
        let _ = mem.send_hit(&hit_payload).await;
    }

    // 2) validate（建议强推）
    for v in build_validate_payloads(project_id, decision) {
        let _ = mem.send_validate(&v).await;
    }

    // 3) candidate（由 GatekeeperDecision.should_write_candidate 控制）
    if decision.should_write_candidate && !candidate_drafts.is_empty() {
        let payloads = build_candidate_payloads(project_id, &candidate_drafts);
        for c in payloads {
            let _ = mem.send_candidate(&c).await;
        }
    }
}
这里全部是 best-effort（不影响主流程退出码）。你后面要做“更严格的错误处理/重试/落盘补偿”，可以再加一层 outbox。

4）你现在已经闭合的链路
到这里你已有：

search（Python 返回 list[dict]） → Rust parse → Vec<SearchMatch>
Gatekeeper.evaluate(...) → GatekeeperDecision
GatekeeperDecision → /hit /validate /candidates 的 payload 构造
MemoryClient 发送三类 API
你只差两块会让系统“真正有记忆价值”的关键实现：

Prompt 注入模板（用 decision.inject_list）
CandidateDraft 抽取器（从 stdout_tail/tool_events 提炼 Q/A）
如果你希望我继续按优先级往下写：我建议下一步先做 Prompt 注入模板（因为 candidate 抽取可以后置）。你回一句“继续 3：注入模板”，我就把注入格式与接入点直接给成可用代码。

You:
继续 3：注入模板

ChatGPT:
下面给你一套可直接落地的“Search→Prompt 注入模板 + 代码实现”，满足：

使用 GatekeeperDecision.inject_list（只包含强/可信的 QA）
支持两种注入位点：system 或 user（你可配置）
兼容你已有的 “QA anchors / [QA_REF qa-xxxx]” 习惯
默认“只给模型可用信息，不把长答案塞爆上下文”
为后续 hit/used 判定预留：在注入内容里带稳定的 QA_REF
1）注入模板规范（冻结版 v1）
1.1 注入块结构（推荐）
标题：说明这些是“可复用已验证知识”
每条 QA：
QA_REF <qa_id>
Question: 一行
Answer: 建议用 summary 优先；没有 summary 才截断 answer
Tags/Level/Trust（简短）
Usage Rules：如何引用与回传
模板示例（渲染后的文本）
[MEMORY_CONTEXT v1]
The following items are retrieved from the memory system. Prefer using them when relevant.
If you use an item, include its anchor exactly once in your final answer: [QA_REF qa-xxxx].

1) [QA_REF qa-123]
Q: How to fix <...>?
A: <summary or truncated answer...>
Meta: level=2 trust=0.82 score=0.71 tags=rust,cli

2) [QA_REF qa-456]
Q: ...
A: ...
Meta: level=3 trust=0.93 score=0.66 tags=mcp,tools

Rules:
- Do not invent anchors.
- If none are relevant, ignore them.
- Prefer the highest validation_level and trust.
[/MEMORY_CONTEXT]
你后续要做 “used 判定”，就让模型在最终回答里出现 [QA_REF qa-123]，wrapper 再从 stdout 抓取并回传 hit/validate。

2）Rust 实现：构造注入文本（可直接用）
文件：src/prompt_inject.rs

use crate::gatekeeper::InjectItem;

/// 注入位点：system 或 user（你可以从 TOML 配置）
#[derive(Debug, Clone, Copy)]
pub enum InjectPlacement {
    System,
    User,
}

/// 注入配置：控制长度与格式
#[derive(Debug, Clone)]
pub struct InjectConfig {
    pub placement: InjectPlacement,
    pub max_items: usize,
    pub max_answer_chars: usize, // answer 截断长度
    pub include_meta_line: bool,
}

impl Default for InjectConfig {
    fn default() -> Self {
        Self {
            placement: InjectPlacement::System,
            max_items: 3,
            max_answer_chars: 900,
            include_meta_line: true,
        }
    }
}

/// 将 GatekeeperDecision.inject_list 渲染成一段可注入 prompt 的文本块
pub fn render_memory_context(items: &[InjectItem], cfg: &InjectConfig) -> String {
    if items.is_empty() {
        return String::new();
    }

    let mut out = String::new();
    out.push_str("[MEMORY_CONTEXT v1]\n");
    out.push_str("The following items are retrieved from the memory system. Prefer using them when relevant.\n");
    out.push_str("If you use an item, include its anchor exactly once in your final answer: [QA_REF <qa_id>].\n\n");

    for (idx, it) in items.iter().take(cfg.max_items).enumerate() {
        let n = idx + 1;
        out.push_str(&format!("{n}) [QA_REF {}]\n", it.qa_id));
        out.push_str(&format!("Q: {}\n", one_line(&it.question)));
        let a = pick_answer(it, cfg.max_answer_chars);
        out.push_str(&format!("A: {}\n", a));

        if cfg.include_meta_line {
            out.push_str(&format!(
                "Meta: level={} trust={:.2} score={:.2} tags={}\n",
                it.validation_level,
                it.trust,
                it.score,
                if it.tags.is_empty() { "-" } else { it.tags.join(",").as_str() }
            ));
        }
        out.push('\n');
    }

    out.push_str("Rules:\n");
    out.push_str("- Do not invent anchors.\n");
    out.push_str("- If none are relevant, ignore them.\n");
    out.push_str("- Prefer the highest validation_level and trust.\n");
    out.push_str("[/MEMORY_CONTEXT]\n");

    out
}

fn pick_answer(it: &InjectItem, max_chars: usize) -> String {
    let raw = if let Some(s) = &it.summary {
        s.as_str()
    } else {
        it.answer.as_str()
    };
    truncate_clean(raw, max_chars)
}

fn one_line(s: &str) -> String {
    s.split_whitespace().collect::<Vec<_>>().join(" ")
}

fn truncate_clean(s: &str, max_chars: usize) -> String {
    let mut t = s.trim().to_string();
    t = t.replace("\r\n", "\n");
    if t.chars().count() <= max_chars {
        return t;
    }
    let mut out = String::new();
    for (i, ch) in t.chars().enumerate() {
        if i >= max_chars {
            break;
        }
        out.push(ch);
    }
    out.push_str(" …");
    out
}
3）如何“把注入文本真正送进 codecli”（两种模式）
由于你现在是 codex/claude/gemini + MCP，不同 CLI 的注入方式不同。为避免绑死具体参数，我建议先实现一个“通用最小法”：把注入块追加到用户输入之前（User placement），它对任何 CLI 都有效。

3.1 通用法：把 memory_context 拼进 prompt（推荐先跑通）
你在启动 codecli 前，把用户 query 变成：

<MEMORY_CONTEXT...>

<User original query...>
这不需要依赖 codecli 的 system 参数。

Rust 拼接函数
文件：src/prompt_inject.rs 追加：

pub fn merge_prompt(user_query: &str, memory_context: &str) -> String {
    if memory_context.trim().is_empty() {
        return user_query.to_string();
    }
    format!("{memory_context}\n{user_query}")
}
然后在 runner 启动参数构建处，把原始 query 替换为 merge_prompt(...) 的结果。

3.2 更强法：CLI 支持 system prompt 的话放 system（后续再做）
如果某个 CLI（例如某些模式的 codex/claude）支持 --system 或类似参数，把 memory_context 放 system 更干净。但这是“适配层工作”，建议你下一阶段单独做一个 CliFlavor。

4）如何回收 QA_REF 用于 hit/used（为你下一步铺路）
注入块要求模型在最终回答里包含：

[QA_REF qa-123]
你就能在 wrapper 侧：

从 stdout（最终回答）做一次 regex：
$QA_REF ([^$]+)$
得到 used_qa_ids
回传 hit/validate（你已经实现了映射与 client）
5）你现在应该怎么接入（最短路径）
在你的 pipeline：

search → parse matches
Gatekeeper.evaluate → decision
render_memory_context(decision.inject_list, cfg)
merge_prompt(user_query, memory_context)
用 merge 后 prompt 作为 codecli 的输入（或参数）
如果你告诉我：你当前调用 codecli 的方式是“把 query 作为参数传进去”还是“stdin 交互输入”，我可以把第 5 步的接入点写成你 Runner 里的具体代码（不需要你自己改参数拼接）。

You:
整理信息，列举目前待做的事件

ChatGPT:
下面是截至目前（已完成注入模板设计与实现）的一次“全量整理 + 待做事件清单”。这份清单已经扣除了已完成项，只保留真实还需要你动手或决定的事件，并按优先级分组，方便你直接拉进 Issue / Project Board。

一、当前系统“完成度快照”
已完成（或已给出可直接使用代码）
✅ Memory Search → Rust 解析

Python 返回 list[dict[str, Any]]
Rust 侧严格解析顶层数组 → Vec<SearchMatch>
✅ Gatekeeper.evaluate（核心逻辑）

三层闸门（状态/TTL/失败 → 等级/信任 → 生命周期）
产出：
inject_list
should_write_candidate
hit_refs
validate_plans
✅ Memory API Client

/v1/qa/hit
/v1/qa/validate
/v1/qa/candidates
✅ GatekeeperDecision → Memory API payload 映射

✅ Search → Prompt 注入模板（v1）

[MEMORY_CONTEXT v1]
[QA_REF qa-xxxx] 约定
Rust 渲染函数 + 合并 prompt 工具函数
到这里：search → inject → run → decision → memory 回传
逻辑已经完整闭环。

二、当前待做事件清单（真实 Backlog）
🔴 P0 — 必须完成（决定系统是否“真正工作”）
事件 P0-1：把注入模板“真正接入 Runner”
状态：未做（只给了工具函数）

你需要做的事：

决定 codecli 的输入方式：
☐ query 作为 CLI 参数
☐ query 通过 stdin
在 Runner 中：
调用 render_memory_context
调用 merge_prompt
用合并后的 prompt 启动 codecli
没有这一步，search / Gatekeeper / 注入模板都只是“纸面设计”。

事件 P0-2：QA_REF 回收（used 判定）
状态：未做

你需要做的事：

在 runner 结束后：
从 stdout 中提取：
[QA_REF qa-xxxx]
生成：
run.used_qa_ids
传给 Gatekeeper.evaluate
这一步决定：

hit 是否准确
validate 是否“真有效”
🟠 P1 — 强烈建议尽快做（决定“记忆质量”）
事件 P1-1：CandidateDraft 抽取器（启发式版）
状态：未做

目标：

在 should_write_candidate == true 时
从以下来源生成 0～1 条候选：
stdout_tail
tool_events（尤其 MCP 工具调用）
最小可用规则即可：

包含明确步骤 / 命令
通过安全扫描（无 token / key）
自动生成：
question（模板化）
answer（步骤 + 注意事项）
事件 P1-2：Validate 强弱信号细化
状态：半完成（目前只看 exit_code）

建议补充：

strong：
test/build success
明确 “success / passed” 关键字
medium：
exit_code=0 但无验证输出
weak：
仅展示，未执行
这会显著提升 trust_score 的收敛速度。

🟡 P2 — 增强项（可后置）
事件 P2-1：Prompt 注入位置策略
状态：只实现 User prepend

可选增强：

system 注入（若 CLI 支持）
限制 memory_context 的 token 占比
多轮对话时只注入一次
事件 P2-2：Gatekeeper 决策日志 / 可观测性
状态：未做

建议：

将 GatekeeperDecision.reasons / signals
打到 debug log
或写 JSONL（方便离线分析）
事件 P2-3：参数配置化（TOML）
状态：未做

包括：

min_trust_show
min_level_inject
max_inject
skip_if_top1_score_ge
🧊 P3 — 明确不做（当前阶段）
以下内容不应再进入当前迭代，否则复杂度会指数上升：

❌ Tool 审批 / policy allow-deny
❌ stdin 控制 / abort / Fail-Closed
❌ Gatekeeper 作为执行闸门
❌ 人工确认 / 交互式质量反馈
三、推荐你“下一步只做的一件事”
最高 ROI、最低风险、最短路径：

👉 实现 P0-1 + P0-2
把注入模板真正送进 codecli
把 [QA_REF] 从 stdout 抓回来
一旦完成：

hit / validate 会立刻变“真实”
trust_score 开始自我收敛
candidate 抽取再做才有意义
四、如果你愿意，我可以直接继续帮你做的事
你可以直接选一个编号：

把注入模板接入 Runner（给你具体 Rust 代码，按你现在的 Runner 结构）
实现 [QA_REF] 回收与 used 判定（regex + pipeline 集成）
写一个最小可用的 CandidateDraft 抽取器（不引入 LLM）
你只要回：继续 <编号>。

You:
继续1

ChatGPT:
[Unsupported Content]

ChatGPT:
[Unsupported Content]

ChatGPT:
下面给你把“注入模板真正接入 Runner”的落地实现整理成 可直接复制的 Rust 代码改动。我按两种最常见的 codecli 形态都给出实现：

A：query 通过 CLI 参数传入（最常见）
B：query 通过 stdin 传入（次常见）
你只需要选你项目里实际那一种，把对应片段放进 runner/mod.rs 与 runner/codecli.rs 即可。

0）接入点总览（你要做的事）
在 Runner 里按顺序做：

memory.search(...) 拿到 raw JSON（顶层 list）
parse_search_matches(...) → Vec<SearchMatch>
Gatekeeper::evaluate(...) → decision
render_memory_context(decision.inject_list, ...) → memory_context
merge_prompt(user_query, &memory_context) → merged_prompt
用 merged_prompt 启动 codecli（通过 参数 或 stdin）
1）Runner：构造 merged_prompt（通用，A/B 都用）
假设你已有这些模块：

memory_client::MemoryClient
memory_adapters::parse_search_matches
gatekeeper::{Gatekeeper, GatekeeperConfig, RunOutcome}
prompt_inject::{InjectConfig, render_memory_context, merge_prompt}
在 runner/mod.rs 中，spawn 之前加：

use chrono::Utc;

use crate::memory_adapters::parse_search_matches;
use crate::prompt_inject::{InjectConfig, render_memory_context, merge_prompt};

async fn build_merged_prompt(
    memory: Option<&crate::memory_client::MemoryClient>,
    project_id: &str,
    user_query: &str,
) -> Result<(String, Vec<String>), String> {
    // 返回 (merged_prompt, shown_qa_ids)
    if memory.is_none() {
        return Ok((user_query.to_string(), vec![]));
    }
    let mem = memory.unwrap();

    // 1) search
    let raw = mem
        .search(crate::memory::QASearchPayload {
            project_id: project_id.to_string(),
            query: user_query.to_string(),
            limit: 6,
            min_score: 0.2,
        })
        .await
        .map_err(|e| e.to_string())?;

    // 2) parse top-level list[dict]
    let matches = parse_search_matches(&raw).map_err(|e| e)?;

    // 3) gatekeeper（这里 run_outcome 先给空壳：仅用于注入筛选）
    let gk_cfg = crate::gatekeeper::GatekeeperConfig::default();
    let dummy_run = crate::gatekeeper::RunOutcome {
        exit_code: 0,
        duration_ms: None,
        stdout_tail: "".to_string(),
        stderr_tail: "".to_string(),
        shown_qa_ids: vec![],
        used_qa_ids: vec![],
    };
    let decision = crate::gatekeeper::Gatekeeper::evaluate(&gk_cfg, Utc::now(), &matches, &dummy_run);

    // 4) render + merge
    let inject_cfg = InjectConfig::default();
    let memory_ctx = render_memory_context(&decision.inject_list, &inject_cfg);
    let merged = merge_prompt(user_query, &memory_ctx);

    // shown_qa_ids 用于后续 hit（注入即 shown）
    let shown = decision.inject_list.iter().map(|x| x.qa_id.clone()).collect::<Vec<_>>();

    Ok((merged, shown))
}
shown_qa_ids 你后面可以塞进真正的 RunOutcome，用于 /hit 回传。

2）A 方案：query 通过 CLI 参数传入（推荐先用这个）
2.1 修改 runner/codecli.rs：支持传入 prompt 参数
把你原来的 spawn(&Args) 改成 spawn_with_prompt(&Args, prompt: &str)：

// src/runner/codecli.rs
use tokio::process::Command;
use std::process::Stdio;

use crate::{cli::Args, error::RunnerError};

pub fn spawn_with_prompt(args: &Args, prompt: &str) -> Result<tokio::process::Child, RunnerError> {
    let mut cmd = Command::new(&args.codecli_bin);
    // 这里按你的 codecli 实际参数拼装：
    // 例：codecli run --prompt "<...>"
    cmd.arg("run");
    cmd.arg("--prompt");
    cmd.arg(prompt);

    // 你已有的其他参数照旧追加（model、profile、workspace 等）
    // cmd.args(&args.extra);

    cmd.stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .stderr(Stdio::piped());

    cmd.spawn().map_err(|e| RunnerError::Spawn(e.to_string()))
}
注意：--prompt / run 这些是示例。你要按你实际 codecli 的参数替换，但结构就是这样：把 merged_prompt 当成一个完整的字符串参数传进去。

2.2 修改 runner/mod.rs：用 merged_prompt 启动
在你原来 spawn(&args) 的地方替换为：

let (merged_prompt, shown_qa_ids) =
    build_merged_prompt(memory.as_ref(), &cfg.project_id, &args.user_query).await
        .map_err(|e| RunnerError::Spawn(e))?;

// 用 merged_prompt 启动 codecli
let mut child = codecli::spawn_with_prompt(&args, &merged_prompt)?;

// 后面跑完后，把 shown_qa_ids 塞进 RunOutcome，用于 hit
// run_outcome.shown_qa_ids = shown_qa_ids;
3）B 方案：query 通过 stdin 传入（如果 codecli 支持从 stdin 读 prompt）
这种情况下，spawn 时不需要传 --prompt，而是在 child 启动后写 stdin。

3.1 codecli.rs 维持 spawn（不带 prompt）
pub fn spawn(args: &Args) -> Result<tokio::process::Child, RunnerError> {
    let mut cmd = Command::new(&args.codecli_bin);
    // 例：codecli run（从 stdin 读）
    cmd.arg("run");

    cmd.stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .stderr(Stdio::piped());

    cmd.spawn().map_err(|e| RunnerError::Spawn(e.to_string()))
}
3.2 runner/mod.rs：spawn 后写 stdin
use tokio::io::AsyncWriteExt;

let (merged_prompt, shown_qa_ids) =
    build_merged_prompt(memory.as_ref(), &cfg.project_id, &args.user_query).await
        .map_err(|e| RunnerError::Spawn(e))?;

let mut child = codecli::spawn(&args)?;

// 写入 stdin（注意加换行，很多 CLI 以换行作为提交）
if let Some(mut stdin) = child.stdin.take() {
    let _ = stdin.write_all(merged_prompt.as_bytes()).await;
    let _ = stdin.write_all(b"\n").await;
    // drop(stdin) 让对方读到 EOF（有的 CLI 需要 EOF 才开始执行）
}
4）你现在需要确认的最小字段（不问你也能做，但你要对齐代码）
为了让上面代码能编译，你的 Args 至少要有：

pub struct Args {
    pub codecli_bin: String,
    pub user_query: String,
    // ...
}
如果你现在 Args 还没有 user_query（而是剩余参数 args.rest），就把“原始用户输入”抽出来填进去即可。

5）你接完以后立刻能看到的效果
每次 run 前，都会把 [MEMORY_CONTEXT v1] 拼到用户输入前面
模型在回答里如果按规则输出 [QA_REF qa-xxxx]，你就能下一步做 used 回收（你已计划 P0-2）
命中 strong 的 QA 会减少 candidate 写入（Gatekeeper 已做）
如果你把 runner/codecli.rs 里实际 Command 参数构建那段贴出来（10～30 行就够），我可以把上面 A/B 方案精确改成你项目的最终版本（不需要你再手工替换参数名）。

You:
继续2

ChatGPT:
下面继续 第 2 部分：CLI 参数与配置 TOML 的精确 schema（并把你这套 qa_memory OpenAPI 里的关键接口一起纳入配置模型，便于 MemoryClient 落地对接） fileciteturn3file6

2. CLI 参数与配置 TOML Schema（精确可落地）
2.1 设计目标
同一套配置同时驱动：
Runner：怎么启动/管理 codecli 子进程、stdin 控制协议、stdout/stderr tee
MemoryClient：怎么调用 QA Memory API（search/candidate/hit/validate/expire/detail）fileciteturn3file6
Gatekeeper/Policy：命中策略、是否写回、阈值、退避与熔断
CLI 参数覆盖配置文件（最后落地为一个“ResolvedConfig”）
允许 profile：--profile dev|prod|ci
允许分模块热替换：比如只换 memory endpoint/token，不动 runner
2.2 CLI 参数（clap）定义草案
建议命令结构（子命令 + 全局参数）：

memwrap run：包装执行某条命令（核心路径）
memwrap doctor：环境自检（codecli 可执行、网络、权限、配置有效性）
memwrap config print：打印解析后的最终配置（含覆盖关系）
memwrap qa search|hit|validate|expire|detail：直接调 QA API（便于联调）fileciteturn3file6
全局参数（适用于所有子命令）：

--config <path>：默认 ./memwrap.toml
--profile <name>：默认 default
--log-level trace|debug|info|warn|error
--json：输出机器可读 JSON（doctor / config print / qa 子命令很有用）
--span-root <name>：覆盖根 span 名（用于 observability 统一命名）
run 子命令关键参数（都可覆盖 TOML）：

--cmd "<string>" 或 -- <argv...>（二选一）
--cwd <path>
--env KEY=VAL（可重复）
--stdin-proto jsonl|off
--control-channel enabled|disabled
--timeout-ms <u64>
--kill-grace-ms <u64>
--tee stdout|stderr|both|off
--events-out <path>：JSONL 事件落盘（便于回放/排障）
--memory enabled|disabled
--memory-endpoint <url>
--memory-project <project_id>
--memory-token <token>（或 --memory-token-file）
2.3 memwrap.toml（精确 Schema）
2.3.1 顶层结构
version = 1

# 默认 profile
active_profile = "default"

[profiles.default]
# 引用下面的模块配置
runner = "runner.default"
memory = "memory.default"
policy = "policy.default"
observability = "obs.default"

[profiles.ci]
runner = "runner.ci"
memory = "memory.ci"
policy = "policy.ci"
observability = "obs.ci"
好处：配置可复用、可组合；CI 可以单独关掉 tee/降低超时/严格失败策略。

2.3.2 Runner 模块
[runner.default]
# codecli 可执行文件（留空则走 PATH 探测）
codecli_path = "codecli"

# 子进程工作目录（空 = 继承当前）
cwd = ""

# 额外环境变量（会合并到子进程 env）
env = { }

# stdin 控制协议：off / jsonl（你后面要的 stdin 控制通道）
stdin_protocol = "jsonl"

# 控制通道开关（控制消息与业务输入分流时有用）
control_channel = true

# 进程超时（0 = 不超时，但不推荐）
timeout_ms = 0

# 优雅退出等待；超时则强杀
kill_grace_ms = 3000

# stdout/stderr 处理
tee = "both"          # off|stdout|stderr|both
line_buffered = true  # 是否按行 flush（利于 JSONL 事件解析）

# 事件落盘（空=不落盘）
events_out = ""

# Windows 相关（重点：不弹窗、信号兼容）
[runner.default.windows]
creation_flags = ["NO_WINDOW"]  # 你的 tokio/Windows 需求可以映射到这里
ctrlc_forward = true

[runner.default.unix]
forward_signals = ["SIGINT", "SIGTERM"]
2.3.3 Memory 模块（对接 QA Memory OpenAPI）
结合你上传的 OpenAPI（/v1/qa/search, /v1/qa/candidates, /v1/qa/hit, /v1/qa/validate, /v1/qa/expire, /v1/qa/{qa_id}）设计如下：fileciteturn3file6

[memory.default]
enabled = true

# 服务端地址（例如 https://api.xxx.com ）
base_url = "http://127.0.0.1:8000"

# 认证（按你后端实现：Bearer / header / query）
auth_type = "bearer"         # bearer|header|none
token = ""                   # 推荐留空，走 token_file 或 env
token_file = ""              # 例如 ~/.config/memwrap/token
header_name = "Authorization" # auth_type=header 时用

# QA 维度（detail 接口要求 project_id query 参数）
project_id = "default-project"

# HTTP 行为
timeout_ms = 5000
connect_timeout_ms = 1500
max_retries = 2
retry_backoff_ms = 200
concurrency = 8

# 端点路径（默认按 OpenAPI；允许覆盖以兼容网关前缀）fileciteturn3file6
endpoints = { 
  qa_search = "/v1/qa/search",
  qa_candidate = "/v1/qa/candidates",
  qa_hit = "/v1/qa/hit",
  qa_validate = "/v1/qa/validate",
  qa_expire = "/v1/qa/expire",
  qa_detail = "/v1/qa/{qa_id}"
}

# 查询与写回的默认参数（可被 Policy 覆盖）
[memory.default.defaults]
namespace = "global"
time_sensitivity = "medium"
tags = []
2.3.4 Policy 模块（命中/写回/验证）
[policy.default]
# 是否自动 search
search_on_start = true

# search 的 top_k
top_k = 5

# 置信门槛：低于阈值不“命中写回 hit”
min_score_to_hit = 0.65

# 是否自动写 hit（用于统计/学习）
auto_hit = true

# 是否自动产生 candidate（生成答案后，走 Gatekeeper 决策）
auto_candidate = true

# 是否自动 validate（你要的 qa_validate_and_update 流程可挂这里）
auto_validate = true

# Gatekeeper 规则（示例）
[policy.default.gatekeeper]
require_no_strong_retrieval = true
require_reusable = true
require_no_secrets = true
min_structure_score = 0.7

# 退避/熔断（控制 channel 断线、API 不可用时）
[policy.default.resilience]
circuit_breaker_enabled = true
failure_threshold = 5
cooldown_ms = 30000
2.3.5 Observability 模块（span 命名规范在第 3 部分会更细）
[obs.default]
service_name = "memwrap"
trace = true
metrics = true

# span 命名前缀
span_root = "memwrap.run"

# JSONL 结构化日志
json_logs = true
2.4 配置覆盖与解析顺序（落地规则）
最终解析顺序建议固定为：

内置默认值（代码里）
memwrap.toml 的 profiles.<active> 选择模块
CLI --config/--profile 覆盖 profile 选择
CLI 参数覆盖具体字段（--memory-base-url 等）
环境变量覆盖敏感项（token、project_id）：
MEMWRAP_TOKEN
MEMWRAP_PROJECT_ID
生成 ResolvedConfig（序列化可 config print 输出）
2.5 最小可用 memwrap.toml 示例
version = 1
active_profile = "default"

[profiles.default]
runner = "runner.default"
memory = "memory.default"
policy = "policy.default"
observability = "obs.default"

[runner.default]
codecli_path = "codecli"
stdin_protocol = "jsonl"
control_channel = true
tee = "both"
kill_grace_ms = 3000

[memory.default]
enabled = true
base_url = "http://127.0.0.1:8000"
auth_type = "bearer"
project_id = "demo"
timeout_ms = 5000

[policy.default]
search_on_start = true
top_k = 5
min_score_to_hit = 0.65
auto_hit = true
auto_candidate = true
auto_validate = true

[obs.default]
service_name = "memwrap"
json_logs = true
span_root = "memwrap.run"
如果你这一步 OK，我下一段（第 3 部分）会继续把：

Rust 模块目录结构与关键 trait（Runner/MemoryClient/Gatekeeper/Policy）
thiserror 分层错误类型 & span 命名规范（逐条列举）
ToolEventParser trait + JSONL 事件格式约定（含字段、版本、兼容策略）
一起补齐，并且会把 QA OpenAPI 的 payload/response 映射成 Rust 类型（serde + reqwest），做到可直接开工。 fileciteturn3file6

You:
整理信息，目前待做的事情

ChatGPT:
下面是截至当前节点的统一整理版待办清单（Backlog）。
我已经把已完成 / 已定型的内容全部剔除，只保留真正还需要你继续推进或做决策的事情，并按优先级排序，方便你直接照单执行或转成 Issue。

一、当前系统所处阶段（一句话定位）
设计已收敛、主链路已打通 80%
当前处于：“注入已接入，回收与沉淀尚未完成” 的阶段。

二、待做事项总览（按优先级）
🔴 P0 — 必须完成（决定系统是否形成“学习闭环”）
P0-1：QA_REF 回收（used 判定）
状态：未做

要做什么

从 codecli 最终 stdout 中解析：
[QA_REF qa-xxxx]
提取所有出现的 qa_id
填充到：
run_outcome.used_qa_ids
传入 Gatekeeper.evaluate
为什么重要

决定 hit / validate 是否“真实”
没有 used 判定，validate 的信号价值会严重下降
P0-2：Validate 回传真正接上执行结果
状态：半完成（目前只看 exit_code）

要做什么

基于 stdout / stderr / tool_events：
区分 strong / medium / weak 信号
示例规则：
strong：tests/build 成功关键词
medium：exit_code=0 但无验证输出
weak：仅展示未执行
为什么重要

这是 QA-Score / trust_score 真正“学习”的入口
🟠 P1 — 强烈建议尽快完成（决定“记忆质量”）
P1-1：CandidateDraft 抽取器（启发式）
状态：未做

要做什么

在 decision.should_write_candidate == true 时：
从 stdout_tail / tool_events 中抽取 0–1 条候选
生成：
question（模板化）
answer（步骤 + 注意事项）
tags / confidence / metadata
约束

search 已命中 validation_level >= 2 时 禁止生成
必须通过基础安全检查（无 token/secret）
P1-2：Hit 回传策略细化
状态：未做

要做什么

明确：
shown = true：被注入到 prompt
used = true：被 QA_REF 引用
构造 /v1/qa/hit payload
为什么重要

命中统计是 search 排序与权重调整的重要信号
🟡 P2 — 增强项（可后置，不影响闭环）
P2-1：Prompt 注入策略增强
状态：基础版已完成

可选增强：

system / user 注入可配置
memory_context token 上限
多轮对话只注入一次
P2-2：Gatekeeper 决策日志 & 可观测性
状态：未做

要做什么

输出：
GatekeeperDecision.reasons
GatekeeperDecision.signals
用于：
调参
排障
离线分析
P2-3：Gatekeeper / Policy 参数配置化
状态：未做

包括：

min_trust_show
min_level_inject
max_inject
skip_if_top1_score_ge
🧊 P3 — 明确不做（当前阶段禁止扩展）
以下事项已明确不进入当前阶段：

❌ tool 调用审批 / policy allow-deny
❌ stdin 阻断 / abort / Fail-Closed
❌ 人工确认闸门
❌ Gatekeeper 参与执行控制
三、推荐执行顺序（最短路径）
如果你只按顺序做 3 件事，建议是：

P0-1：QA_REF 回收（used 判定）
P0-2：Validate 信号分级
P1-1：CandidateDraft 抽取器
完成这三步后，你将得到：

一个能自动注入 → 使用 → 验证 → 学习 → 逐步沉淀知识的系统

四、你可以让我继续直接写代码的部分
你现在可以直接选一个，我会给你可复制的完整 Rust 实现：

QA_REF 回收（stdout 解析 + pipeline 集成）
Validate 信号分级实现（基于 stdout/stderr/tool_events）
最小可用 CandidateDraft 抽取器（无 LLM）
你只要回复：
👉 继续 <编号>

You:
继续1/2

ChatGPT:
[Unsupported Content]

ChatGPT:
[Unsupported Content]

ChatGPT:
下面把 P0-1（QA_REF 回收） 和 P0-2（Validate 信号分级） 一次性落成“可直接用”的 Rust 代码（含集成点）。你复制进去就能跑，不依赖 LLM、不改变执行行为。

1）QA_REF 回收（stdout → used_qa_ids）
1.1 解析函数
文件：src/qa_ref.rs

use regex::Regex;
use std::collections::BTreeSet;

/// 从模型最终输出中提取所有 [QA_REF qa-xxxx] 的 qa_id
/// - 去重
/// - 保序不重要（BTreeSet 会排序），如果你要保序可改用 IndexSet
pub fn extract_qa_refs(text: &str) -> Vec<String> {
    // 允许 qa_id 包含字母数字、下划线、短横线
    // 匹配形如：[QA_REF qa-123] 或 [QA_REF abc_def-01]
    let re = Regex::new(r"$QA_REF\s+([A-Za-z0-9_\-]+)$").expect("valid regex");
    let mut set = BTreeSet::new();

    for cap in re.captures_iter(text) {
        if let Some(m) = cap.get(1) {
            set.insert(m.as_str().to_string());
        }
    }

    set.into_iter().collect()
}
Cargo 依赖：regex = "1"

1.2 接入点（run 结束后填充 used_qa_ids）
你在 runner 收尾构造 RunOutcome 时，加入：

use crate::qa_ref::extract_qa_refs;

// stdout_tail 你已有（ring buffer tail）
let used_qa_ids = extract_qa_refs(&run_outcome.stdout_tail);

// shown_qa_ids 你在注入阶段已经拿到（注入即 shown）
// 这里把 used 写进去
run_outcome.used_qa_ids = used_qa_ids;
注意：stdout_tail 要尽量包含“最终回答”，如果你 ring buffer 太小，建议单独保留“最后 N 行文本”。

2）Validate 信号分级（strong/medium/weak + pass/fail）
目标：把你现在“只看 exit_code”的 validate，升级成更可靠的强/中/弱信号。

2.1 规则（默认可用）
pass/fail：
exit_code == 0 → pass
else → fail
signal_strength：
strong：exit_code == 0 且 stdout/stderr 命中“成功关键字”
medium：exit_code == 0 但未命中成功关键字（或 exit_code != 0 但能明确定位错误）
weak：只有展示/无执行证据（当前阶段先不用太复杂；如果 used_qa_ids 为空也可降级）
2.2 实现
文件：src/validate_signal.rs

use regex::Regex;

/// validate 的判定结果
#[derive(Debug, Clone)]
pub struct ValidationSignal {
    pub result: String,          // "pass" | "fail"
    pub signal_strength: String, // "strong" | "medium" | "weak"
    pub strong_signal: bool,
    pub reason: String,
}

/// 可配置关键字集合（先硬编码，后续再进 TOML）
#[derive(Debug, Clone)]
pub struct SignalHeuristics {
    pub success_patterns: Vec<Regex>,
    pub fail_patterns: Vec<Regex>,
}

impl Default for SignalHeuristics {
    fn default() -> Self {
        // 覆盖常见工程/测试/构建输出；你可按栈补充（cargo/npm/pytest/go test 等）
        let success = vec![
            Regex::new(r"(?i)\btests?\s+passed\b").unwrap(),
            Regex::new(r"(?i)\ball\s+tests?\s+passed\b").unwrap(),
            Regex::new(r"(?i)\bbuild\s+succeeded\b").unwrap(),
            Regex::new(r"(?i)\bcompile(d)?\s+success(fully)?\b").unwrap(),
            Regex::new(r"(?i)\bfinished\b.*\bsuccess\b").unwrap(),
            Regex::new(r"(?i)\bpass(ed)?\b").unwrap(),
            Regex::new(r"(?i)\bok\b").unwrap(),
        ];

        let fail = vec![
            Regex::new(r"(?i)\bfailed\b").unwrap(),
            Regex::new(r"(?i)\berror\b").unwrap(),
            Regex::new(r"(?i)\bpanic\b").unwrap(),
            Regex::new(r"(?i)\bexception\b").unwrap(),
            Regex::new(r"(?i)\btraceback\b").unwrap(),
        ];

        Self { success_patterns: success, fail_patterns: fail }
    }
}

/// 根据运行结果给出 validate 的强/中/弱信号
pub fn grade_validation_signal(
    exit_code: i32,
    stdout_tail: &str,
    stderr_tail: &str,
    used_qa_ids_count: usize,
    heur: &SignalHeuristics,
) -> ValidationSignal {
    let joined = format!("{stdout_tail}\n{stderr_tail}");

    let is_pass = exit_code == 0;
    let hit_success = heur.success_patterns.iter().any(|re| re.is_match(&joined));
    let hit_fail = heur.fail_patterns.iter().any(|re| re.is_match(&joined));

    // result
    let result = if is_pass { "pass" } else { "fail" }.to_string();

    // signal strength
    // - strong：pass + success keyword + 至少使用过某条 QA（used_qa_ids_count>0）
    // - medium：pass 但无 success keyword；或 fail 且有 fail keyword（说明是“明确失败”）
    // - weak：其余（例如 fail 但输出不明确，或根本没用 QA）
    let (signal_strength, strong_signal, reason) = if is_pass && hit_success && used_qa_ids_count > 0 {
        ("strong".to_string(), true, "exit_code=0 + success markers + QA used".to_string())
    } else if is_pass && (hit_success || used_qa_ids_count > 0) {
        ("medium".to_string(), false, "exit_code=0 but not strong-enough markers".to_string())
    } else if !is_pass && hit_fail {
        ("medium".to_string(), false, "exit_code!=0 with explicit failure markers".to_string())
    } else {
        ("weak".to_string(), false, "insufficient evidence for strong/medium".to_string())
    };

    ValidationSignal { result, signal_strength, strong_signal, reason }
}
Cargo 依赖同样用 regex = "1"。

2.3 接入 Gatekeeper.evaluate（替换你之前仅 exit_code 的分级）
在 Gatekeeper::evaluate 里构造 validate_plan 时，把这段：

let (result, signal_strength, strong_signal) = if run.exit_code == 0 {
    ("pass".to_string(), "strong".to_string(), true)
} else {
    ("fail".to_string(), "medium".to_string(), false)
};
替换为：

use crate::validate_signal::{grade_validation_signal, SignalHeuristics};

let heur = SignalHeuristics::default();
let sig = grade_validation_signal(
    run.exit_code,
    &run.stdout_tail,
    &run.stderr_tail,
    run.used_qa_ids.len(),
    &heur,
);

// 后面用 sig.result / sig.signal_strength / sig.strong_signal
let result = sig.result.clone();
let signal_strength = sig.signal_strength.clone();
let strong_signal = sig.strong_signal;
并建议把 sig.reason 写进 ValidatePlan.context 或 payload 里，便于调参：

context: Some(format!(
    "exit_code={}, duration_ms={:?}, reason={}",
    run.exit_code, run.duration_ms, sig.reason
)),
3）validate 目标选择（配合 QA_REF 更准确）
你之前的选择策略是：

优先 used_qa_ids
used 为空就 validate inject_list[0]
这仍然成立；现在有 QA_REF 后，准确性明显提升。

4）你完成这两步后，系统会发生的关键变化
你能准确回传：
/v1/qa/hit：shown vs used
/v1/qa/validate：strong/medium/weak（真实信号）
trust_score 与 validation_level 会开始稳定收敛
Gatekeeper 的“抑制 candidate”会更有效（因为强知识更快升级）
如果你下一步要继续，我建议直接做 P1-1：CandidateDraft 抽取器（启发式版），这样就能在“无强匹配”的场景自动沉淀新知识。你回：继续 3 即可。

You:
继续3

ChatGPT:
[Unsupported Content]

ChatGPT:
[Unsupported Content]

ChatGPT:
下面继续 P1-1：CandidateDraft 抽取器（启发式版，无 LLM），目标是在 decision.should_write_candidate == true 时，从 stdout_tail / stderr_tail / tool_events 自动沉淀 0–1 条可复用 QA。

我给你：

抽取器模块（完整 Rust 代码）
最小 secret 扫描与脱敏
如何接入 pipeline（与 /v1/qa/candidates 打通）
1）Candidate 抽取器模块
文件：src/candidate_extract.rs

use regex::Regex;
use serde_json::Value;

use crate::memory_mapping::CandidateDraft;

/// 你项目里如果已有 ToolEvent，建议改成直接复用；
/// 这里给一个最小可用视图（可用 From 转换）。
#[derive(Debug, Clone)]
pub struct ToolEventLite {
    pub tool: String,
    pub action: Option<String>,
    pub args: Value,
    pub ok: Option<bool>,
}

/// 抽取配置（后续可进 TOML）
#[derive(Debug, Clone)]
pub struct CandidateExtractConfig {
    pub max_candidates: usize,     // 建议 1
    pub max_answer_chars: usize,   // 建议 1200
    pub min_answer_chars: usize,   // 建议 200
    pub context_lines: usize,      // 命令行上下文窗口
    pub redact: bool,
    pub strict_secret_block: bool, // 命中 secret 直接拒绝写入
}

impl Default for CandidateExtractConfig {
    fn default() -> Self {
        Self {
            max_candidates: 1,
            max_answer_chars: 1200,
            min_answer_chars: 200,
            context_lines: 8,
            redact: true,
            strict_secret_block: true,
        }
    }
}

/// 抽取入口：
/// - 返回 0..=max_candidates 条 CandidateDraft
/// - 只做启发式：命令块/错误块/工具事件摘要
pub fn extract_candidates(
    cfg: &CandidateExtractConfig,
    user_query: &str,
    stdout_tail: &str,
    stderr_tail: &str,
    tool_events: &[ToolEventLite],
) -> Vec<CandidateDraft> {
    if cfg.max_candidates == 0 {
        return vec![];
    }

    // 1) 先组装原始材料
    let mut combined = String::new();
    if !stdout_tail.trim().is_empty() {
        combined.push_str(stdout_tail);
        combined.push('\n');
    }
    if !stderr_tail.trim().is_empty() {
        combined.push_str(stderr_tail);
        combined.push('\n');
    }

    // 2) secret 扫描：命中则直接拒绝（严格模式）
    if cfg.strict_secret_block && contains_secret(&combined) {
        return vec![];
    }

    // 3) 抽取“命令块”作为答案主体（优先）
    let cmd_block = extract_command_block(stdout_tail, cfg.context_lines)
        .or_else(|| extract_command_block(stderr_tail, cfg.context_lines));

    // 4) 抽取“错误线索”（用于 question/注意事项）
    let err_hint = extract_error_hint(stderr_tail).or_else(|| extract_error_hint(stdout_tail));

    // 5) 工具事件摘要（可选增强）
    let tool_summary = summarize_tool_events(tool_events);

    // 6) 组装 question（模板化）
    let question = build_question(user_query, err_hint.as_deref(), tool_events);

    // 7) 组装 answer（步骤 + 注意事项）
    let mut answer = String::new();

    // 背景
    answer.push_str("## Context\n");
    answer.push_str(&format!("- Task: {}\n", one_line(user_query)));
    if let Some(h) = &err_hint {
        answer.push_str(&format!("- Error hint: {}\n", one_line(h)));
    }
    if !tool_summary.trim().is_empty() {
        answer.push_str(&format!("- Tools observed: {}\n", tool_summary));
    }
    answer.push('\n');

    // 步骤（命令块）
    answer.push_str("## Steps\n");
    if let Some(block) = cmd_block {
        answer.push_str("1. Run the following commands:\n");
        answer.push_str("```bash\n");
        answer.push_str(&block);
        if !block.ends_with('\n') {
            answer.push('\n');
        }
        answer.push_str("```\n");
    } else {
        // 兜底：没有命令块就提供可复用结构（但多数情况下会不够长，会被 min_answer_chars 拦掉）
        answer.push_str("1. Identify the failing command/output in your terminal logs.\n");
        answer.push_str("2. Apply the fix corresponding to the error hint.\n");
        answer.push_str("3. Re-run tests/build to confirm.\n");
    }

    // 注意事项
    answer.push_str("\n## Notes\n");
    if let Some(h) = &err_hint {
        answer.push_str(&format!("- If you see `{}`, focus on the dependency/configuration causing it.\n", trim_mid(h, 80)));
    } else {
        answer.push_str("- If the fix doesn't work, capture the exact error line and tool versions.\n");
    }
    answer.push_str("- Keep secrets (tokens/keys/passwords) out of logs and configs.\n");

    // 8) 脱敏（可选）
    let mut final_answer = answer;
    if cfg.redact {
        final_answer = redact_secrets(&final_answer);
    }

    // 9) 质量下限：太短就不写
    if final_answer.chars().count() < cfg.min_answer_chars {
        return vec![];
    }

    // 10) 截断上限
    final_answer = truncate_clean(&final_answer, cfg.max_answer_chars);

    // tags：从工具/关键词提取
    let tags = infer_tags(user_query, &final_answer, tool_events);

    let draft = CandidateDraft {
        question,
        answer: final_answer,
        tags,
        confidence: 0.45,
        metadata: serde_json::json!({
            "source": "heuristic_extractor_v1",
            "has_cmd_block": cmd_block.is_some(),
            "has_error_hint": err_hint.is_some(),
        }),
        summary: None,
        source: Some("mem-codecli".to_string()),
    };

    vec![draft]
}

/* ----------------- heuristics ----------------- */

fn extract_command_block(text: &str, context_lines: usize) -> Option<String> {
    let lines: Vec<&str> = text.lines().collect();
    if lines.is_empty() {
        return None;
    }

    // 识别“命令行风格”
    // - 以 "$ " 开头
    // - 或常见命令：cargo/git/npm/pnpm/yarn/go/pytest/python/pip/uv/docker/kubectl
    let cmd_re = Regex::new(r#"^(?:\s*\$\s+|\s*(cargo|git|npm|pnpm|yarn|bun|go|pytest|python|pip|uv|uvx|docker|kubectl)\b)"#)
        .ok()?;

    // 找最后一个命令行位置，取一段窗口作为命令块
    let mut last_idx: Option<usize> = None;
    for (i, l) in lines.iter().enumerate() {
        if cmd_re.is_match(l) {
            last_idx = Some(i);
        }
    }
    let idx = last_idx?;

    let start = idx.saturating_sub(context_lines);
    let end = (idx + context_lines + 1).min(lines.len());

    // 收集窗口内的“命令行与紧邻输出”，尽量去掉纯空行
    let mut out = String::new();
    for l in &lines[start..end] {
        let s = l.trim_end();
        if s.is_empty() {
            continue;
        }
        out.push_str(s);
        out.push('\n');
    }

    if out.trim().is_empty() { None } else { Some(out) }
}

fn extract_error_hint(text: &str) -> Option<String> {
    let lines: Vec<&str> = text.lines().collect();
    if lines.is_empty() {
        return None;
    }

    // 常见错误提示行
    let err_re = Regex::new(r#"(?i)\b(error|failed|panic|exception|traceback)\b"#).ok()?;

    // 优先取“最后一个明显错误行”
    for l in lines.iter().rev() {
        let s = l.trim();
        if s.len() < 6 { continue; }
        if err_re.is_match(s) {
            return Some(s.to_string());
        }
    }
    None
}

fn summarize_tool_events(events: &[ToolEventLite]) -> String {
    if events.is_empty() {
        return String::new();
    }
    // 只取最后 3 个工具名，避免太长
    let mut names: Vec<String> = Vec::new();
    for e in events.iter().rev().take(3) {
        let mut t = e.tool.clone();
        if let Some(a) = &e.action {
            t = format!("{}:{}", t, a);
        }
        names.push(t);
    }
    names.reverse();
    names.join(", ")
}

fn build_question(user_query: &str, err_hint: Option<&str>, tool_events: &[ToolEventLite]) -> String {
    // 优先带 error hint 的模板化问句
    if let Some(h) = err_hint {
        return format!("How to resolve `{}` when running: {}", trim_mid(h, 90), trim_mid(user_query, 120));
    }

    // 如果有工具事件，可提示“在某工具调用过程中”
    if let Some(t) = tool_events.last() {
        return format!("How to complete task using tool `{}` for: {}", t.tool, trim_mid(user_query, 140));
    }

    format!("How to: {}", trim_mid(user_query, 180))
}

fn infer_tags(user_query: &str, answer: &str, tool_events: &[ToolEventLite]) -> Vec<String> {
    let mut tags = Vec::new();
    let s = format!("{}\n{}", user_query, answer).to_lowercase();

    // 常见生态 tags
    if s.contains("cargo") || s.contains("rust") { tags.push("rust".into()); }
    if s.contains("npm") || s.contains("pnpm") || s.contains("node") { tags.push("nodejs".into()); }
    if s.contains("pytest") || s.contains("python") || s.contains("pip") || s.contains("uv") { tags.push("python".into()); }
    if s.contains("docker") { tags.push("docker".into()); }
    if s.contains("kubernetes") || s.contains("kubectl") { tags.push("k8s".into()); }
    if s.contains("mcp") { tags.push("mcp".into()); }

    // 工具事件名也可打 tag（轻量）
    for e in tool_events.iter() {
        let t = e.tool.to_lowercase();
        if t.contains("git") && !tags.contains(&"git".to_string()) { tags.push("git".into()); }
        if t.contains("fs") && !tags.contains(&"filesystem".to_string()) { tags.push("filesystem".into()); }
    }

    tags.sort();
    tags.dedup();
    tags
}

/* ----------------- secrets & redact ----------------- */

fn contains_secret(s: &str) -> bool {
    let patterns = secret_patterns();
    patterns.iter().any(|re| re.is_match(s))
}

fn redact_secrets(s: &str) -> String {
    let mut out = s.to_string();
    for re in secret_patterns() {
        out = re.replace_all(&out, "[REDACTED]").to_string();
    }
    out
}

fn secret_patterns() -> Vec<Regex> {
    vec![
        // OpenAI / generic API keys (best-effort)
        Regex::new(r"(?i)\b(sk-[A-Za-z0-9]{20,})\b").unwrap(),
        // AWS Access Key ID
        Regex::new(r"\bAKIA[0-9A-Z]{16}\b").unwrap(),
        // GitHub token (classic / fine-grained rough)
        Regex::new(r"(?i)\b(ghp|gho|ghu|ghs|ghr)_[A-Za-z0-9]{20,}\b").unwrap(),
        // JWT (very rough)
        Regex::new(r"\beyJ[A-Za-z0-9_\-]+=*\.[A-Za-z0-9_\-]+=*\.[A-Za-z0-9_\-]+=*\b").unwrap(),
        // Private key headers
        Regex::new(r"-----BEGIN (RSA|EC|OPENSSH|DSA)? ?PRIVATE KEY-----").unwrap(),
        // URI with user:pass@
        Regex::new(r"(?i)\b[a-z]+:\/\/[^\/\s:]+:[^\/\s@]+@").unwrap(),
    ]
}

/* ----------------- utils ----------------- */

fn one_line(s: &str) -> String {
    s.split_whitespace().collect::<Vec<_>>().join(" ")
}

fn truncate_clean(s: &str, max_chars: usize) -> String {
    let mut t = s.trim().to_string();
    t = t.replace("\r\n", "\n");
    if t.chars().count() <= max_chars {
        return t;
    }
    let mut out = String::new();
    for (i, ch) in t.chars().enumerate() {
        if i >= max_chars {
            break;
        }
        out.push(ch);
    }
    out.push_str(" …");
    out
}

fn trim_mid(s: &str, max_chars: usize) -> String {
    let t = one_line(s);
    if t.chars().count() <= max_chars { return t; }
    let head: String = t.chars().take(max_chars.saturating_sub(2)).collect();
    format!("{head}..")
}
依赖：

regex = "1"
serde_json = "1"
2）接入 pipeline（与 /v1/qa/candidates 打通）
你之前已经有：

decision.should_write_candidate
post_run_memory_reporting(..., candidate_drafts)
现在只需要在 run 完成后（并且已经做完 QA_REF 回收、validate 信号判定之后）加一段：

use crate::candidate_extract::{extract_candidates, CandidateExtractConfig, ToolEventLite};

// tool_events：你如果已有 Vec<ToolEvent>，在这里映射成 ToolEventLite；
// 暂时没有也可以传空 vec![]，抽取器仍然能靠 stdout/stderr 工作。
let tool_events_lite: Vec<ToolEventLite> = vec![]; // TODO: map from your ToolEvent

let cand_cfg = CandidateExtractConfig::default();
let candidate_drafts = if decision.should_write_candidate {
    extract_candidates(
        &cand_cfg,
        &args.user_query,           // 原始用户 query
        &run_outcome.stdout_tail,
        &run_outcome.stderr_tail,
        &tool_events_lite,
    )
} else {
    vec![]
};

// 然后交给你已有的回传函数
post_run_memory_reporting(
    &mem_client,
    &cfg.project_id,
    &decision,
    candidate_drafts,
).await;
3）与 Gatekeeper 的约束对齐（不会制造噪声）
这套抽取器天然遵循你的核心约束：

只有在 should_write_candidate == true 才会产出
命中 secret → 严格模式直接不写
太短（<200 chars）→ 不写
默认最多 1 条 candidate（防爆炸）
4）下一步（可选，但很值）
你现在 candidate 抽取已可用。下一步最值得做的是：

把你真实的 ToolEvent 映射成 ToolEventLite
这样 question/tags/steps 会更准（尤其是 MCP 工具调用链明显时）。
如果你把你项目里 ToolEvent 的 Rust struct（或 JSONL 格式）贴一段，我可以直接给你一个 impl From<&ToolEvent> for ToolEventLite 的映射实现。

You:
按照设计继续

ChatGPT:
[Unsupported Content]

ChatGPT:
[Unsupported Content]

ChatGPT:
好的，“按设计继续”的下一步，最顺的推进是把 ToolEvent 链路补齐并接入：

从 stdout/stderr 流里识别并解析 @@MEM_TOOL_EVENT@@ {JSON}
累积为 Vec<ToolEvent>（供 Gatekeeper / validate / candidate 抽取使用）
把 ToolEvent 映射为 ToolEventLite（给启发式 candidate 抽取器增强质量）
下面给你一套“可直接落地”的实现（模块 + 接入点），不依赖你当前 Runner 的具体细节。

1）ToolEvent 数据结构 + 解析器
文件：src/tool_event.rs

use serde::{Deserialize, Serialize};
use serde_json::Value;

pub const TOOL_EVENT_PREFIX: &str = "@@MEM_TOOL_EVENT@@";

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ToolEvent {
    #[serde(default)]
    pub v: i32,

    #[serde(rename = "type")]
    pub event_type: String, // "tool.request" | "tool.result" | ...

    #[serde(default)]
    pub ts: Option<String>,

    #[serde(default)]
    pub id: Option<String>,

    #[serde(default)]
    pub tool: Option<String>,

    #[serde(default)]
    pub action: Option<String>,

    #[serde(default)]
    pub args: Value,

    // tool.result
    #[serde(default)]
    pub ok: Option<bool>,

    #[serde(default)]
    pub output: Option<Value>,
}

/// 从单行文本中解析 ToolEvent：
/// - 必须以 @@MEM_TOOL_EVENT@@ 开头
/// - 后面紧跟一个 JSON object
pub fn parse_tool_event_line(line: &str) -> Option<ToolEvent> {
    let s = line.trim();
    if !s.starts_with(TOOL_EVENT_PREFIX) {
        return None;
    }
    let json_part = s[TOOL_EVENT_PREFIX.len()..].trim();
    if json_part.is_empty() {
        return None;
    }
    serde_json::from_str::<ToolEvent>(json_part).ok()
}

/// 用于调试/回放：将 ToolEvent 编码回一行 JSONL（带前缀）
pub fn format_tool_event_line(ev: &ToolEvent) -> String {
    let json = serde_json::to_string(ev).unwrap_or_else(|_| "{}".to_string());
    format!("{TOOL_EVENT_PREFIX} {json}")
}
2）ToolEvent → ToolEventLite 映射（接你 Candidate 抽取器）
文件：src/tool_event_lite.rs

use serde_json::Value;

use crate::candidate_extract::ToolEventLite;
use crate::tool_event::ToolEvent;

impl From<&ToolEvent> for ToolEventLite {
    fn from(e: &ToolEvent) -> Self {
        ToolEventLite {
            tool: e.tool.clone().unwrap_or_else(|| "unknown".to_string()),
            action: e.action.clone(),
            args: if e.args.is_null() { Value::Null } else { e.args.clone() },
            ok: e.ok,
        }
    }
}
3）Runner 接入点：在 tee 过程中收集 ToolEvent
你当前是做 stdout/stderr 流式 tee。接入方式是：每读到一行，就尝试 parse_tool_event_line，成功则 push 到 Vec<ToolEvent>。

下面是一个“最小可用”的通用函数，给你在 stdout/stderr 的 line loop 里调用。

文件：src/tool_event_collect.rs

use crate::tool_event::{parse_tool_event_line, ToolEvent};

#[derive(Default)]
pub struct ToolEventCollector {
    pub events: Vec<ToolEvent>,
}

impl ToolEventCollector {
    pub fn observe_line(&mut self, line: &str) {
        if let Some(ev) = parse_tool_event_line(line) {
            self.events.push(ev);
        }
    }
}
在你的 stdout/stderr loop 里怎么用（示意）
你应该有类似：

while let Some(line) = stdout_lines.next_line().await? {
    println!("{line}");
    // ...
}
改成：

use crate::tool_event_collect::ToolEventCollector;

let mut collector = ToolEventCollector::default();

// stdout loop
while let Some(line) = stdout_lines.next_line().await? {
    println!("{line}");
    collector.observe_line(&line);
    // 你已有的 ring buffer append 也照旧
}

// stderr loop
while let Some(line) = stderr_lines.next_line().await? {
    eprintln!("{line}");
    collector.observe_line(&line);
}
最终 runner 结束时，你就有：

let tool_events: Vec<ToolEvent> = collector.events;
4）把 tool_events 接进 Candidate 抽取器（增强质量）
在你之前那段 pipeline 里，把空的 vec![] 换成真实映射：

use crate::candidate_extract::{extract_candidates, CandidateExtractConfig};
use crate::tool_event_lite::ToolEventLite; // 实际上 From<&ToolEvent> 已实现
use crate::tool_event::ToolEvent;

// 假设你从 runner 拿到了 tool_events: Vec<ToolEvent>
let tool_events_lite = tool_events.iter().map(|e| ToolEventLite::from(e)).collect::<Vec<_>>();

let cand_cfg = CandidateExtractConfig::default();
let candidate_drafts = if decision.should_write_candidate {
    extract_candidates(
        &cand_cfg,
        &args.user_query,
        &run_outcome.stdout_tail,
        &run_outcome.stderr_tail,
        &tool_events_lite,
    )
} else {
    vec![]
};
5）把 tool_events 接进 Validate payload（可选但很值）
你现在 validate payload 里有 stdout/stderr digest。可以再加一个“工具摘要”，让服务端更好做归因：

在 Gatekeeper 里构造 ValidatePlan.payload 时追加：

let tools = tool_events.iter()
    .filter_map(|e| e.tool.clone())
    .collect::<std::collections::BTreeSet<_>>()
    .into_iter()
    .collect::<Vec<_>>();

payload: serde_json::json!({
  "exit_code": run.exit_code,
  "duration_ms": run.duration_ms,
  "stdout_tail_digest": digest_cheap(&run.stdout_tail),
  "stderr_tail_digest": digest_cheap(&run.stderr_tail),
  "tools": tools,
})
6）你现在“按设计继续”的下一步待办（非常具体）
完成上面代码接入后，下一步就该进入你设计里更系统的工程化：

ToolEventParser trait（把 observe_line 抽象成 trait，便于替换前缀/版本/多来源）
事件落盘（events_out JSONL）：collector 每收一个 event 就写一行（便于回放）
在 GatekeeperDecision.signals 增加 tool 统计（用于调参）
你如果要我继续按这个方向往下写，我建议下一条我直接给你：

ToolEventParser trait + PrefixedJsonlParser 实现
events_out 的异步写入器（带 backpressure，避免阻塞 tee）
你回一句：继续 ToolEventParser + events_out 即可。

You:
继续 ToolEventParser + events_out

ChatGPT:
[Unsupported Content]

ChatGPT:
[Unsupported Content]

ChatGPT:
下面给出 ToolEventParser trait + PrefixedJsonlParser 实现，以及 events_out 的异步落盘器（带 backpressure，不阻塞 tee），并提供 Runner 集成示例。全部按你当前“Observer Mode”设计：只采集、只记录，不影响执行。

1）ToolEventParser trait + PrefixedJsonlParser
文件：src/tool_event_parser.rs

use serde::{Deserialize, Serialize};
use serde_json::Value;

/// 工具事件（最小通用模型）
/// - v: 版本号，便于演进
/// - type: 事件类型（tool.request / tool.result / progress...）
/// - id: 可用于 request/result 关联（可选）
/// - tool/action/args/ok/output: 事件负载
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ToolEvent {
    #[serde(default)]
    pub v: i32,

    #[serde(rename = "type")]
    pub event_type: String,

    #[serde(default)]
    pub ts: Option<String>,

    #[serde(default)]
    pub id: Option<String>,

    #[serde(default)]
    pub tool: Option<String>,

    #[serde(default)]
    pub action: Option<String>,

    #[serde(default)]
    pub args: Value,

    #[serde(default)]
    pub ok: Option<bool>,

    #[serde(default)]
    pub output: Option<Value>,
}

/// 解析器：从“文本行”里尝试解析出 ToolEvent
pub trait ToolEventParser: Send {
    /// 输入：原始行（不含换行）
    /// 输出：Some(event) 表示识别到了工具事件；None 表示不是事件行
    fn parse_line(&mut self, line: &str) -> Option<ToolEvent>;

    /// 用于把 ToolEvent 格式化回一行（用于 events_out 落盘）
    fn format_line(&self, ev: &ToolEvent) -> String;
}

/// 一个实现：前缀 + JSON（你目前使用的风格）
/// 行格式：@@MEM_TOOL_EVENT@@ {json}
pub struct PrefixedJsonlParser {
    prefix: &'static str,
}

impl PrefixedJsonlParser {
    pub fn new(prefix: &'static str) -> Self {
        Self { prefix }
    }
}

impl ToolEventParser for PrefixedJsonlParser {
    fn parse_line(&mut self, line: &str) -> Option<ToolEvent> {
        let s = line.trim();
        if !s.starts_with(self.prefix) {
            return None;
        }
        let json_part = s[self.prefix.len()..].trim();
        if json_part.is_empty() {
            return None;
        }
        serde_json::from_str::<ToolEvent>(json_part).ok()
    }

    fn format_line(&self, ev: &ToolEvent) -> String {
        let json = serde_json::to_string(ev).unwrap_or_else(|_| "{}".to_string());
        format!("{} {}", self.prefix, json)
    }
}
2）events_out：异步落盘器（带 backpressure）
目标：

tee 线程/任务只做 非阻塞 send（或短暂 await）
写文件在独立任务中完成
通道满时：按策略 丢弃或阻塞（默认丢弃，保证 runner 不被 IO 拖死）
文件：src/events_out.rs

use tokio::io::{AsyncWriteExt, BufWriter};
use tokio::sync::mpsc;

#[derive(Debug, Clone)]
pub struct EventsOutConfig {
    pub enabled: bool,
    pub path: String,
    pub channel_capacity: usize, // backpressure
    pub drop_when_full: bool,    // true: 满了就丢；false: 满了就 await（可能拖慢 tee）
}

impl Default for EventsOutConfig {
    fn default() -> Self {
        Self {
            enabled: false,
            path: "".to_string(),
            channel_capacity: 2048,
            drop_when_full: true,
        }
    }
}

/// 发送端：Runner/tee 调用它写事件行
#[derive(Clone)]
pub struct EventsOutTx {
    tx: mpsc::Sender<String>,
    dropped: std::sync::Arc<std::sync::atomic::AtomicU64>,
    drop_when_full: bool,
}

impl EventsOutTx {
    pub fn dropped_count(&self) -> u64 {
        self.dropped.load(std::sync::atomic::Ordering::Relaxed)
    }

    /// 尽量不阻塞：drop_when_full=true 时使用 try_send
    pub async fn send_line(&self, line: String) {
        if self.drop_when_full {
            if self.tx.try_send(line).is_err() {
                self.dropped
                    .fetch_add(1, std::sync::atomic::Ordering::Relaxed);
            }
        } else {
            if self.tx.send(line).await.is_err() {
                // writer 已结束，忽略
            }
        }
    }
}

/// 创建落盘任务
pub async fn start_events_out(cfg: &EventsOutConfig) -> Result<Option<EventsOutTx>, String> {
    if !cfg.enabled || cfg.path.trim().is_empty() {
        return Ok(None);
    }

    let (tx, mut rx) = mpsc::channel::<String>(cfg.channel_capacity);
    let dropped = std::sync::Arc::new(std::sync::atomic::AtomicU64::new(0));
    let dropped_clone = dropped.clone();
    let path = cfg.path.clone();
    let drop_when_full = cfg.drop_when_full;

    // writer task
    tokio::spawn(async move {
        // 打开文件（追加写）
        let file = match tokio::fs::OpenOptions::new()
            .create(true)
            .append(true)
            .open(&path)
            .await
        {
            Ok(f) => f,
            Err(_) => return, // 无法写就直接退出，不影响主流程
        };

        let mut w = BufWriter::new(file);
        while let Some(mut line) = rx.recv().await {
            if !line.ends_with('\n') {
                line.push('\n');
            }
            if w.write_all(line.as_bytes()).await.is_err() {
                return;
            }
        }

        // flush best-effort
        let _ = w.flush().await;

        // 防止编译器认为 dropped_clone 未使用（同时保留可扩展性）
        let _ = dropped_clone.load(std::sync::atomic::Ordering::Relaxed);
    });

    Ok(Some(EventsOutTx {
        tx,
        dropped,
        drop_when_full,
    }))
}
3）Collector：Parser + events_out + 内存累积
我们需要一个“聚合器”，在 stdout/stderr 每行都调用一次：

先尝试 parse tool event
parse 成功：push 到 events，并落盘
parse 失败：忽略
文件：src/tool_event_runtime.rs

use crate::events_out::EventsOutTx;
use crate::tool_event_parser::{ToolEvent, ToolEventParser};

pub struct ToolEventRuntime<P: ToolEventParser> {
    parser: P,
    events: Vec<ToolEvent>,
    events_out: Option<EventsOutTx>,
}

impl<P: ToolEventParser> ToolEventRuntime<P> {
    pub fn new(parser: P, events_out: Option<EventsOutTx>) -> Self {
        Self {
            parser,
            events: Vec::new(),
            events_out,
        }
    }

    /// 在 tee 中每读到一行调用一次（非阻塞/低开销）
    pub async fn observe_line(&mut self, line: &str) {
        if let Some(ev) = self.parser.parse_line(line) {
            // 内存收集
            self.events.push(ev.clone());

            // 落盘（异步，带 backpressure）
            if let Some(out) = &self.events_out {
                let s = self.parser.format_line(&ev);
                out.send_line(s).await;
            }
        }
    }

    pub fn into_events(self) -> Vec<ToolEvent> {
        self.events
    }

    pub fn dropped_events_out(&self) -> u64 {
        self.events_out.as_ref().map(|x| x.dropped_count()).unwrap_or(0)
    }
}
4）Runner 集成示例（stdout/stderr tee 中接入）
你当前应该是 tokio::io::BufReader::new(child.stdout.take().unwrap()).lines() 这种模式。下面给一个最常见集成方式：

关键点：stdout/stderr 是并行的；共享 runtime 需要 Arc<Mutex<...>>。

use tokio::io::{AsyncBufReadExt, BufReader};
use tokio::sync::Mutex;
use std::sync::Arc;

use crate::events_out::{start_events_out, EventsOutConfig};
use crate::tool_event_parser::{PrefixedJsonlParser};
use crate::tool_event_runtime::ToolEventRuntime;

pub async fn run_with_tool_events(
    mut child: tokio::process::Child,
    events_out_cfg: EventsOutConfig,
) -> Result<Vec<crate::tool_event_parser::ToolEvent>, String> {
    // 1) events_out writer
    let events_out_tx = start_events_out(&events_out_cfg).await?;

    // 2) tool event runtime（prefix 固定）
    let parser = PrefixedJsonlParser::new("@@MEM_TOOL_EVENT@@");
    let runtime = ToolEventRuntime::new(parser, events_out_tx);
    let runtime = Arc::new(Mutex::new(runtime));

    // 3) stdout task
    let rt1 = runtime.clone();
    let mut stdout_lines = BufReader::new(child.stdout.take().ok_or("missing stdout")?)
        .lines();
    let stdout_task = tokio::spawn(async move {
        while let Ok(Some(line)) = stdout_lines.next_line().await {
            // 你原来的 tee 输出
            println!("{line}");

            // tool event 观察
            rt1.lock().await.observe_line(&line).await;
        }
    });

    // 4) stderr task
    let rt2 = runtime.clone();
    let mut stderr_lines = BufReader::new(child.stderr.take().ok_or("missing stderr")?)
        .lines();
    let stderr_task = tokio::spawn(async move {
        while let Ok(Some(line)) = stderr_lines.next_line().await {
            eprintln!("{line}");
            rt2.lock().await.observe_line(&line).await;
        }
    });

    // 5) 等待子进程结束
    let _status = child.wait().await.map_err(|e| e.to_string())?;

    // 6) 等待 tee 任务结束（best-effort）
    let _ = stdout_task.await;
    let _ = stderr_task.await;

    // 7) 取回 events
    let mut guard = runtime.lock().await;
    let dropped = guard.dropped_events_out();
    if dropped > 0 {
        // 这里建议打 debug log：events_out 队列满导致丢弃
        // e.g. tracing::warn!(dropped, "events_out dropped lines");
        let _ = dropped;
    }

    // 把 runtime 移出 mutex：这里用 std::mem::take 技巧
    // 但 runtime 不是 Default，最简单是：clone events 并返回（events 通常不大）
    // 如果你担心复制，建议把 ToolEventRuntime.events 设计成 Arc<Vec<_>> 或用 Option 包一层。
    let events = std::mem::take(&mut guard.into_events());
    Ok(events)
}
上面最后 std::mem::take(&mut guard.into_events()) 在当前代码不可用（into_events 消费 self）。
更实用的做法是给 runtime 加一个 take_events(&mut self)：

把 ToolEventRuntime 增加这个方法即可：

pub fn take_events(&mut self) -> Vec<ToolEvent> {
    std::mem::take(&mut self.events)
}
然后 runner 里改为：

let events = guard.take_events();
Ok(events)
（这是推荐做法）

5）events_out 建议配置（与你的 TOML 对齐）
你之前 Runner 模块里已有：

events_out = ""
建议扩展成：

[runner.default.events_out]
enabled = true
path = "./run.events.jsonl"
channel_capacity = 2048
drop_when_full = true
并在 Rust 侧把 TOML 映射到 EventsOutConfig。

6）下一步按设计继续的“紧邻任务”
ToolEventParser + events_out 完成后，下一步最值得做的是：

把 ToolEvent 传入 validate payload（tools 摘要、request/result 计数、失败工具名）
ToolEvent → CandidateDraft 的步骤生成增强（优先用 tool.request 里的 args 形成可复用 steps）
在 GatekeeperDecision.signals 增加 tool 维度（例如 tool_event_count、tool_error_count）
你要我继续的话，回复：
“继续：ToolEvent 驱动 validate + candidate 增强”

You:
继续：ToolEvent 驱动 validate + candidate 增强

ChatGPT:
[Unsupported Content]

ChatGPT:
[Unsupported Content]

ChatGPT:
下面把 ToolEvent 驱动 validate + candidate 增强 按你现有代码体系继续落地：
核心目标是两件事：

Validate payload 更“可验证”：带上工具调用统计、失败工具、最后一次 tool.request/result 摘要，便于服务端做归因与 trust 收敛。
CandidateDraft 更“可复用”：优先用 tool.request 的参数/输入生成 Steps（比从 stdout 猜命令更准），并在 question/tags/notes 里融合 tool 线索。
1）ToolEvent 统计与摘要（用于 validate）
文件：src/tool_event_insights.rs

use crate::tool_event_parser::ToolEvent;
use serde_json::Value;
use std::collections::{BTreeMap, BTreeSet};

#[derive(Debug, Clone)]
pub struct ToolInsights {
    pub total: usize,
    pub by_type: BTreeMap<String, usize>,
    pub tools: Vec<String>,
    pub failing_tools: Vec<String>,
    pub last_request: Option<Value>,
    pub last_result: Option<Value>,
}

pub fn build_tool_insights(events: &[ToolEvent]) -> ToolInsights {
    let mut by_type: BTreeMap<String, usize> = BTreeMap::new();
    let mut tools: BTreeSet<String> = BTreeSet::new();
    let mut failing: BTreeSet<String> = BTreeSet::new();

    let mut last_req: Option<&ToolEvent> = None;
    let mut last_res: Option<&ToolEvent> = None;

    for e in events {
        *by_type.entry(e.event_type.clone()).or_insert(0) += 1;

        if let Some(t) = &e.tool {
            tools.insert(t.clone());
        }

        if e.event_type == "tool.request" {
            last_req = Some(e);
        } else if e.event_type == "tool.result" {
            last_res = Some(e);
            if e.ok == Some(false) {
                if let Some(t) = &e.tool {
                    failing.insert(t.clone());
                }
            }
        }
    }

    ToolInsights {
        total: events.len(),
        by_type,
        tools: tools.into_iter().collect(),
        failing_tools: failing.into_iter().collect(),
        last_request: last_req.map(slim_event),
        last_result: last_res.map(slim_event),
    }
}

/// 将事件裁剪成“可回传摘要”，避免 payload 过大
fn slim_event(e: &ToolEvent) -> Value {
    serde_json::json!({
        "v": e.v,
        "type": e.event_type,
        "ts": e.ts,
        "id": e.id,
        "tool": e.tool,
        "action": e.action,
        "ok": e.ok,
        // args 可能很大：只保留 top-level keys
        "args_keys": args_keys(&e.args),
    })
}

fn args_keys(v: &Value) -> Vec<String> {
    match v.as_object() {
        Some(map) => map.keys().cloned().take(32).collect(),
        None => vec![],
    }
}
2）把 ToolInsights 注入 validate payload（Gatekeeper.evaluate 接入）
你现在 Gatekeeper 构造 ValidatePlan.payload 的地方，追加工具维度。
在 Gatekeeper::evaluate(...) 函数签名里建议新增参数：

tool_events: &[ToolEvent]
也就是：

pub fn evaluate(
    cfg: &GatekeeperConfig,
    now: DateTime<Utc>,
    matches: &[SearchMatch],
    run: &RunOutcome,
    tool_events: &[crate::tool_event_parser::ToolEvent],
) -> GatekeeperDecision
然后在构造 validate payload 时：

use crate::tool_event_insights::build_tool_insights;

let insights = build_tool_insights(tool_events);

payload: serde_json::json!({
  "exit_code": run.exit_code,
  "duration_ms": run.duration_ms,
  "stdout_tail_digest": digest_cheap(&run.stdout_tail),
  "stderr_tail_digest": digest_cheap(&run.stderr_tail),

  // tool insights
  "tool_events_total": insights.total,
  "tool_events_by_type": insights.by_type,
  "tools": insights.tools,
  "failing_tools": insights.failing_tools,
  "last_tool_request": insights.last_request,
  "last_tool_result": insights.last_result,
})
同时建议把 insights.total 纳入 validate 信号分级（让 strong 更严格）：

如果 exit_code==0 且有 success markers 且 used_qa_ids>0 且 failing_tools 为空 → strong
如果存在 failing_tools → 至少降级到 medium（即便 exit_code==0）
在 grade_validation_signal(...) 里加一个参数：

failing_tools_count: usize
并改强信号条件：

if is_pass && hit_success && used_qa_ids_count > 0 && failing_tools_count == 0
3）Candidate 抽取增强：优先用 tool.request 生成 Steps
3.1 从 ToolEvent 抽取“可复用步骤”
文件：src/tool_steps.rs

use crate::tool_event_parser::ToolEvent;
use serde_json::Value;

#[derive(Debug, Clone)]
pub struct ToolStep {
    pub title: String,
    pub body: String,
}

pub fn extract_tool_steps(events: &[ToolEvent], max_steps: usize) -> Vec<ToolStep> {
    let mut steps = Vec::new();

    // 只取最近的 tool.request，倒序扫描
    for e in events.iter().rev() {
        if steps.len() >= max_steps {
            break;
        }
        if e.event_type != "tool.request" {
            continue;
        }

        let tool = e.tool.clone().unwrap_or_else(|| "unknown".to_string());
        let action = e.action.clone().unwrap_or_else(|| "call".to_string());

        // 生成一个“稳健的摘要”（不输出全部 args）
        let args_summary = summarize_args(&e.args);

        steps.push(ToolStep {
            title: format!("Call tool `{}` ({})", tool, action),
            body: format!("Args summary: {}", args_summary),
        });
    }

    steps.reverse();
    steps
}

fn summarize_args(args: &Value) -> String {
    // 优先：如果有常见字段（query/path/url/code）就提取；否则列 keys
    if let Some(o) = args.as_object() {
        for k in ["query", "q", "path", "filepath", "file", "url", "command", "cmd", "code"].iter() {
            if let Some(v) = o.get(*k) {
                return format!("{}={}", k, shorten(v));
            }
        }
        let keys: Vec<String> = o.keys().cloned().take(16).collect();
        return format!("keys=[{}]", keys.join(","));
    }
    "non-object args".to_string()
}

fn shorten(v: &Value) -> String {
    let s = match v {
        Value::String(x) => x.clone(),
        _ => v.to_string(),
    };
    let t = s.trim().replace('\n', " ");
    if t.chars().count() <= 140 {
        t
    } else {
        t.chars().take(138).collect::<String>() + "…"
    }
}
3.2 把 tool_steps 接入你的启发式 Candidate 抽取器
修改 extract_candidates(...) 中组装 answer 的部分：

在 ## Steps 里优先输出 tool_steps
若 tool_steps 为空，再用命令块（你已有）
两者都为空才用兜底模板
在 candidate_extract.rs 里加：

use crate::tool_steps::extract_tool_steps;
并在组装 Steps 时替换为：

let tool_steps = extract_tool_steps_from_lite(tool_events, 5); // 若你传的是 ToolEventLite，就用 lite 版本（下面提供）

answer.push_str("## Steps\n");
if !tool_steps.is_empty() {
    for (i, s) in tool_steps.iter().enumerate() {
        answer.push_str(&format!("{}. {}\n", i + 1, s.title));
        answer.push_str(&format!("   - {}\n", s.body));
    }
} else if let Some(block) = cmd_block {
    answer.push_str("1. Run the following commands:\n```bash\n");
    answer.push_str(&block);
    if !block.ends_with('\n') { answer.push('\n'); }
    answer.push_str("```\n");
} else {
    answer.push_str("1. Identify the failing command/output in your terminal logs.\n");
    answer.push_str("2. Apply the fix corresponding to the error hint.\n");
    answer.push_str("3. Re-run tests/build to confirm.\n");
}
由于你的抽取器当前吃的是 ToolEventLite，我给一个 lite 版 steps 提取器（更简单）：

文件：src/tool_steps_lite.rs

use crate::candidate_extract::ToolEventLite;

#[derive(Debug, Clone)]
pub struct ToolStepLite {
    pub title: String,
    pub body: String,
}

pub fn extract_tool_steps_from_lite(events: &[ToolEventLite], max_steps: usize) -> Vec<ToolStepLite> {
    let mut steps = Vec::new();

    for e in events.iter().rev() {
        if steps.len() >= max_steps {
            break;
        }
        let tool = e.tool.clone();
        let action = e.action.clone().unwrap_or_else(|| "call".to_string());
        let args_keys = e
            .args
            .as_object()
            .map(|o| o.keys().cloned().take(16).collect::<Vec<_>>().join(","))
            .unwrap_or_else(|| "-".to_string());

        steps.push(ToolStepLite {
            title: format!("Call tool `{}` ({})", tool, action),
            body: format!("Args keys: {}", args_keys),
        });
    }

    steps.reverse();
    steps
}
4）Candidate 的 question/tags 也利用工具线索（增强）
在 build_question(...) 里你已经用 tool_events.last() 做兜底。可以升级为：

若存在 failing tool.result（ok=false），把 tool 名写进 question（更可检索）
在 candidate_extract.rs 增加一个函数：

fn last_failing_tool(events: &[ToolEventLite]) -> Option<String> {
    for e in events.iter().rev() {
        if e.ok == Some(false) {
            return Some(e.tool.clone());
        }
    }
    None
}
并在 build_question(...) 前面加：

if let Some(t) = last_failing_tool(tool_events) {
    return format!("How to fix tool `{}` failure while running: {}", t, trim_mid(user_query, 140));
}
tags 方面，你已经会从 mcp/工具名推导；现在建议加一个规则：如果出现 failing tool，把 tool 名本身也作为 tag（但要规范化、短一点）。

5）Runner 里把 ToolEvent 注入到 Gatekeeper / Candidate
你现在 runner 已经能收集 Vec<ToolEvent>（ToolEventParser + events_out 部分已完成）。
接下来把它串起来：

tool_events: Vec<ToolEvent>
tool_events_lite: Vec<ToolEventLite>
调用 Gatekeeper：
let decision = Gatekeeper::evaluate(&gk_cfg, Utc::now(), &matches, &run_outcome, &tool_events);
candidate 抽取：
let tool_events_lite = tool_events.iter().map(|e| ToolEventLite::from(e)).collect::<Vec<_>>();

let candidate_drafts = if decision.should_write_candidate {
    extract_candidates(
        &cand_cfg,
        &args.user_query,
        &run_outcome.stdout_tail,
        &run_outcome.stderr_tail,
        &tool_events_lite,
    )
} else { vec![] };
6）现在“按设计继续”的下一步待办（非常具体）
完成以上增强后，下一步就进入你设计的“质量闸门收敛”阶段，建议做：

ToolEvent request/result 关联（用 id）：输出 “N requests / N results / unmatched count” 到 signals
Candidate 去重增强：candidate 的 question/answer 先做一次本地 fingerprint，避免同一 run 多次写入
events_out 回放工具：memwrap replay --events run.events.jsonl 复现 gatekeeper/candidate 逻辑（纯离线）
你如果要我继续写，我建议下一条直接做 “request/result 关联 + unmatched 指标 + signals 输出”。

You:
request/result 关联 + unmatched 指标 + signals 输出

ChatGPT:
[Unsupported Content]

ChatGPT:
[Unsupported Content]

ChatGPT:
下面把 request/result 关联 + unmatched 指标 + signals 输出 这块完整补齐到可落地的 Rust 代码，并给出你需要改的接入点（ToolInsights / GatekeeperDecision.signals / validate payload 三处）。

1）request/result 关联与统计（核心模块）
文件：src/tool_event_correlate.rs

use crate::tool_event_parser::ToolEvent;
use serde_json::Value;
use std::collections::{BTreeMap, BTreeSet};

#[derive(Debug, Clone, Default)]
pub struct CorrelationStats {
    pub request_count: usize,
    pub result_count: usize,

    pub matched_pairs: usize,

    /// 有 request 没有 result（按 id）
    pub unmatched_requests: usize,

    /// 有 result 没有 request（按 id）
    pub unmatched_results: usize,

    /// 没有 id 的 request/result（无法关联）
    pub request_missing_id: usize,
    pub result_missing_id: usize,

    /// 同一个 id 的重复 request/result（异常信号）
    pub duplicate_request_ids: usize,
    pub duplicate_result_ids: usize,

    /// 关联后失败（ok=false）的 result 数量
    pub failed_results: usize,

    /// 按 tool 统计 matched/failed/unmatched（便于排障）
    pub by_tool: BTreeMap<String, ToolCorrStats>,

    /// 最近一次匹配到的 pair 摘要（可选）
    pub last_pair: Option<Value>,
}

#[derive(Debug, Clone, Default)]
pub struct ToolCorrStats {
    pub matched: usize,
    pub failed: usize,
    pub request_only: usize,
    pub result_only: usize,
    pub request_missing_id: usize,
    pub result_missing_id: usize,
}

pub fn correlate_request_result(events: &[ToolEvent]) -> CorrelationStats {
    let mut stats = CorrelationStats::default();

    // id -> event index（取最后一次；也可以保留 first/last 两个索引）
    let mut req_by_id: BTreeMap<String, &ToolEvent> = BTreeMap::new();
    let mut res_by_id: BTreeMap<String, &ToolEvent> = BTreeMap::new();

    let mut seen_req_ids: BTreeSet<String> = BTreeSet::new();
    let mut seen_res_ids: BTreeSet<String> = BTreeSet::new();

    for e in events {
        match e.event_type.as_str() {
            "tool.request" => {
                stats.request_count += 1;
                let tool = tool_name(e);
                let entry = stats.by_tool.entry(tool).or_default();

                match e.id.as_deref() {
                    Some(id) if !id.trim().is_empty() => {
                        if !seen_req_ids.insert(id.to_string()) {
                            stats.duplicate_request_ids += 1;
                        }
                        req_by_id.insert(id.to_string(), e);
                    }
                    _ => {
                        stats.request_missing_id += 1;
                        entry.request_missing_id += 1;
                    }
                }
            }
            "tool.result" => {
                stats.result_count += 1;
                let tool = tool_name(e);
                let entry = stats.by_tool.entry(tool).or_default();

                if e.ok == Some(false) {
                    stats.failed_results += 1;
                }

                match e.id.as_deref() {
                    Some(id) if !id.trim().is_empty() => {
                        if !seen_res_ids.insert(id.to_string()) {
                            stats.duplicate_result_ids += 1;
                        }
                        res_by_id.insert(id.to_string(), e);
                    }
                    _ => {
                        stats.result_missing_id += 1;
                        entry.result_missing_id += 1;
                    }
                }
            }
            _ => {}
        }
    }

    // matched/unmatched by id
    let mut matched = 0usize;

    for (id, req) in req_by_id.iter() {
        if let Some(res) = res_by_id.get(id) {
            matched += 1;

            let tool = tool_name(req);
            let entry = stats.by_tool.entry(tool).or_default();
            entry.matched += 1;
            if res.ok == Some(false) {
                entry.failed += 1;
            }

            stats.last_pair = Some(slim_pair(id, req, res));
        } else {
            stats.unmatched_requests += 1;
            let tool = tool_name(req);
            let entry = stats.by_tool.entry(tool).or_default();
            entry.request_only += 1;
        }
    }

    for (id, res) in res_by_id.iter() {
        if !req_by_id.contains_key(id) {
            stats.unmatched_results += 1;
            let tool = tool_name(res);
            let entry = stats.by_tool.entry(tool).or_default();
            entry.result_only += 1;
        }
    }

    stats.matched_pairs = matched;
    stats
}

fn tool_name(e: &ToolEvent) -> String {
    e.tool.clone().unwrap_or_else(|| "unknown".to_string())
}

fn slim_pair(id: &str, req: &ToolEvent, res: &ToolEvent) -> Value {
    serde_json::json!({
        "id": id,
        "tool": req.tool,
        "action": req.action,
        "req_ts": req.ts,
        "res_ts": res.ts,
        "ok": res.ok,
        "req_args_keys": args_keys(&req.args),
        "res_output_keys": res.output.as_ref().and_then(|v| v.as_object().map(|o| o.keys().cloned().take(32).collect::<Vec<_>>())),
    })
}

fn args_keys(v: &Value) -> Vec<String> {
    match v.as_object() {
        Some(map) => map.keys().cloned().take(32).collect(),
        None => vec![],
    }
}
2）把 CorrelationStats 纳入 ToolInsights（用于 validate 与 signals）
你之前有 ToolInsights（build_tool_insights）。现在把关联统计加进去。

修改：src/tool_event_insights.rs

在 ToolInsights 里新增字段：

pub correlation: crate::tool_event_correlate::CorrelationStats,
然后在 build_tool_insights 末尾加入：

use crate::tool_event_correlate::correlate_request_result;

let correlation = correlate_request_result(events);

ToolInsights {
    total: events.len(),
    by_type,
    tools: tools.into_iter().collect(),
    failing_tools: failing.into_iter().collect(),
    last_request: last_req.map(slim_event),
    last_result: last_res.map(slim_event),
    correlation,
}
3）signals 输出（GatekeeperDecision.signals 增强）
目标：把“关联质量”作为可观测指标输出，便于你调试 tool 事件链路问题（比如 result 丢了、id 不稳定等）。

修改：Gatekeeper::evaluate(...)（建议已带 tool_events: &[ToolEvent]）

在构造 signals 前先算：

use crate::tool_event_insights::build_tool_insights;

let insights = build_tool_insights(tool_events);
let corr = &insights.correlation;
然后把下面这些塞进 signals：

let signals = serde_json::json!({
  // 你原有 signals...
  "usable_count": usable.len(),
  "inject_count": inject_list.len(),
  "has_strong": has_strong,
  "top1_score": top1_score,
  "status_reject": status_reject,
  "stale_reject": stale_count,
  "fail_reject": fail_reject,
  "should_write_candidate": should_write_candidate,

  // tool correlation signals
  "tool_events_total": insights.total,
  "tool_events_by_type": insights.by_type,
  "tools": insights.tools,
  "failing_tools": insights.failing_tools,

  "tool_corr": {
    "request_count": corr.request_count,
    "result_count": corr.result_count,
    "matched_pairs": corr.matched_pairs,
    "unmatched_requests": corr.unmatched_requests,
    "unmatched_results": corr.unmatched_results,
    "request_missing_id": corr.request_missing_id,
    "result_missing_id": corr.result_missing_id,
    "duplicate_request_ids": corr.duplicate_request_ids,
    "duplicate_result_ids": corr.duplicate_result_ids,
    "failed_results": corr.failed_results,
    "by_tool": corr.by_tool,         // BTreeMap 可直接 JSON
    "last_pair": corr.last_pair,     // 可选，可能为 null
  }
});
注意：BTreeMap<String, ToolCorrStats> 需要可序列化。
你只要给 ToolCorrStats 派生 Serialize 即可：

在 tool_event_correlate.rs 里给 ToolCorrStats 加：

use serde::Serialize;

#[derive(Debug, Clone, Default, Serialize)]
pub struct ToolCorrStats { ... }
同理 CorrelationStats 如果也想直接塞 JSON，可以 Serialize，不过你已经手动拆字段写入 JSON 了，不强制。

4）Validate payload 增强（把 corr 指标回传给服务端）
你构造 ValidatePlan.payload 的地方，把 ToolInsights/corr 也放进去（建议与 signals 保持同构，但更紧凑）：

payload: serde_json::json!({
  "exit_code": run.exit_code,
  "duration_ms": run.duration_ms,
  "stdout_tail_digest": digest_cheap(&run.stdout_tail),
  "stderr_tail_digest": digest_cheap(&run.stderr_tail),

  "tools": insights.tools,
  "failing_tools": insights.failing_tools,

  "tool_corr": {
    "request_count": corr.request_count,
    "result_count": corr.result_count,
    "matched_pairs": corr.matched_pairs,
    "unmatched_requests": corr.unmatched_requests,
    "unmatched_results": corr.unmatched_results,
    "missing_id": {
      "request": corr.request_missing_id,
      "result": corr.result_missing_id
    },
    "duplicates": {
      "request_ids": corr.duplicate_request_ids,
      "result_ids": corr.duplicate_result_ids
    },
    "failed_results": corr.failed_results
  },
  "last_pair": corr.last_pair,
})
这样服务端可以基于：

“unmatched 是否异常偏高”
“missing_id 是否在某版本激增”
“failed_results 与 exit_code 是否一致” 来调整 trust 或打告警。
5）把关联质量纳入 validate 信号分级（推荐）
你在 grade_validation_signal(...) 里新增参数：

unmatched_total = unmatched_requests + unmatched_results
missing_id_total = request_missing_id + result_missing_id
failed_tools_count = failing_tools.len()
强信号条件建议收紧为：

pass
success markers
used_qa_ids_count > 0
failing_tools_count == 0
unmatched_total == 0（或 <=1）
missing_id_total == 0（或 <=1）
示例（只给关键逻辑）：

if is_pass
   && hit_success
   && used_qa_ids_count > 0
   && failing_tools_count == 0
   && unmatched_total == 0
   && missing_id_total == 0
{
   strong
}
这样可以避免“工具链路不完整但 exit_code=0”的虚假强信号。

6）落地检查清单（你接完就能确认对不对）
运行一次后，在 GatekeeperDecision.signals.tool_corr 里你应该能看到：

request_count 与 result_count 大体接近
matched_pairs 接近 min(request_count, result_count)
unmatched_* 接近 0
missing_id 接近 0
如果出现：

missing_id 很高：说明工具事件没有带 id，需要你在产生日志一端补 id
unmatched_results 很高：说明 result 打印了但 request 没打印（或前缀不一致）
unmatched_requests 很高：说明 request 打印了但 result 丢了（子进程崩溃/输出截断/tee 任务退出等）
如果你愿意继续按设计推进，下一步最自然的是：
在 GatekeeperDecision.reasons 里输出“关键异常摘要”（例如 unmatched>0、missing_id>0 时给出 top 工具名），以及 在 events_out 中额外写入 wrapper 自身的观测事件（比如 runner.exit / tee.drop），让回放更完整。

You:
继续

ChatGPT:
下面继续两件事（按你刚说的方向）：

GatekeeperDecision.reasons 增强：输出关键异常摘要（unmatched/missing_id/duplicates/failures 的 top 工具）
events_out 追加 wrapper 自身观测事件（runner.exit / tee.drop / memory.call 等），让回放完整
我给你可直接落地的模块 + 接入点。

1）GatekeeperDecision.reasons：异常摘要生成器
1.1 摘要生成模块
文件：src/gatekeeper_reasons.rs

use crate::tool_event_correlate::{CorrelationStats, ToolCorrStats};
use std::cmp::Reverse;

/// 将工具关联统计转成“可读的 reasons”片段（可直接 push 到 GatekeeperDecision.reasons）
pub fn summarize_tool_corr_anomalies(corr: &CorrelationStats) -> Vec<String> {
    let mut reasons = Vec::new();

    // 总览
    reasons.push(format!(
        "tool_corr: req={}, res={}, matched={}, unreq={}, unres={}, miss_req_id={}, miss_res_id={}, dup_req_id={}, dup_res_id={}, failed_res={}",
        corr.request_count,
        corr.result_count,
        corr.matched_pairs,
        corr.unmatched_requests,
        corr.unmatched_results,
        corr.request_missing_id,
        corr.result_missing_id,
        corr.duplicate_request_ids,
        corr.duplicate_result_ids,
        corr.failed_results,
    ));

    // 关键异常：按严重度追加
    if corr.request_missing_id + corr.result_missing_id > 0 {
        reasons.push(format!(
            "tool_corr anomaly: missing id (request={}, result={})",
            corr.request_missing_id, corr.result_missing_id
        ));
        reasons.extend(top_tools_lines(&corr.by_tool, Kind::MissingId, 5));
    }

    if corr.unmatched_requests + corr.unmatched_results > 0 {
        reasons.push(format!(
            "tool_corr anomaly: unmatched (requests_only={}, results_only={})",
            corr.unmatched_requests, corr.unmatched_results
        ));
        reasons.extend(top_tools_lines(&corr.by_tool, Kind::Unmatched, 5));
    }

    if corr.duplicate_request_ids + corr.duplicate_result_ids > 0 {
        reasons.push(format!(
            "tool_corr anomaly: duplicate ids (req_dup={}, res_dup={})",
            corr.duplicate_request_ids, corr.duplicate_result_ids
        ));
    }

    if corr.failed_results > 0 {
        reasons.push(format!("tool_corr: failed_results={}", corr.failed_results));
        reasons.extend(top_tools_lines(&corr.by_tool, Kind::Failed, 5));
    }

    // last_pair 只给简短提示（不要塞太大）
    if corr.last_pair.is_some() {
        reasons.push("tool_corr: last_pair available".to_string());
    }

    reasons
}

#[derive(Clone, Copy)]
enum Kind {
    MissingId,
    Unmatched,
    Failed,
}

fn top_tools_lines(
    by_tool: &std::collections::BTreeMap<String, ToolCorrStats>,
    kind: Kind,
    top_n: usize,
) -> Vec<String> {
    let mut rows: Vec<(String, usize, ToolCorrStats)> = Vec::new();

    for (tool, s) in by_tool.iter() {
        let score = match kind {
            Kind::MissingId => s.request_missing_id + s.result_missing_id,
            Kind::Unmatched => s.request_only + s.result_only,
            Kind::Failed => s.failed,
        };
        if score > 0 {
            rows.push((tool.clone(), score, s.clone()));
        }
    }

    // score desc
    rows.sort_by_key(|(_, score, _)| Reverse(*score));

    rows.into_iter()
        .take(top_n)
        .map(|(tool, score, s)| {
            match kind {
                Kind::MissingId => format!(
                    " - tool={} missing_id={} (req_missing={}, res_missing={})",
                    tool, score, s.request_missing_id, s.result_missing_id
                ),
                Kind::Unmatched => format!(
                    " - tool={} unmatched={} (request_only={}, result_only={})",
                    tool, score, s.request_only, s.result_only
                ),
                Kind::Failed => format!(
                    " - tool={} failed={} (matched={}, request_only={}, result_only={})",
                    tool, score, s.matched, s.request_only, s.result_only
                ),
            }
        })
        .collect()
}
依赖：CorrelationStats/ToolCorrStats 需要 Clone（你已有）即可。

1.2 Gatekeeper.evaluate 接入点
在你 Gatekeeper::evaluate 里已经有 insights / corr。
把 reasons 增强为：

use crate::gatekeeper_reasons::summarize_tool_corr_anomalies;

let corr = &insights.correlation;

// 在 reasons.push(...) 之后追加：
reasons.extend(summarize_tool_corr_anomalies(corr));
这样每次 run 都会把“工具链路是否健康”写进 reasons，排障效率会提升很多。

2）events_out：写入 wrapper 自身观测事件
目标：除了子进程吐出来的 @@MEM_TOOL_EVENT@@ ...，我们还要把 wrapper 自己的关键事件写进同一个 JSONL 文件，这样你能离线回放完整流程。

2.1 定义 wrapper 观测事件格式
文件：src/wrapper_event.rs

use serde::{Deserialize, Serialize};
use serde_json::Value;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WrapperEvent {
    pub v: i32,
    #[serde(rename = "type")]
    pub event_type: String, // "runner.start" | "runner.exit" | "tee.drop" | "memory.call" | ...
    pub ts: String,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub run_id: Option<String>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub data: Option<Value>,
}

impl WrapperEvent {
    pub fn new(event_type: &str, ts: String) -> Self {
        Self {
            v: 1,
            event_type: event_type.to_string(),
            ts,
            run_id: None,
            data: None,
        }
    }
}
2.2 events_out 写入 wrapper event 的辅助函数
文件：src/events_out_helpers.rs

use crate::events_out::EventsOutTx;
use crate::wrapper_event::WrapperEvent;

pub async fn write_wrapper_event(out: Option<&EventsOutTx>, ev: &WrapperEvent) {
    let Some(out) = out else { return; };
    if let Ok(line) = serde_json::to_string(ev) {
        // 为了区分子进程工具事件前缀格式，这里不用前缀，直接纯 JSONL
        out.send_line(line).await;
    }
}
2.3 Runner 集成点（推荐写 4 类事件）
A) runner.start（启动子进程前）
use chrono::Utc;
use crate::wrapper_event::WrapperEvent;
use crate::events_out_helpers::write_wrapper_event;

let mut ev = WrapperEvent::new("runner.start", Utc::now().to_rfc3339());
ev.run_id = Some(run_id.clone());
ev.data = Some(serde_json::json!({
  "cmd": resolved_cmd_string,
  "cwd": cwd,
  "profile": profile_name,
}));
write_wrapper_event(events_out_tx.as_ref(), &ev).await;
B) tee.drop（events_out 丢弃行数）
在你 ToolEventRuntime 里已能读到 dropped count。run 结束时：

let dropped = tool_event_runtime.dropped_events_out();
if dropped > 0 {
  let mut ev = WrapperEvent::new("tee.drop", Utc::now().to_rfc3339());
  ev.run_id = Some(run_id.clone());
  ev.data = Some(serde_json::json!({ "dropped_lines": dropped }));
  write_wrapper_event(events_out_tx.as_ref(), &ev).await;
}
这里的 events_out_tx 就是你 start_events_out 返回的 EventsOutTx（建议你在 runner 顶层保留一份）。

C) memory.call（每次调用 memory API 记录一次）
在 MemoryClient.send_* 方法里，发请求前/后写一条（best-effort）：

type: memory.call
data: { "endpoint": "/v1/qa/validate", "ok": true/false, "status": 200, "latency_ms": 12 }
（你可以先只做 runner 侧调用点写一次，后续再下沉到 client。）

D) runner.exit（子进程结束后）
let mut ev = WrapperEvent::new("runner.exit", Utc::now().to_rfc3339());
ev.run_id = Some(run_id.clone());
ev.data = Some(serde_json::json!({
  "exit_code": run_outcome.exit_code,
  "duration_ms": run_outcome.duration_ms,
  "used_qa_ids": run_outcome.used_qa_ids,
  "shown_qa_ids": run_outcome.shown_qa_ids,
}));
write_wrapper_event(events_out_tx.as_ref(), &ev).await;
3）把两条链路统一到同一 events_out（重要约定）
现在 events_out 文件里将出现两种行：

子进程工具事件行：
@@MEM_TOOL_EVENT@@ { ... }
wrapper 自身观测事件：
{ "v":1, "type":"runner.start", ... }
这对回放工具很友好：

看到前缀 → 用 ToolEventParser 解析
看到纯 JSON → 用 WrapperEvent 解析（或先检查 type 字段）
4）下一步（按设计继续，回放能力）
做完这一步，你就可以实现一个离线回放命令：

memwrap replay --events run.events.jsonl
重建 tool events
重放 gatekeeper evaluate
比较不同阈值的决策变化（调参神器）
如果你愿意继续，我下一条可以把 replay 工具（CLI 子命令 + 解析器 + 输出报告） 一次性写完。

You:
replay 工具（CLI 子命令 + 解析器 + 输出报告）

ChatGPT:
[Unsupported Content]

ChatGPT:
[Unsupported Content]

ChatGPT:
下面给你一个可直接落地的 replay 工具实现：包含 CLI 子命令（clap）+ 解析器（同时支持前缀 ToolEvent 与纯 JSON WrapperEvent）+ 输出报告（text/json）。它不依赖运行 codecli，不依赖网络，可用于离线调参和排障。

1）CLI 子命令：memwrap replay
1.1 参数设计
--events <path>：必填，events_out JSONL 文件
--run-id <id>：可选，只回放某次 run
--format text|json：默认 text
--show-lines <n>：默认 0，不输出原始行
--gatekeeper：可选，若提供则对每个 run 用当前配置重跑 Gatekeeper（需要你提供 search matches 或关闭）
本版本先做基础回放报告；Gatekeeper 重跑留一个扩展点（下面给接口）
2）文件结构（新增）
建议新增：

src/replay/
  mod.rs
  cli.rs
  parse.rs
  model.rs
  report.rs
3）数据模型：WrapperEvent + ToolEvent + ReplayRecord
文件：src/replay/model.rs

use serde::{Deserialize, Serialize};
use serde_json::Value;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WrapperEvent {
    pub v: i32,
    #[serde(rename = "type")]
    pub event_type: String,
    pub ts: String,

    #[serde(default)]
    pub run_id: Option<String>,

    #[serde(default)]
    pub data: Option<Value>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ToolEvent {
    #[serde(default)]
    pub v: i32,

    #[serde(rename = "type")]
    pub event_type: String, // tool.request/tool.result/...
    #[serde(default)]
    pub ts: Option<String>,
    #[serde(default)]
    pub id: Option<String>,
    #[serde(default)]
    pub tool: Option<String>,
    #[serde(default)]
    pub action: Option<String>,
    #[serde(default)]
    pub args: Value,
    #[serde(default)]
    pub ok: Option<bool>,
    #[serde(default)]
    pub output: Option<Value>,
}

#[derive(Debug, Clone)]
pub enum ReplayLine {
    Wrapper(WrapperEvent),
    Tool(ToolEvent),
    Unknown(String),
}

/// 按 run_id 聚合后的回放记录
#[derive(Debug, Clone, Default, Serialize)]
pub struct ReplayRun {
    pub run_id: String,
    pub runner_start: Option<WrapperEvent>,
    pub runner_exit: Option<WrapperEvent>,
    pub tee_drop: Option<WrapperEvent>,
    pub memory_calls: Vec<WrapperEvent>,

    pub tool_events: Vec<ToolEvent>,

    // 派生指标（report 阶段填）
    pub derived: Value,
}
4）解析器：同时解析两类行
以 @@MEM_TOOL_EVENT@@ 开头：解析 ToolEvent
否则尝试解析 JSON：如果有 "type" 并匹配 wrapper 事件形态，则当 WrapperEvent
否则 Unknown
文件：src/replay/parse.rs

use super::model::{ReplayLine, ToolEvent, WrapperEvent};
use serde_json::Value;

pub const TOOL_PREFIX: &str = "@@MEM_TOOL_EVENT@@";

pub fn parse_line(line: &str) -> ReplayLine {
    let s = line.trim_end_matches('\n').trim();

    if s.starts_with(TOOL_PREFIX) {
        let json_part = s[TOOL_PREFIX.len()..].trim();
        if let Ok(ev) = serde_json::from_str::<ToolEvent>(json_part) {
            return ReplayLine::Tool(ev);
        }
        return ReplayLine::Unknown(line.to_string());
    }

    // 纯 JSON
    match serde_json::from_str::<Value>(s) {
        Ok(v) => {
            // wrapper event：至少要有 type + ts
            if v.get("type").is_some() && v.get("ts").is_some() {
                if let Ok(w) = serde_json::from_value::<WrapperEvent>(v) {
                    return ReplayLine::Wrapper(w);
                }
            }
            ReplayLine::Unknown(line.to_string())
        }
        Err(_) => ReplayLine::Unknown(line.to_string()),
    }
}
5）聚合器：按 run_id 归档（没有 run_id 的工具事件也能挂靠）
关键点：ToolEvent 本身不带 run_id。我们用“最近一次 runner.start 的 run_id”作为当前 run 的上下文，把 tool events 归到该 run。

文件：src/replay/mod.rs

pub mod cli;
pub mod model;
pub mod parse;
pub mod report;

use model::{ReplayLine, ReplayRun, WrapperEvent};
use parse::parse_line;
use std::collections::BTreeMap;
use tokio::io::{AsyncBufReadExt, BufReader};

pub async fn replay_events_file(path: &str, filter_run_id: Option<&str>) -> Result<Vec<ReplayRun>, String> {
    let f = tokio::fs::File::open(path).await.map_err(|e| e.to_string())?;
    let mut lines = BufReader::new(f).lines();

    let mut runs: BTreeMap<String, ReplayRun> = BTreeMap::new();
    let mut current_run_id: Option<String> = None;

    while let Ok(Some(line)) = lines.next_line().await {
        match parse_line(&line) {
            ReplayLine::Wrapper(w) => {
                if let Some(rid) = w.run_id.clone().or_else(|| infer_run_id_from_event(&w)) {
                    current_run_id = Some(rid.clone());
                    if filter_run_id.is_some() && filter_run_id != Some(rid.as_str()) {
                        // 仍然更新 current_run_id，但不聚合
                        continue;
                    }
                    let entry = runs.entry(rid.clone()).or_insert_with(|| ReplayRun {
                        run_id: rid.clone(),
                        ..Default::default()
                    });
                    attach_wrapper(entry, w);
                } else {
                    // 没有 run_id 的 wrapper event，忽略或记日志
                }
            }
            ReplayLine::Tool(t) => {
                let Some(rid) = current_run_id.clone() else {
                    continue; // 没遇到 runner.start，没法归属
                };
                if filter_run_id.is_some() && filter_run_id != Some(rid.as_str()) {
                    continue;
                }
                let entry = runs.entry(rid.clone()).or_insert_with(|| ReplayRun {
                    run_id: rid.clone(),
                    ..Default::default()
                });
                entry.tool_events.push(t);
            }
            ReplayLine::Unknown(_) => {
                // 可选：统计 unknown 行数
            }
        }
    }

    Ok(runs.into_values().collect())
}

fn attach_wrapper(run: &mut ReplayRun, w: WrapperEvent) {
    match w.event_type.as_str() {
        "runner.start" => run.runner_start = Some(w),
        "runner.exit" => run.runner_exit = Some(w),
        "tee.drop" => run.tee_drop = Some(w),
        "memory.call" => run.memory_calls.push(w),
        _ => {
            // 其他 wrapper event：也按 memory_calls 收集或扩展字段
            run.memory_calls.push(w);
        }
    }
}

/// 某些实现可能把 run_id 放在 data 里，这里留个兜底（可选）
fn infer_run_id_from_event(w: &WrapperEvent) -> Option<String> {
    w.data.as_ref()?.get("run_id")?.as_str().map(|s| s.to_string())
}
6）报告：统计 request/result 关联、unmatched、失败工具、以及退出码
这里复用你前面已经写过的关联器 correlate_request_result（如果你已经放在 src/tool_event_correlate.rs），replay 只需要调用它并输出。

文件：src/replay/report.rs

use super::model::ReplayRun;
use crate::tool_event_correlate::correlate_request_result;
use serde_json::Value;

#[derive(Debug, Clone, serde::Serialize)]
pub struct ReplayReport {
    pub runs: Vec<Value>,
    pub totals: Value,
}

pub fn build_report(mut runs: Vec<ReplayRun>) -> ReplayReport {
    let mut out_runs = Vec::new();

    let mut total_runs = 0usize;
    let mut total_tool_events = 0usize;
    let mut total_unmatched = 0usize;
    let mut total_missing_id = 0usize;
    let mut total_failed_results = 0usize;

    for r in runs.iter_mut() {
        total_runs += 1;
        total_tool_events += r.tool_events.len();

        let corr = correlate_request_result(&r.tool_events);
        let unmatched = corr.unmatched_requests + corr.unmatched_results;
        let missing_id = corr.request_missing_id + corr.result_missing_id;

        total_unmatched += unmatched;
        total_missing_id += missing_id;
        total_failed_results += corr.failed_results;

        // 从 runner.exit 里抓 exit_code/duration
        let (exit_code, duration_ms) = extract_exit_fields(r);

        r.derived = serde_json::json!({
            "exit_code": exit_code,
            "duration_ms": duration_ms,
            "tool_corr": {
                "request_count": corr.request_count,
                "result_count": corr.result_count,
                "matched_pairs": corr.matched_pairs,
                "unmatched_requests": corr.unmatched_requests,
                "unmatched_results": corr.unmatched_results,
                "request_missing_id": corr.request_missing_id,
                "result_missing_id": corr.result_missing_id,
                "duplicate_request_ids": corr.duplicate_request_ids,
                "duplicate_result_ids": corr.duplicate_result_ids,
                "failed_results": corr.failed_results,
                "by_tool": corr.by_tool,
                "last_pair": corr.last_pair
            }
        });

        out_runs.push(serde_json::json!({
            "run_id": r.run_id,
            "start": r.runner_start.as_ref().map(|x| &x.ts),
            "exit": r.runner_exit.as_ref().map(|x| &x.ts),
            "derived": r.derived,
            "tee_drop": r.tee_drop.as_ref().and_then(|x| x.data.clone()),
            "memory_calls": r.memory_calls.len(),
            "tool_events": r.tool_events.len(),
        }));
    }

    let totals = serde_json::json!({
        "runs": total_runs,
        "tool_events": total_tool_events,
        "unmatched_total": total_unmatched,
        "missing_id_total": total_missing_id,
        "failed_results_total": total_failed_results
    });

    ReplayReport { runs: out_runs, totals }
}

fn extract_exit_fields(r: &ReplayRun) -> (Option<i64>, Option<i64>) {
    let Some(exit) = &r.runner_exit else { return (None, None); };
    let Some(data) = &exit.data else { return (None, None); };

    let exit_code = data.get("exit_code").and_then(|v| v.as_i64());
    let duration_ms = data.get("duration_ms").and_then(|v| v.as_i64());
    (exit_code, duration_ms)
}

pub fn format_text(report: &ReplayReport) -> String {
    let mut s = String::new();

    s.push_str("Replay Report\n");
    s.push_str("=============\n\n");

    s.push_str(&format!(
        "Totals: runs={}, tool_events={}, unmatched_total={}, missing_id_total={}, failed_results_total={}\n\n",
        report.totals.get("runs").unwrap_or(&Value::Null),
        report.totals.get("tool_events").unwrap_or(&Value::Null),
        report.totals.get("unmatched_total").unwrap_or(&Value::Null),
        report.totals.get("missing_id_total").unwrap_or(&Value::Null),
        report.totals.get("failed_results_total").unwrap_or(&Value::Null),
    ));

    for r in report.runs.iter() {
        let run_id = r.get("run_id").and_then(|v| v.as_str()).unwrap_or("-");
        let tool_events = r.get("tool_events").and_then(|v| v.as_u64()).unwrap_or(0);
        let memory_calls = r.get("memory_calls").and_then(|v| v.as_u64()).unwrap_or(0);
        let derived = r.get("derived").unwrap_or(&Value::Null);
        let exit_code = derived.get("exit_code").and_then(|v| v.as_i64()).unwrap_or(-999);

        let tool_corr = derived.get("tool_corr").unwrap_or(&Value::Null);
        let req = tool_corr.get("request_count").and_then(|v| v.as_u64()).unwrap_or(0);
        let res = tool_corr.get("result_count").and_then(|v| v.as_u64()).unwrap_or(0);
        let matched = tool_corr.get("matched_pairs").and_then(|v| v.as_u64()).unwrap_or(0);
        let unreq = tool_corr.get("unmatched_requests").and_then(|v| v.as_u64()).unwrap_or(0);
        let unres = tool_corr.get("unmatched_results").and_then(|v| v.as_u64()).unwrap_or(0);
        let miss_req = tool_corr.get("request_missing_id").and_then(|v| v.as_u64()).unwrap_or(0);
        let miss_res = tool_corr.get("result_missing_id").and_then(|v| v.as_u64()).unwrap_or(0);
        let failed = tool_corr.get("failed_results").and_then(|v| v.as_u64()).unwrap_or(0);

        s.push_str(&format!("Run: {run_id}\n"));
        s.push_str(&format!("  exit_code: {exit_code}\n"));
        s.push_str(&format!("  tool_events: {tool_events}, memory_calls: {memory_calls}\n"));
        s.push_str(&format!(
            "  corr: req={req} res={res} matched={matched} unreq={unreq} unres={unres} miss_req_id={miss_req} miss_res_id={miss_res} failed_res={failed}\n"
        ));

        // 如果有 top by_tool（只打印前 3 个失败/未匹配最多的工具）
        if let Some(by_tool) = tool_corr.get("by_tool").and_then(|v| v.as_object()) {
            let mut hot: Vec<(String, u64)> = Vec::new();
            for (tool, stats) in by_tool.iter() {
                let failed = stats.get("failed").and_then(|v| v.as_u64()).unwrap_or(0);
                let un = stats.get("request_only").and_then(|v| v.as_u64()).unwrap_or(0)
                    + stats.get("result_only").and_then(|v| v.as_u64()).unwrap_or(0);
                let score = failed * 10 + un; // 简单热度：失败更重
                if score > 0 {
                    hot.push((tool.clone(), score));
                }
            }
            hot.sort_by(|a, b| b.1.cmp(&a.1));
            for (tool, score) in hot.into_iter().take(3) {
                s.push_str(&format!("  hot_tool: {} (score={})\n", tool, score));
            }
        }

        s.push('\n');
    }

    s
}
7）CLI 接线（clap）
文件：src/replay/cli.rs

use clap::Args;

#[derive(Debug, Clone, Args)]
pub struct ReplayArgs {
    /// Path to events_out JSONL file
    #[arg(long)]
    pub events: String,

    /// Only replay a specific run_id
    #[arg(long)]
    pub run_id: Option<String>,

    /// Output format: text|json
    #[arg(long, default_value = "text")]
    pub format: String,
}
8）主命令入口接入（示例）
假设你已有 Cli/Commands：

#[derive(clap::Subcommand)]
enum Commands {
  Run(RunArgs),
  Replay(replay::cli::ReplayArgs),
}
在 main.rs 或 app.rs 里处理：

match cli.command {
  Commands::Replay(args) => {
    let runs = crate::replay::replay_events_file(&args.events, args.run_id.as_deref()).await
        .map_err(|e| anyhow::anyhow!(e))?;

    let report = crate::replay::report::build_report(runs);

    if args.format == "json" {
        println!("{}", serde_json::to_string_pretty(&report).unwrap());
    } else {
        println!("{}", crate::replay::report::format_text(&report));
    }
  }
  _ => { /* existing */ }
}
9）Cargo 依赖补充
你需要确保：

clap = { version = "4", features = ["derive"] }
serde = { version = "1", features = ["derive"] }
serde_json = "1"
tokio = { version = "1", features = ["fs", "io-util", "macros", "rt-multi-thread"] }
并且你的 tool_event_correlate.rs 已存在且可被 replay 引用（如果还没挂到 crate mod，请 pub mod tool_event_correlate;）。

10）用法示例
输出 text：

memwrap replay --events ./run.events.jsonl
输出 json：

memwrap replay --events ./run.events.jsonl --format json
只看某个 run：

memwrap replay --events ./run.events.jsonl --run-id 20251227-abc123
下一步（按设计继续）
你现在有了 replay 的基础闭环。下一步最有价值的是把 replay 变成“调参器”：

--set gatekeeper.max_inject=2 --set policy.min_trust_show=0.5（临时覆盖）
对每个 run 重跑 Gatekeeper 并输出“决策差异”（inject_list/candidate suppressed 等）
生成一个“阈值敏感性报告”（比如 unmatched=0 的 run 占比，strong validate 占比）
如果你要我继续，我会直接给你：

ConfigOverride（点路径 set）
Gatekeeper replay evaluator 接口
diff report 输出格式（text + json）
You:
继续

ChatGPT:
[Unsupported Content]

ChatGPT:
[Unsupported Content]

ChatGPT:
下面继续把 replay 工具升级成“调参 + 重跑 Gatekeeper + 输出决策差异”的离线调参器。整体思路是：

replay 读取 events_out.jsonl 聚合成 runs
允许 --set a.b.c=value 临时覆盖配置（不改文件）
如果 run 中存在必要的“离线重跑输入”（至少：search_matches + user_query + stdout_tail/stderr_tail/exit_code），就对该 run 重跑 Gatekeeper
输出：
原始 run（如果记录了 gatekeeper 决策） vs 重跑决策
或者仅输出重跑决策（若原始决策没记录）
关键前提：要离线重跑 Gatekeeper，events 里必须记录足够信息。最少需要把 memory.search 的响应（matches）写入 events_out（wrapper event）。我下面会同时给你“如何记录 search_matches”与“replay 如何消费”。

1）扩展 events_out：记录 search_matches / gatekeeper.decision（一次到位）
1.1 在调用 memory.search 后写 wrapper event（建议类型）
memory.search.result
data 包含：
query（user_query）
matches（原始数组，或裁剪版）
latency_ms/status（可选）
示例写入（在 runner 的 search 阶段）：

use chrono::Utc;
use crate::wrapper_event::WrapperEvent;
use crate::events_out_helpers::write_wrapper_event;

// raw 是 memory.search 的 serde_json::Value（顶层数组）
let mut ev = WrapperEvent::new("memory.search.result", Utc::now().to_rfc3339());
ev.run_id = Some(run_id.clone());
ev.data = Some(serde_json::json!({
  "query": args.user_query,
  "matches": raw,                 // 顶层数组 list[dict]
}));
write_wrapper_event(events_out_tx.as_ref(), &ev).await;
1.2 在 Gatekeeper.evaluate 后写 decision（便于 diff baseline）
let mut ev = WrapperEvent::new("gatekeeper.decision", Utc::now().to_rfc3339());
ev.run_id = Some(run_id.clone());
ev.data = Some(serde_json::json!({
  "decision": decision,          // GatekeeperDecision 需 Serialize
}));
write_wrapper_event(events_out_tx.as_ref(), &ev).await;
若你暂时不想给 GatekeeperDecision 派生 Serialize，也可以只写 signals/reasons/inject_list/should_write_candidate 等子集。

2）replay CLI：新增 --set 与 --rerun-gatekeeper
修改：src/replay/cli.rs

use clap::Args;

#[derive(Debug, Clone, Args)]
pub struct ReplayArgs {
    #[arg(long)]
    pub events: String,

    #[arg(long)]
    pub run_id: Option<String>,

    #[arg(long, default_value = "text")]
    pub format: String,

    /// 临时覆盖配置，支持多次：--set gatekeeper.max_inject=2
    #[arg(long, action = clap::ArgAction::Append)]
    pub set: Vec<String>,

    /// 尝试离线重跑 Gatekeeper，并输出 diff
    #[arg(long, default_value_t = false)]
    pub rerun_gatekeeper: bool,
}
3）ConfigOverride：把 --set a.b.c=value 应用到配置结构
这里给你一个通用做法：
把 GatekeeperConfig（或你总配置）先 serde_json::to_value，对 JSON 做点路径 set，再 from_value 回结构体。

新增：src/replay/override.rs

use serde::{de::DeserializeOwned, Serialize};
use serde_json::{Value};

pub fn apply_overrides<T: Serialize + DeserializeOwned>(
    cfg: &T,
    sets: &[String],
) -> Result<T, String> {
    let mut v = serde_json::to_value(cfg).map_err(|e| e.to_string())?;
    for s in sets {
        let (path, raw_val) = parse_set(s)?;
        let val = parse_value(raw_val);
        set_by_path(&mut v, &path, val)?;
    }
    serde_json::from_value(v).map_err(|e| e.to_string())
}

fn parse_set(s: &str) -> Result<(Vec<String>, &str), String> {
    let Some((k, v)) = s.split_once('=') else {
        return Err(format!("invalid --set `{}`; expected key=value", s));
    };
    let path = k.split('.').map(|x| x.trim().to_string()).filter(|x| !x.is_empty()).collect::<Vec<_>>();
    if path.is_empty() { return Err(format!("invalid key path in `{}`", s)); }
    Ok((path, v.trim()))
}

/// 支持 bool/number/string/json object/array（若 raw 以 { 或 [ 开头则当 JSON）
fn parse_value(raw: &str) -> Value {
    if raw.eq_ignore_ascii_case("true") { return Value::Bool(true); }
    if raw.eq_ignore_ascii_case("false") { return Value::Bool(false); }

    if raw.starts_with('{') || raw.starts_with('[') {
        if let Ok(v) = serde_json::from_str::<Value>(raw) {
            return v;
        }
    }

    // number?
    if let Ok(i) = raw.parse::<i64>() { return Value::Number(i.into()); }
    if let Ok(f) = raw.parse::<f64>() {
        if let Some(n) = serde_json::Number::from_f64(f) { return Value::Number(n); }
    }

    Value::String(raw.to_string())
}

fn set_by_path(root: &mut Value, path: &[String], val: Value) -> Result<(), String> {
    let mut cur = root;
    for (i, key) in path.iter().enumerate() {
        let is_last = i == path.len() - 1;
        if is_last {
            match cur {
                Value::Object(map) => { map.insert(key.clone(), val); return Ok(()); }
                _ => return Err(format!("path {:?} does not resolve to object at leaf", path)),
            }
        } else {
            match cur {
                Value::Object(map) => {
                    cur = map.entry(key.clone()).or_insert(Value::Object(Default::default()));
                }
                _ => return Err(format!("path {:?} does not resolve to object", path)),
            }
        }
    }
    Ok(())
}
4）replay 聚合：把 memory.search.result / gatekeeper.decision 收进 ReplayRun
修改：src/replay/model.rs 的 ReplayRun 增加字段：

#[derive(Debug, Clone, Default, serde::Serialize)]
pub struct ReplayRun {
    pub run_id: String,
    pub runner_start: Option<WrapperEvent>,
    pub runner_exit: Option<WrapperEvent>,
    pub tee_drop: Option<WrapperEvent>,
    pub memory_calls: Vec<WrapperEvent>,
    pub tool_events: Vec<ToolEvent>,

    // 新增：离线重跑输入/基线
    pub search_result: Option<WrapperEvent>,      // memory.search.result
    pub gatekeeper_decision: Option<WrapperEvent>,// gatekeeper.decision

    pub derived: serde_json::Value,
}
修改：src/replay/mod.rs 的 attach_wrapper：

fn attach_wrapper(run: &mut ReplayRun, w: WrapperEvent) {
    match w.event_type.as_str() {
        "runner.start" => run.runner_start = Some(w),
        "runner.exit" => run.runner_exit = Some(w),
        "tee.drop" => run.tee_drop = Some(w),
        "memory.search.result" => run.search_result = Some(w),
        "gatekeeper.decision" => run.gatekeeper_decision = Some(w),
        "memory.call" => run.memory_calls.push(w),
        _ => run.memory_calls.push(w),
    }
}
5）离线重跑 Gatekeeper：Evaluator + Diff 输出
5.1 提取重跑所需输入
query：来自 memory.search.result.data.query（建议）
matches：来自 memory.search.result.data.matches（顶层数组）
exit_code/duration_ms/stdout_tail/stderr_tail/shown_qa_ids/used_qa_ids：来自 runner.exit.data
新增：src/replay/eval.rs

use crate::gatekeeper::{Gatekeeper, GatekeeperConfig, RunOutcome, SearchMatch};
use crate::memory_adapters::parse_search_matches;
use crate::tool_event_parser::ToolEvent;
use crate::replay::model::ReplayRun;

pub struct GatekeeperReplayResult {
    pub skipped: bool,
    pub skip_reason: Option<String>,
    pub decision_json: serde_json::Value,
}

pub fn rerun_gatekeeper_for_run(
    run: &ReplayRun,
    gk_cfg: &GatekeeperConfig,
) -> GatekeeperReplayResult {
    let Some(sr) = &run.search_result else {
        return GatekeeperReplayResult {
            skipped: true,
            skip_reason: Some("missing memory.search.result in events".to_string()),
            decision_json: serde_json::Value::Null,
        };
    };
    let Some(data) = &sr.data else {
        return GatekeeperReplayResult {
            skipped: true,
            skip_reason: Some("memory.search.result missing data".to_string()),
            decision_json: serde_json::Value::Null,
        };
    };

    let matches_v = data.get("matches").cloned().unwrap_or(serde_json::Value::Null);
    let matches: Vec<SearchMatch> = match parse_search_matches(&matches_v) {
        Ok(m) => m,
        Err(e) => {
            return GatekeeperReplayResult {
                skipped: true,
                skip_reason: Some(format!("failed to parse search matches: {}", e)),
                decision_json: serde_json::Value::Null,
            }
        }
    };

    let outcome = build_run_outcome_from_exit(run);

    // 你当前 Gatekeeper.evaluate 签名如果是 (cfg, now, matches, run, tool_events)
    let now = chrono::Utc::now();
    let decision = Gatekeeper::evaluate(gk_cfg, now, &matches, &outcome, &run.tool_events);

    GatekeeperReplayResult {
        skipped: false,
        skip_reason: None,
        decision_json: serde_json::to_value(&decision).unwrap_or(serde_json::Value::Null),
    }
}

fn build_run_outcome_from_exit(run: &ReplayRun) -> RunOutcome {
    let mut out = RunOutcome {
        exit_code: -999,
        duration_ms: None,
        stdout_tail: String::new(),
        stderr_tail: String::new(),
        shown_qa_ids: vec![],
        used_qa_ids: vec![],
    };

    if let Some(exit) = &run.runner_exit {
        if let Some(d) = &exit.data {
            out.exit_code = d.get("exit_code").and_then(|v| v.as_i64()).unwrap_or(-999) as i32;
            out.duration_ms = d.get("duration_ms").and_then(|v| v.as_i64()).map(|x| x as u64);
            out.stdout_tail = d.get("stdout_tail").and_then(|v| v.as_str()).unwrap_or("").to_string();
            out.stderr_tail = d.get("stderr_tail").and_then(|v| v.as_str()).unwrap_or("").to_string();
            out.shown_qa_ids = d.get("shown_qa_ids").and_then(|v| v.as_array()).map(arr_str).unwrap_or_default();
            out.used_qa_ids = d.get("used_qa_ids").and_then(|v| v.as_array()).map(arr_str).unwrap_or_default();
        }
    }

    out
}

fn arr_str(a: &Vec<serde_json::Value>) -> Vec<String> {
    a.iter().filter_map(|x| x.as_str().map(|s| s.to_string())).collect()
}
说明：为了让离线重跑更准，你需要在 runner.exit 里把 stdout_tail/stderr_tail 也写进去（如果你之前只写了 digest，建议补上；不想写全量就写 tail）。

5.2 Diff：基线 decision vs 重跑 decision（只对关键字段）
新增：src/replay/diff.rs

use serde_json::Value;

#[derive(Debug, Clone)]
pub struct DecisionDiff {
    pub has_baseline: bool,
    pub changed: bool,
    pub summary_lines: Vec<String>,
}

pub fn diff_gatekeeper_decision(baseline: Option<&Value>, rerun: &Value) -> DecisionDiff {
    let mut lines = Vec::new();

    let (b_inject, b_candidate, b_signals) = if let Some(b) = baseline {
        (get_inject_ids(b), get_bool(b, "should_write_candidate"), b.get("signals").cloned())
    } else {
        (vec![], None, None)
    };

    let r_inject = get_inject_ids(rerun);
    let r_candidate = get_bool(rerun, "should_write_candidate");
    let r_signals = rerun.get("signals").cloned();

    if baseline.is_some() {
        if b_inject != r_inject {
            lines.push(format!("inject_list changed: baseline={:?} rerun={:?}", b_inject, r_inject));
        }
        if b_candidate != r_candidate {
            lines.push(format!("should_write_candidate changed: baseline={:?} rerun={:?}", b_candidate, r_candidate));
        }
        // signals 可能很大：只对一些 key 做对比
        let keys = ["tool_events_total", "has_strong", "top1_score", "status_reject", "stale_reject", "fail_reject"];
        for k in keys {
            let bv = b_signals.as_ref().and_then(|x| x.get(k)).cloned();
            let rv = r_signals.as_ref().and_then(|x| x.get(k)).cloned();
            if bv != rv {
                lines.push(format!("signals.{k} changed: baseline={:?} rerun={:?}", bv, rv));
            }
        }
    } else {
        lines.push(format!("rerun inject_list: {:?}", r_inject));
        lines.push(format!("rerun should_write_candidate: {:?}", r_candidate));
    }

    let changed = baseline.is_some() && !lines.is_empty();
    DecisionDiff {
        has_baseline: baseline.is_some(),
        changed,
        summary_lines: lines,
    }
}

fn get_inject_ids(v: &Value) -> Vec<String> {
    // decision.inject_list 是数组，元素含 qa_id
    let mut ids = Vec::new();
    if let Some(arr) = v.get("inject_list").and_then(|x| x.as_array()) {
        for it in arr {
            if let Some(id) = it.get("qa_id").and_then(|x| x.as_str()) {
                ids.push(id.to_string());
            }
        }
    }
    ids
}

fn get_bool(v: &Value, k: &str) -> Option<bool> {
    v.get(k).and_then(|x| x.as_bool())
}
6）replay 主流程：应用 overrides → 重跑 → 输出报告/差异
修改：main.rs 处理 Commands::Replay(args) 的逻辑（示意）

use crate::replay::override_::apply_overrides; // 注意模块名别和关键字冲突
use crate::replay::eval::rerun_gatekeeper_for_run;
use crate::replay::diff::diff_gatekeeper_decision;

let mut runs = crate::replay::replay_events_file(&args.events, args.run_id.as_deref()).await?;

// 1) 基础 report（已有）
let mut report = crate::replay::report::build_report(runs.clone());

// 2) 如果要 rerun gatekeeper
if args.rerun_gatekeeper {
    let base_cfg = crate::gatekeeper::GatekeeperConfig::default();
    let gk_cfg = apply_overrides(&base_cfg, &args.set).map_err(|e| anyhow::anyhow!(e))?;

    // 对每个 run 做 rerun + diff
    let mut diffs = Vec::new();
    for r in runs.iter() {
        let rer = rerun_gatekeeper_for_run(r, &gk_cfg);

        if rer.skipped {
            diffs.push(serde_json::json!({
                "run_id": r.run_id,
                "skipped": true,
                "reason": rer.skip_reason,
            }));
            continue;
        }

        // baseline：如果记录了 gatekeeper.decision
        let baseline = r.gatekeeper_decision.as_ref()
            .and_then(|w| w.data.as_ref())
            .and_then(|d| d.get("decision"))
            .cloned();

        let diff = diff_gatekeeper_decision(baseline.as_ref(), &rer.decision_json);
        diffs.push(serde_json::json!({
            "run_id": r.run_id,
            "skipped": false,
            "has_baseline": diff.has_baseline,
            "changed": diff.changed,
            "diff": diff.summary_lines,
        }));
    }

    // 把 diffs 挂进 report（json 输出时很方便）
    // report.totals / runs 是 Value，所以可以直接扩展，也可以新建一个 report struct
    // 这里给一个简单方式：把 diffs 打印在 text 尾部或 json 顶层
}
上面示意里 override_ 是避免 override 与关键字/模块冲突，你文件名可用 override.rs，mod 名用 override_。

7）报告输出增强：text 加一段 “Gatekeeper Rerun Diff”
在 format_text(report) 后面追加 diffs（你可直接在 replay command 里打印）：

skipped run：缺少 memory.search.result/runner.exit.stdout_tail 等
changed run：列出 inject_list/candidate/signals 关键变更
8）你需要补齐的最小事件字段（保证 rerun 不被跳过）
为了让 --rerun-gatekeeper 真正发挥作用，建议确保 events_out 至少包含：

memory.search.result.data.matches（顶层数组）
memory.search.result.data.query（原始 query）
runner.exit.data.exit_code
runner.exit.data.stdout_tail、runner.exit.data.stderr_tail（至少 tail）
runner.exit.data.used_qa_ids、shown_qa_ids
（可选）gatekeeper.decision.data.decision 用于 baseline diff
这些都不涉及敏感信息（但 stdout/stderr 仍可能含 secret，所以你若担心可以在写入前做 redact）。

9）下一步按设计继续：变成真正的“调参器”
完成上述后，下一步就可以做两项很值的增强：

--matrix gatekeeper.max_inject=1,2,3：对同一批 runs 跑多组配置，输出“强命中率/候选写入率/异常率”对比
--export report.json：写文件，便于 CI 或图表化
你如果继续，我建议先做 --matrix（实现很快、收益很大）。